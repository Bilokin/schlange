# Autogenerated by Sphinx on Tue May  6 18:33:44 2025
# als part of the release process.

topics = {
    'assert': r'''The "assert" statement
**********************

Assert statements are a convenient way to insert debugging assertions
into a program:

   assert_stmt: "assert" expression ["," expression]

The simple form, "assert expression", ist equivalent to

   wenn __debug__:
       wenn nicht expression: wirf AssertionError

The extended form, "assert expression1, expression2", ist equivalent to

   wenn __debug__:
       wenn nicht expression1: wirf AssertionError(expression2)

These equivalences assume that "__debug__" und "AssertionError" refer
to the built-in variables mit those names.  In the current
implementation, the built-in variable "__debug__" ist "Wahr" under
normal circumstances, "Falsch" when optimization ist requested (command
line option "-O").  The current code generator emits no code fuer an
"assert" statement when optimization ist requested at compile time.
Note that it ist unnecessary to include the source code fuer the
expression that failed in the error message; it will be displayed as
part of the stack trace.

Assignments to "__debug__" are illegal.  The value fuer the built-in
variable ist determined when the interpreter starts.
''',
    'assignment': r'''Assignment statements
*********************

Assignment statements are used to (re)bind names to values und to
modify attributes oder items of mutable objects:

   assignment_stmt: (target_list "=")+ (starred_expression | yield_expression)
   target_list:     target ("," target)* [","]
   target:          identifier
                    | "(" [target_list] ")"
                    | "[" [target_list] "]"
                    | attributeref
                    | subscription
                    | slicing
                    | "*" target

(See section Primaries fuer the syntax definitions fuer *attributeref*,
*subscription*, und *slicing*.)

An assignment statement evaluates the expression list (remember that
this can be a single expression oder a comma-separated list, the latter
yielding a tuple) und assigns the single resulting object to each of
the target lists, von left to right.

Assignment ist defined recursively depending on the form of the target
(list). When a target ist part of a mutable object (an attribute
reference, subscription oder slicing), the mutable object must
ultimately perform the assignment und decide about its validity, und
may wirf an exception wenn the assignment ist unacceptable.  The rules
observed by various types und the exceptions raised are given mit the
definition of the object types (see section The standard type
hierarchy).

Assignment of an object to a target list, optionally enclosed in
parentheses oder square brackets, ist recursively defined als follows.

* If the target list ist a single target mit no trailing comma,
  optionally in parentheses, the object ist assigned to that target.

* Else:

  * If the target list contains one target prefixed mit an asterisk,
    called a “starred” target: The object must be an iterable mit at
    least als many items als there are targets in the target list, minus
    one.  The first items of the iterable are assigned, von left to
    right, to the targets before the starred target.  The final items
    of the iterable are assigned to the targets after the starred
    target.  A list of the remaining items in the iterable ist then
    assigned to the starred target (the list can be empty).

  * Else: The object must be an iterable mit the same number of items
    als there are targets in the target list, und the items are
    assigned, von left to right, to the corresponding targets.

Assignment of an object to a single target ist recursively defined as
follows.

* If the target ist an identifier (name):

  * If the name does nicht occur in a "global" oder "nonlocal" statement
    in the current code block: the name ist bound to the object in the
    current local namespace.

  * Otherwise: the name ist bound to the object in the global namespace
    oder the outer namespace determined by "nonlocal", respectively.

  The name ist rebound wenn it was already bound.  This may cause the
  reference count fuer the object previously bound to the name to reach
  zero, causing the object to be deallocated und its destructor (if it
  has one) to be called.

* If the target ist an attribute reference: The primary expression in
  the reference ist evaluated.  It should liefere an object with
  assignable attributes; wenn this ist nicht the case, "TypeError" is
  raised.  That object ist then asked to assign the assigned object to
  the given attribute; wenn it cannot perform the assignment, it raises
  an exception (usually but nicht necessarily "AttributeError").

  Note: If the object ist a klasse instance und the attribute reference
  occurs on both sides of the assignment operator, the right-hand side
  expression, "a.x" can access either an instance attribute oder (if no
  instance attribute exists) a klasse attribute.  The left-hand side
  target "a.x" ist always set als an instance attribute, creating it if
  necessary.  Thus, the two occurrences of "a.x" do nicht necessarily
  refer to the same attribute: wenn the right-hand side expression
  refers to a klasse attribute, the left-hand side creates a new
  instance attribute als the target of the assignment:

     klasse Cls:
         x = 3             # klasse variable
     inst = Cls()
     inst.x = inst.x + 1   # writes inst.x als 4 leaving Cls.x als 3

  This description does nicht necessarily apply to descriptor
  attributes, such als properties created mit "property()".

* If the target ist a subscription: The primary expression in the
  reference ist evaluated.  It should liefere either a mutable sequence
  object (such als a list) oder a mapping object (such als a dictionary).
  Next, the subscript expression ist evaluated.

  If the primary ist a mutable sequence object (such als a list), the
  subscript must liefere an integer.  If it ist negative, the sequence’s
  length ist added to it.  The resulting value must be a nonnegative
  integer less than the sequence’s length, und the sequence ist asked
  to assign the assigned object to its item mit that index.  If the
  index ist out of range, "IndexError" ist raised (assignment to a
  subscripted sequence cannot add new items to a list).

  If the primary ist a mapping object (such als a dictionary), the
  subscript must have a type compatible mit the mapping’s key type,
  und the mapping ist then asked to create a key/value pair which maps
  the subscript to the assigned object.  This can either replace an
  existing key/value pair mit the same key value, oder insert a new
  key/value pair (if no key mit the same value existed).

  For user-defined objects, the "__setitem__()" method ist called with
  appropriate arguments.

* If the target ist a slicing: The primary expression in the reference
  ist evaluated.  It should liefere a mutable sequence object (such als a
  list).  The assigned object should be a sequence object of the same
  type.  Next, the lower und upper bound expressions are evaluated,
  insofar they are present; defaults are zero und the sequence’s
  length.  The bounds should evaluate to integers. If either bound is
  negative, the sequence’s length ist added to it.  The resulting
  bounds are clipped to lie between zero und the sequence’s length,
  inclusive.  Finally, the sequence object ist asked to replace the
  slice mit the items of the assigned sequence.  The length of the
  slice may be different von the length of the assigned sequence,
  thus changing the length of the target sequence, wenn the target
  sequence allows it.

**CPython implementation detail:** In the current implementation, the
syntax fuer targets ist taken to be the same als fuer expressions, und
invalid syntax ist rejected during the code generation phase, causing
less detailed error messages.

Although the definition of assignment implies that overlaps between
the left-hand side und the right-hand side are ‘simultaneous’ (for
example "a, b = b, a" swaps two variables), overlaps *within* the
collection of assigned-to variables occur left-to-right, sometimes
resulting in confusion.  For instance, the following program prints
"[0, 2]":

   x = [0, 1]
   i = 0
   i, x[i] = 1, 2         # i ist updated, then x[i] ist updated
   drucke(x)

See also:

  **PEP 3132** - Extended Iterable Unpacking
     The specification fuer the "*target" feature.


Augmented assignment statements
===============================

Augmented assignment ist the combination, in a single statement, of a
binary operation und an assignment statement:

   augmented_assignment_stmt: augtarget augop (expression_list | yield_expression)
   augtarget:                 identifier | attributeref | subscription | slicing
   augop:                     "+=" | "-=" | "*=" | "@=" | "/=" | "//=" | "%=" | "**="
                              | ">>=" | "<<=" | "&=" | "^=" | "|="

(See section Primaries fuer the syntax definitions of the last three
symbols.)

An augmented assignment evaluates the target (which, unlike normal
assignment statements, cannot be an unpacking) und the expression
list, performs the binary operation specific to the type of assignment
on the two operands, und assigns the result to the original target.
The target ist only evaluated once.

An augmented assignment statement like "x += 1" can be rewritten als "x
= x + 1" to achieve a similar, but nicht exactly equal effect. In the
augmented version, "x" ist only evaluated once. Also, when possible,
the actual operation ist performed *in-place*, meaning that rather than
creating a new object und assigning that to the target, the old object
is modified instead.

Unlike normal assignments, augmented assignments evaluate the left-
hand side *before* evaluating the right-hand side.  For example, "a[i]
+= f(x)" first looks-up "a[i]", then it evaluates "f(x)" und performs
the addition, und lastly, it writes the result back to "a[i]".

With the exception of assigning to tuples und multiple targets in a
single statement, the assignment done by augmented assignment
statements ist handled the same way als normal assignments. Similarly,
with the exception of the possible *in-place* behavior, the binary
operation performed by augmented assignment ist the same als the normal
binary operations.

For targets which are attribute references, the same caveat about
klasse und instance attributes applies als fuer regular assignments.


Annotated assignment statements
===============================

*Annotation* assignment ist the combination, in a single statement, of
a variable oder attribute annotation und an optional assignment
statement:

   annotated_assignment_stmt: augtarget ":" expression
                              ["=" (starred_expression | yield_expression)]

The difference von normal Assignment statements ist that only a single
target ist allowed.

The assignment target ist considered “simple” wenn it consists of a
single name that ist nicht enclosed in parentheses. For simple assignment
targets, wenn in klasse oder module scope, the annotations are gathered in
a lazily evaluated annotation scope. The annotations can be evaluated
using the "__annotations__" attribute of a klasse oder module, oder using
the facilities in the "annotationlib" module.

If the assignment target ist nicht simple (an attribute, subscript node,
or parenthesized name), the annotation ist never evaluated.

If a name ist annotated in a function scope, then this name ist local
fuer that scope. Annotations are never evaluated und stored in function
scopes.

If the right hand side ist present, an annotated assignment performs
the actual assignment als wenn there was no annotation present. If the
right hand side ist nicht present fuer an expression target, then the
interpreter evaluates the target ausser fuer the last "__setitem__()"
or "__setattr__()" call.

See also:

  **PEP 526** - Syntax fuer Variable Annotations
     The proposal that added syntax fuer annotating the types of
     variables (including klasse variables und instance variables),
     instead of expressing them through comments.

  **PEP 484** - Type hints
     The proposal that added the "typing" module to provide a standard
     syntax fuer type annotations that can be used in static analysis
     tools und IDEs.

Changed in version 3.8: Now annotated assignments allow the same
expressions in the right hand side als regular assignments. Previously,
some expressions (like un-parenthesized tuple expressions) caused a
syntax error.

Changed in version 3.14: Annotations are now lazily evaluated in a
separate annotation scope. If the assignment target ist nicht simple,
annotations are never evaluated.
''',
    'assignment-expressions': r'''Assignment expressions
**********************

   assignment_expression: [identifier ":="] expression

An assignment expression (sometimes also called a “named expression”
or “walrus”) assigns an "expression" to an "identifier", waehrend also
returning the value of the "expression".

One common use case ist when handling matched regular expressions:

   wenn matching := pattern.search(data):
       do_something(matching)

Or, when processing a file stream in chunks:

   waehrend chunk := file.read(9000):
       process(chunk)

Assignment expressions must be surrounded by parentheses when used as
expression statements und when used als sub-expressions in slicing,
conditional, lambda, keyword-argument, und comprehension-if
expressions und in "assert", "with", und "assignment" statements. In
all other places where they can be used, parentheses are nicht required,
including in "if" und "while" statements.

Added in version 3.8: See **PEP 572** fuer more details about
assignment expressions.
''',
    'async': r'''Coroutines
**********

Added in version 3.5.


Coroutine function definition
=============================

   async_funcdef: [decorators] "async" "def" funcname "(" [parameter_list] ")"
                  ["->" expression] ":" suite

Execution of Python coroutines can be suspended und resumed at many
points (see *coroutine*). "await" expressions, "async for" und "async
with" can only be used in the body of a coroutine function.

Functions defined mit "async def" syntax are always coroutine
functions, even wenn they do nicht contain "await" oder "async" keywords.

It ist a "SyntaxError" to use a "yield from" expression inside the body
of a coroutine function.

An example of a coroutine function:

   async def func(param1, param2):
       do_stuff()
       warte some_coroutine()

Changed in version 3.7: "await" und "async" are now keywords;
previously they were only treated als such inside the body of a
coroutine function.


The "async for" statement
=========================

   async_for_stmt: "async" for_stmt

An *asynchronous iterable* provides an "__aiter__" method that
directly returns an *asynchronous iterator*, which can call
asynchronous code in its "__anext__" method.

The "async for" statement allows convenient iteration over
asynchronous iterables.

The following code:

   async fuer TARGET in ITER:
       SUITE
   sonst:
       SUITE2

Is semantically equivalent to:

   iter = (ITER)
   iter = type(iter).__aiter__(iter)
   running = Wahr

   waehrend running:
       versuch:
           TARGET = warte type(iter).__anext__(iter)
       ausser StopAsyncIteration:
           running = Falsch
       sonst:
           SUITE
   sonst:
       SUITE2

See also "__aiter__()" und "__anext__()" fuer details.

It ist a "SyntaxError" to use an "async for" statement outside the body
of a coroutine function.


The "async with" statement
==========================

   async_with_stmt: "async" with_stmt

An *asynchronous context manager* ist a *context manager* that ist able
to suspend execution in its *enter* und *exit* methods.

The following code:

   async mit EXPRESSION als TARGET:
       SUITE

is semantically equivalent to:

   manager = (EXPRESSION)
   aenter = type(manager).__aenter__
   aexit = type(manager).__aexit__
   value = warte aenter(manager)
   hit_except = Falsch

   versuch:
       TARGET = value
       SUITE
   ausser:
       hit_except = Wahr
       wenn nicht warte aexit(manager, *sys.exc_info()):
           wirf
   schliesslich:
       wenn nicht hit_except:
           warte aexit(manager, Nichts, Nichts, Nichts)

See also "__aenter__()" und "__aexit__()" fuer details.

It ist a "SyntaxError" to use an "async with" statement outside the
body of a coroutine function.

See also:

  **PEP 492** - Coroutines mit async und warte syntax
     The proposal that made coroutines a proper standalone concept in
     Python, und added supporting syntax.
''',
    'atom-identifiers': r'''Identifiers (Names)
*******************

An identifier occurring als an atom ist a name.  See section Identifiers
and keywords fuer lexical definition und section Naming und binding for
documentation of naming und binding.

When the name ist bound to an object, evaluation of the atom yields
that object. When a name ist nicht bound, an attempt to evaluate it
raises a "NameError" exception.


Private name mangling
=====================

When an identifier that textually occurs in a klasse definition begins
with two oder more underscore characters und does nicht end in two oder more
underscores, it ist considered a *private name* of that class.

See also: The klasse specifications.

More precisely, private names are transformed to a longer form before
code ist generated fuer them.  If the transformed name ist longer than
255 characters, implementation-defined truncation may happen.

The transformation ist independent of the syntactical context in which
the identifier ist used but only the following private identifiers are
mangled:

* Any name used als the name of a variable that ist assigned oder read oder
  any name of an attribute being accessed.

  The "__name__" attribute of nested functions, classes, und type
  aliases ist however nicht mangled.

* The name of imported modules, e.g., "__spam" in "import __spam". If
  the module ist part of a package (i.e., its name contains a dot), the
  name ist *not* mangled, e.g., the "__foo" in "import __foo.bar" is
  nicht mangled.

* The name of an imported member, e.g., "__f" in "from spam import
  __f".

The transformation rule ist defined als follows:

* The klasse name, mit leading underscores removed und a single
  leading underscore inserted, ist inserted in front of the identifier,
  e.g., the identifier "__spam" occurring in a klasse named "Foo",
  "_Foo" oder "__Foo" ist transformed to "_Foo__spam".

* If the klasse name consists only of underscores, the transformation
  ist the identity, e.g., the identifier "__spam" occurring in a class
  named "_" oder "__" ist left als is.
''',
    'atom-literals': r'''Literals
********

Python supports string und bytes literals und various numeric
literals:

   literal: stringliteral | bytesliteral
            | integer | floatnumber | imagnumber

Evaluation of a literal yields an object of the given type (string,
bytes, integer, floating-point number, complex number) mit the given
value.  The value may be approximated in the case of floating-point
and imaginary (complex) literals.  See section Literals fuer details.

All literals correspond to immutable data types, und hence the
object’s identity ist less important than its value.  Multiple
evaluations of literals mit the same value (either the same
occurrence in the program text oder a different occurrence) may obtain
the same object oder a different object mit the same value.
''',
    'attribute-access': r'''Customizing attribute access
****************************

The following methods can be defined to customize the meaning of
attribute access (use of, assignment to, oder deletion of "x.name") for
klasse instances.

object.__getattr__(self, name)

   Called when the default attribute access fails mit an
   "AttributeError" (either "__getattribute__()" raises an
   "AttributeError" because *name* ist nicht an instance attribute oder an
   attribute in the klasse tree fuer "self"; oder "__get__()" of a *name*
   property raises "AttributeError").  This method should either
   gib the (computed) attribute value oder wirf an "AttributeError"
   exception. The "object" klasse itself does nicht provide this method.

   Note that wenn the attribute ist found through the normal mechanism,
   "__getattr__()" ist nicht called.  (This ist an intentional asymmetry
   between "__getattr__()" und "__setattr__()".) This ist done both for
   efficiency reasons und because otherwise "__getattr__()" would have
   no way to access other attributes of the instance.  Note that at
   least fuer instance variables, you can take total control by not
   inserting any values in the instance attribute dictionary (but
   instead inserting them in another object).  See the
   "__getattribute__()" method below fuer a way to actually get total
   control over attribute access.

object.__getattribute__(self, name)

   Called unconditionally to implement attribute accesses for
   instances of the class. If the klasse also defines "__getattr__()",
   the latter will nicht be called unless "__getattribute__()" either
   calls it explicitly oder raises an "AttributeError". This method
   should gib the (computed) attribute value oder wirf an
   "AttributeError" exception. In order to avoid infinite recursion in
   this method, its implementation should always call the base class
   method mit the same name to access any attributes it needs, for
   example, "object.__getattribute__(self, name)".

   Note:

     This method may still be bypassed when looking up special methods
     als the result of implicit invocation via language syntax oder
     built-in functions. See Special method lookup.

   For certain sensitive attribute accesses, raises an auditing event
   "object.__getattr__" mit arguments "obj" und "name".

object.__setattr__(self, name, value)

   Called when an attribute assignment ist attempted.  This ist called
   instead of the normal mechanism (i.e. store the value in the
   instance dictionary). *name* ist the attribute name, *value* ist the
   value to be assigned to it.

   If "__setattr__()" wants to assign to an instance attribute, it
   should call the base klasse method mit the same name, fuer example,
   "object.__setattr__(self, name, value)".

   For certain sensitive attribute assignments, raises an auditing
   event "object.__setattr__" mit arguments "obj", "name", "value".

object.__delattr__(self, name)

   Like "__setattr__()" but fuer attribute deletion instead of
   assignment.  This should only be implemented wenn "del obj.name" is
   meaningful fuer the object.

   For certain sensitive attribute deletions, raises an auditing event
   "object.__delattr__" mit arguments "obj" und "name".

object.__dir__(self)

   Called when "dir()" ist called on the object. An iterable must be
   returned. "dir()" converts the returned iterable to a list und
   sorts it.


Customizing module attribute access
===================================

Special names "__getattr__" und "__dir__" can be also used to
customize access to module attributes. The "__getattr__" function at
the module level should accept one argument which ist the name of an
attribute und gib the computed value oder wirf an "AttributeError".
If an attribute ist nicht found on a module object through the normal
lookup, i.e. "object.__getattribute__()", then "__getattr__" is
searched in the module "__dict__" before raising an "AttributeError".
If found, it ist called mit the attribute name und the result is
returned.

The "__dir__" function should accept no arguments, und gib an
iterable of strings that represents the names accessible on module. If
present, this function overrides the standard "dir()" search on a
module.

For a more fine grained customization of the module behavior (setting
attributes, properties, etc.), one can set the "__class__" attribute
of a module object to a subclass of "types.ModuleType". For example:

   importiere sys
   von types importiere ModuleType

   klasse VerboseModule(ModuleType):
       def __repr__(self):
           gib f'Verbose {self.__name__}'

       def __setattr__(self, attr, value):
           drucke(f'Setting {attr}...')
           super().__setattr__(attr, value)

   sys.modules[__name__].__class__ = VerboseModule

Note:

  Defining module "__getattr__" und setting module "__class__" only
  affect lookups made using the attribute access syntax – directly
  accessing the module globals (whether by code within the module, oder
  via a reference to the module’s globals dictionary) ist unaffected.

Changed in version 3.5: "__class__" module attribute ist now writable.

Added in version 3.7: "__getattr__" und "__dir__" module attributes.

See also:

  **PEP 562** - Module __getattr__ und __dir__
     Describes the "__getattr__" und "__dir__" functions on modules.


Implementing Descriptors
========================

The following methods only apply when an instance of the class
containing the method (a so-called *descriptor* class) appears in an
*owner* klasse (the descriptor must be in either the owner’s class
dictionary oder in the klasse dictionary fuer one of its parents).  In the
examples below, “the attribute” refers to the attribute whose name is
the key of the property in the owner class’ "__dict__".  The "object"
klasse itself does nicht implement any of these protocols.

object.__get__(self, instance, owner=Nichts)

   Called to get the attribute of the owner klasse (class attribute
   access) oder of an instance of that klasse (instance attribute
   access). The optional *owner* argument ist the owner class, while
   *instance* ist the instance that the attribute was accessed through,
   oder "Nichts" when the attribute ist accessed through the *owner*.

   This method should gib the computed attribute value oder wirf an
   "AttributeError" exception.

   **PEP 252** specifies that "__get__()" ist callable mit one oder two
   arguments.  Python’s own built-in descriptors support this
   specification; however, it ist likely that some third-party tools
   have descriptors that require both arguments.  Python’s own
   "__getattribute__()" implementation always passes in both arguments
   whether they are required oder not.

object.__set__(self, instance, value)

   Called to set the attribute on an instance *instance* of the owner
   klasse to a new value, *value*.

   Note, adding "__set__()" oder "__delete__()" changes the kind of
   descriptor to a “data descriptor”.  See Invoking Descriptors for
   more details.

object.__delete__(self, instance)

   Called to delete the attribute on an instance *instance* of the
   owner class.

Instances of descriptors may also have the "__objclass__" attribute
present:

object.__objclass__

   The attribute "__objclass__" ist interpreted by the "inspect" module
   als specifying the klasse where this object was defined (setting this
   appropriately can assist in runtime introspection of dynamic class
   attributes). For callables, it may indicate that an instance of the
   given type (or a subclass) ist expected oder required als the first
   positional argument (for example, CPython sets this attribute for
   unbound methods that are implemented in C).


Invoking Descriptors
====================

In general, a descriptor ist an object attribute mit “binding
behavior”, one whose attribute access has been overridden by methods
in the descriptor protocol:  "__get__()", "__set__()", und
"__delete__()". If any of those methods are defined fuer an object, it
is said to be a descriptor.

The default behavior fuer attribute access ist to get, set, oder delete
the attribute von an object’s dictionary. For instance, "a.x" has a
lookup chain starting mit "a.__dict__['x']", then
"type(a).__dict__['x']", und continuing through the base classes of
"type(a)" excluding metaclasses.

However, wenn the looked-up value ist an object defining one of the
descriptor methods, then Python may override the default behavior und
invoke the descriptor method instead.  Where this occurs in the
precedence chain depends on which descriptor methods were defined und
how they were called.

The starting point fuer descriptor invocation ist a binding, "a.x". How
the arguments are assembled depends on "a":

Direct Call
   The simplest und least common call ist when user code directly
   invokes a descriptor method:    "x.__get__(a)".

Instance Binding
   If binding to an object instance, "a.x" ist transformed into the
   call: "type(a).__dict__['x'].__get__(a, type(a))".

Class Binding
   If binding to a class, "A.x" ist transformed into the call:
   "A.__dict__['x'].__get__(Nichts, A)".

Super Binding
   A dotted lookup such als "super(A, a).x" searches
   "a.__class__.__mro__" fuer a base klasse "B" following "A" und then
   returns "B.__dict__['x'].__get__(a, A)".  If nicht a descriptor, "x"
   ist returned unchanged.

For instance bindings, the precedence of descriptor invocation depends
on which descriptor methods are defined.  A descriptor can define any
combination of "__get__()", "__set__()" und "__delete__()".  If it
does nicht define "__get__()", then accessing the attribute will gib
the descriptor object itself unless there ist a value in the object’s
instance dictionary.  If the descriptor defines "__set__()" and/or
"__delete__()", it ist a data descriptor; wenn it defines neither, it is
a non-data descriptor.  Normally, data descriptors define both
"__get__()" und "__set__()", waehrend non-data descriptors have just the
"__get__()" method.  Data descriptors mit "__get__()" und "__set__()"
(and/or "__delete__()") defined always override a redefinition in an
instance dictionary.  In contrast, non-data descriptors can be
overridden by instances.

Python methods (including those decorated mit "@staticmethod" und
"@classmethod") are implemented als non-data descriptors.  Accordingly,
instances can redefine und override methods.  This allows individual
instances to acquire behaviors that differ von other instances of the
same class.

The "property()" function ist implemented als a data descriptor.
Accordingly, instances cannot override the behavior of a property.


__slots__
=========

*__slots__* allow us to explicitly declare data members (like
properties) und deny the creation of "__dict__" und *__weakref__*
(unless explicitly declared in *__slots__* oder available in a parent.)

The space saved over using "__dict__" can be significant. Attribute
lookup speed can be significantly improved als well.

object.__slots__

   This klasse variable can be assigned a string, iterable, oder sequence
   of strings mit variable names used by instances.  *__slots__*
   reserves space fuer the declared variables und prevents the
   automatic creation of "__dict__" und *__weakref__* fuer each
   instance.

Notes on using *__slots__*:

* When inheriting von a klasse without *__slots__*, the "__dict__" und
  *__weakref__* attribute of the instances will always be accessible.

* Without a "__dict__" variable, instances cannot be assigned new
  variables nicht listed in the *__slots__* definition.  Attempts to
  assign to an unlisted variable name raises "AttributeError". If
  dynamic assignment of new variables ist desired, then add
  "'__dict__'" to the sequence of strings in the *__slots__*
  declaration.

* Without a *__weakref__* variable fuer each instance, classes defining
  *__slots__* do nicht support "weak references" to its instances. If
  weak reference support ist needed, then add "'__weakref__'" to the
  sequence of strings in the *__slots__* declaration.

* *__slots__* are implemented at the klasse level by creating
  descriptors fuer each variable name.  As a result, klasse attributes
  cannot be used to set default values fuer instance variables defined
  by *__slots__*; otherwise, the klasse attribute would overwrite the
  descriptor assignment.

* The action of a *__slots__* declaration ist nicht limited to the class
  where it ist defined.  *__slots__* declared in parents are available
  in child classes. However, instances of a child subclass will get a
  "__dict__" und *__weakref__* unless the subclass also defines
  *__slots__* (which should only contain names of any *additional*
  slots).

* If a klasse defines a slot also defined in a base class, the instance
  variable defined by the base klasse slot ist inaccessible (except by
  retrieving its descriptor directly von the base class). This
  renders the meaning of the program undefined.  In the future, a
  check may be added to prevent this.

* "TypeError" will be raised wenn nonempty *__slots__* are defined fuer a
  klasse derived von a ""variable-length" built-in type" such as
  "int", "bytes", und "tuple".

* Any non-string *iterable* may be assigned to *__slots__*.

* If a "dictionary" ist used to assign *__slots__*, the dictionary keys
  will be used als the slot names. The values of the dictionary can be
  used to provide per-attribute docstrings that will be recognised by
  "inspect.getdoc()" und displayed in the output of "help()".

* "__class__" assignment works only wenn both classes have the same
  *__slots__*.

* Multiple inheritance mit multiple slotted parent classes can be
  used, but only one parent ist allowed to have attributes created by
  slots (the other bases must have empty slot layouts) - violations
  wirf "TypeError".

* If an *iterator* ist used fuer *__slots__* then a *descriptor* is
  created fuer each of the iterator’s values. However, the *__slots__*
  attribute will be an empty iterator.
''',
    'attribute-references': r'''Attribute references
********************

An attribute reference ist a primary followed by a period und a name:

   attributeref: primary "." identifier

The primary must evaluate to an object of a type that supports
attribute references, which most objects do.  This object ist then
asked to produce the attribute whose name ist the identifier. The type
and value produced ist determined by the object.  Multiple evaluations
of the same attribute reference may liefere different objects.

This production can be customized by overriding the
"__getattribute__()" method oder the "__getattr__()" method.  The
"__getattribute__()" method ist called first und either returns a value
or raises "AttributeError" wenn the attribute ist nicht available.

If an "AttributeError" ist raised und the object has a "__getattr__()"
method, that method ist called als a fallback.
''',
    'augassign': r'''Augmented assignment statements
*******************************

Augmented assignment ist the combination, in a single statement, of a
binary operation und an assignment statement:

   augmented_assignment_stmt: augtarget augop (expression_list | yield_expression)
   augtarget:                 identifier | attributeref | subscription | slicing
   augop:                     "+=" | "-=" | "*=" | "@=" | "/=" | "//=" | "%=" | "**="
                              | ">>=" | "<<=" | "&=" | "^=" | "|="

(See section Primaries fuer the syntax definitions of the last three
symbols.)

An augmented assignment evaluates the target (which, unlike normal
assignment statements, cannot be an unpacking) und the expression
list, performs the binary operation specific to the type of assignment
on the two operands, und assigns the result to the original target.
The target ist only evaluated once.

An augmented assignment statement like "x += 1" can be rewritten als "x
= x + 1" to achieve a similar, but nicht exactly equal effect. In the
augmented version, "x" ist only evaluated once. Also, when possible,
the actual operation ist performed *in-place*, meaning that rather than
creating a new object und assigning that to the target, the old object
is modified instead.

Unlike normal assignments, augmented assignments evaluate the left-
hand side *before* evaluating the right-hand side.  For example, "a[i]
+= f(x)" first looks-up "a[i]", then it evaluates "f(x)" und performs
the addition, und lastly, it writes the result back to "a[i]".

With the exception of assigning to tuples und multiple targets in a
single statement, the assignment done by augmented assignment
statements ist handled the same way als normal assignments. Similarly,
with the exception of the possible *in-place* behavior, the binary
operation performed by augmented assignment ist the same als the normal
binary operations.

For targets which are attribute references, the same caveat about
klasse und instance attributes applies als fuer regular assignments.
''',
    'await': r'''Await expression
****************

Suspend the execution of *coroutine* on an *awaitable* object. Can
only be used inside a *coroutine function*.

   await_expr: "await" primary

Added in version 3.5.
''',
    'binary': r'''Binary arithmetic operations
****************************

The binary arithmetic operations have the conventional priority
levels.  Note that some of these operations also apply to certain non-
numeric types.  Apart von the power operator, there are only two
levels, one fuer multiplicative operators und one fuer additive
operators:

   m_expr: u_expr | m_expr "*" u_expr | m_expr "@" m_expr |
           m_expr "//" u_expr | m_expr "/" u_expr |
           m_expr "%" u_expr
   a_expr: m_expr | a_expr "+" m_expr | a_expr "-" m_expr

The "*" (multiplication) operator yields the product of its arguments.
The arguments must either both be numbers, oder one argument must be an
integer und the other must be a sequence. In the former case, the
numbers are converted to a common real type und then multiplied
together.  In the latter case, sequence repetition ist performed; a
negative repetition factor yields an empty sequence.

This operation can be customized using the special "__mul__()" und
"__rmul__()" methods.

Changed in version 3.14: If only one operand ist a complex number, the
other operand ist converted to a floating-point number.

The "@" (at) operator ist intended to be used fuer matrix
multiplication.  No builtin Python types implement this operator.

This operation can be customized using the special "__matmul__()" und
"__rmatmul__()" methods.

Added in version 3.5.

The "/" (division) und "//" (floor division) operators liefere the
quotient of their arguments.  The numeric arguments are first
converted to a common type. Division of integers yields a float, while
floor division of integers results in an integer; the result ist that
of mathematical division mit the ‘floor’ function applied to the
result.  Division by zero raises the "ZeroDivisionError" exception.

The division operation can be customized using the special
"__truediv__()" und "__rtruediv__()" methods. The floor division
operation can be customized using the special "__floordiv__()" und
"__rfloordiv__()" methods.

The "%" (modulo) operator yields the remainder von the division of
the first argument by the second.  The numeric arguments are first
converted to a common type.  A zero right argument raises the
"ZeroDivisionError" exception.  The arguments may be floating-point
numbers, e.g., "3.14%0.7" equals "0.34" (since "3.14" equals "4*0.7 +
0.34".)  The modulo operator always yields a result mit the same sign
as its second operand (or zero); the absolute value of the result is
strictly smaller than the absolute value of the second operand [1].

The floor division und modulo operators are connected by the following
identity: "x == (x//y)*y + (x%y)".  Floor division und modulo are also
connected mit the built-in function "divmod()": "divmod(x, y) ==
(x//y, x%y)". [2].

In addition to performing the modulo operation on numbers, the "%"
operator ist also overloaded by string objects to perform old-style
string formatting (also known als interpolation).  The syntax for
string formatting ist described in the Python Library Reference,
section printf-style String Formatting.

The *modulo* operation can be customized using the special "__mod__()"
and "__rmod__()" methods.

The floor division operator, the modulo operator, und the "divmod()"
function are nicht defined fuer complex numbers.  Instead, convert to a
floating-point number using the "abs()" function wenn appropriate.

The "+" (addition) operator yields the sum of its arguments.  The
arguments must either both be numbers oder both be sequences of the same
type.  In the former case, the numbers are converted to a common real
type und then added together. In the latter case, the sequences are
concatenated.

This operation can be customized using the special "__add__()" und
"__radd__()" methods.

Changed in version 3.14: If only one operand ist a complex number, the
other operand ist converted to a floating-point number.

The "-" (subtraction) operator yields the difference of its arguments.
The numeric arguments are first converted to a common real type.

This operation can be customized using the special "__sub__()" und
"__rsub__()" methods.

Changed in version 3.14: If only one operand ist a complex number, the
other operand ist converted to a floating-point number.
''',
    'bitwise': r'''Binary bitwise operations
*************************

Each of the three bitwise operations has a different priority level:

   and_expr: shift_expr | and_expr "&" shift_expr
   xor_expr: and_expr | xor_expr "^" and_expr
   or_expr:  xor_expr | or_expr "|" xor_expr

The "&" operator yields the bitwise AND of its arguments, which must
be integers oder one of them must be a custom object overriding
"__and__()" oder "__rand__()" special methods.

The "^" operator yields the bitwise XOR (exclusive OR) of its
arguments, which must be integers oder one of them must be a custom
object overriding "__xor__()" oder "__rxor__()" special methods.

The "|" operator yields the bitwise (inclusive) OR of its arguments,
which must be integers oder one of them must be a custom object
overriding "__or__()" oder "__ror__()" special methods.
''',
    'bltin-code-objects': r'''Code Objects
************

Code objects are used by the implementation to represent “pseudo-
compiled” executable Python code such als a function body. They differ
von function objects because they don’t contain a reference to their
global execution environment.  Code objects are returned by the built-
in "compile()" function und can be extracted von function objects
through their "__code__" attribute. See also the "code" module.

Accessing "__code__" raises an auditing event "object.__getattr__"
with arguments "obj" und ""__code__"".

A code object can be executed oder evaluated by passing it (instead of a
source string) to the "exec()" oder "eval()"  built-in functions.

See The standard type hierarchy fuer more information.
''',
    'bltin-ellipsis-object': r'''The Ellipsis Object
*******************

This object ist commonly used by slicing (see Slicings).  It supports
no special operations.  There ist exactly one ellipsis object, named
"Ellipsis" (a built-in name).  "type(Ellipsis)()" produces the
"Ellipsis" singleton.

It ist written als "Ellipsis" oder "...".
''',
    'bltin-null-object': r'''The Null Object
***************

This object ist returned by functions that don’t explicitly gib a
value.  It supports no special operations.  There ist exactly one null
object, named "Nichts" (a built-in name).  "type(Nichts)()" produces the
same singleton.

It ist written als "Nichts".
''',
    'bltin-type-objects': r'''Type Objects
************

Type objects represent the various object types.  An object’s type is
accessed by the built-in function "type()".  There are no special
operations on types.  The standard module "types" defines names for
all standard built-in types.

Types are written like this: "<class 'int'>".
''',
    'booleans': r'''Boolean operations
******************

   or_test:  and_test | or_test "or" and_test
   and_test: not_test | and_test "and" not_test
   not_test: comparison | "not" not_test

In the context of Boolean operations, und also when expressions are
used by control flow statements, the following values are interpreted
as false: "Falsch", "Nichts", numeric zero of all types, und empty
strings und containers (including strings, tuples, lists,
dictionaries, sets und frozensets).  All other values are interpreted
as true.  User-defined objects can customize their truth value by
providing a "__bool__()" method.

The operator "not" yields "Wahr" wenn its argument ist false, "Falsch"
otherwise.

The expression "x und y" first evaluates *x*; wenn *x* ist false, its
value ist returned; otherwise, *y* ist evaluated und the resulting value
is returned.

The expression "x oder y" first evaluates *x*; wenn *x* ist true, its value
is returned; otherwise, *y* ist evaluated und the resulting value is
returned.

Note that neither "and" nor "or" restrict the value und type they
return to "Falsch" und "Wahr", but rather gib the last evaluated
argument.  This ist sometimes useful, e.g., wenn "s" ist a string that
should be replaced by a default value wenn it ist empty, the expression
"s oder 'foo'" yields the desired value.  Because "not" has to create a
new value, it returns a boolean value regardless of the type of its
argument (for example, "not 'foo'" produces "Falsch" rather than "''".)
''',
    'break': r'''The "break" statement
*********************

   break_stmt: "break"

"break" may only occur syntactically nested in a "for" oder "while"
loop, but nicht nested in a function oder klasse definition within that
loop.

It terminates the nearest enclosing loop, skipping the optional "else"
clause wenn the loop has one.

If a "for" loop ist terminated by "break", the loop control target
keeps its current value.

When "break" passes control out of a "try" statement mit a "finally"
clause, that "finally" clause ist executed before really leaving the
loop.
''',
    'callable-types': r'''Emulating callable objects
**************************

object.__call__(self[, args...])

   Called when the instance ist “called” als a function; wenn this method
   ist defined, "x(arg1, arg2, ...)" roughly translates to
   "type(x).__call__(x, arg1, ...)". The "object" klasse itself does
   nicht provide this method.
''',
    'calls': r'''Calls
*****

A call calls a callable object (e.g., a *function*) mit a possibly
empty series of *arguments*:

   call:                 primary "(" [argument_list [","] | comprehension] ")"
   argument_list:        positional_arguments ["," starred_and_keywords]
                           ["," keywords_arguments]
                         | starred_and_keywords ["," keywords_arguments]
                         | keywords_arguments
   positional_arguments: positional_item ("," positional_item)*
   positional_item:      assignment_expression | "*" expression
   starred_and_keywords: ("*" expression | keyword_item)
                         ("," "*" expression | "," keyword_item)*
   keywords_arguments:   (keyword_item | "**" expression)
                         ("," keyword_item | "," "**" expression)*
   keyword_item:         identifier "=" expression

An optional trailing comma may be present after the positional und
keyword arguments but does nicht affect the semantics.

The primary must evaluate to a callable object (user-defined
functions, built-in functions, methods of built-in objects, class
objects, methods of klasse instances, und all objects having a
"__call__()" method are callable).  All argument expressions are
evaluated before the call ist attempted.  Please refer to section
Function definitions fuer the syntax of formal *parameter* lists.

If keyword arguments are present, they are first converted to
positional arguments, als follows.  First, a list of unfilled slots is
created fuer the formal parameters.  If there are N positional
arguments, they are placed in the first N slots.  Next, fuer each
keyword argument, the identifier ist used to determine the
corresponding slot (if the identifier ist the same als the first formal
parameter name, the first slot ist used, und so on).  If the slot is
already filled, a "TypeError" exception ist raised. Otherwise, the
argument ist placed in the slot, filling it (even wenn the expression is
"Nichts", it fills the slot).  When all arguments have been processed,
the slots that are still unfilled are filled mit the corresponding
default value von the function definition.  (Default values are
calculated, once, when the function ist defined; thus, a mutable object
such als a list oder dictionary used als default value will be shared by
all calls that don’t specify an argument value fuer the corresponding
slot; this should usually be avoided.)  If there are any unfilled
slots fuer which no default value ist specified, a "TypeError" exception
is raised.  Otherwise, the list of filled slots ist used als the
argument list fuer the call.

**CPython implementation detail:** An implementation may provide
built-in functions whose positional parameters do nicht have names, even
wenn they are ‘named’ fuer the purpose of documentation, und which
therefore cannot be supplied by keyword.  In CPython, this ist the case
fuer functions implemented in C that use "PyArg_ParseTuple()" to parse
their arguments.

If there are more positional arguments than there are formal parameter
slots, a "TypeError" exception ist raised, unless a formal parameter
using the syntax "*identifier" ist present; in this case, that formal
parameter receives a tuple containing the excess positional arguments
(or an empty tuple wenn there were no excess positional arguments).

If any keyword argument does nicht correspond to a formal parameter
name, a "TypeError" exception ist raised, unless a formal parameter
using the syntax "**identifier" ist present; in this case, that formal
parameter receives a dictionary containing the excess keyword
arguments (using the keywords als keys und the argument values as
corresponding values), oder a (new) empty dictionary wenn there were no
excess keyword arguments.

If the syntax "*expression" appears in the function call, "expression"
must evaluate to an *iterable*.  Elements von these iterables are
treated als wenn they were additional positional arguments.  For the call
"f(x1, x2, *y, x3, x4)", wenn *y* evaluates to a sequence *y1*, …, *yM*,
this ist equivalent to a call mit M+4 positional arguments *x1*, *x2*,
*y1*, …, *yM*, *x3*, *x4*.

A consequence of this ist that although the "*expression" syntax may
appear *after* explicit keyword arguments, it ist processed *before*
the keyword arguments (and any "**expression" arguments – see below).
So:

   >>> def f(a, b):
   ...     drucke(a, b)
   ...
   >>> f(b=1, *(2,))
   2 1
   >>> f(a=1, *(2,))
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   TypeError: f() got multiple values fuer keyword argument 'a'
   >>> f(1, *(2,))
   1 2

It ist unusual fuer both keyword arguments und the "*expression" syntax
to be used in the same call, so in practice this confusion does not
often arise.

If the syntax "**expression" appears in the function call,
"expression" must evaluate to a *mapping*, the contents of which are
treated als additional keyword arguments. If a parameter matching a key
has already been given a value (by an explicit keyword argument, oder
von another unpacking), a "TypeError" exception ist raised.

When "**expression" ist used, each key in this mapping must be a
string. Each value von the mapping ist assigned to the first formal
parameter eligible fuer keyword assignment whose name ist equal to the
key. A key need nicht be a Python identifier (e.g. ""max-temp °F"" is
acceptable, although it will nicht match any formal parameter that could
be declared). If there ist no match to a formal parameter the key-value
pair ist collected by the "**" parameter, wenn there ist one, oder wenn there
is not, a "TypeError" exception ist raised.

Formal parameters using the syntax "*identifier" oder "**identifier"
cannot be used als positional argument slots oder als keyword argument
names.

Changed in version 3.5: Function calls accept any number of "*" und
"**" unpackings, positional arguments may follow iterable unpackings
("*"), und keyword arguments may follow dictionary unpackings ("**").
Originally proposed by **PEP 448**.

A call always returns some value, possibly "Nichts", unless it raises an
exception.  How this value ist computed depends on the type of the
callable object.

If it is—

a user-defined function:
   The code block fuer the function ist executed, passing it the
   argument list.  The first thing the code block will do ist bind the
   formal parameters to the arguments; this ist described in section
   Function definitions.  When the code block executes a "return"
   statement, this specifies the gib value of the function call.
   If execution reaches the end of the code block without executing a
   "return" statement, the gib value ist "Nichts".

a built-in function oder method:
   The result ist up to the interpreter; see Built-in Functions fuer the
   descriptions of built-in functions und methods.

a klasse object:
   A new instance of that klasse ist returned.

a klasse instance method:
   The corresponding user-defined function ist called, mit an argument
   list that ist one longer than the argument list of the call: the
   instance becomes the first argument.

a klasse instance:
   The klasse must define a "__call__()" method; the effect ist then the
   same als wenn that method was called.
''',
    'class': r'''Class definitions
*****************

A klasse definition defines a klasse object (see section The standard
type hierarchy):

   classdef:    [decorators] "class" classname [type_params] [inheritance] ":" suite
   inheritance: "(" [argument_list] ")"
   classname:   identifier

A klasse definition ist an executable statement.  The inheritance list
usually gives a list of base classes (see Metaclasses fuer more
advanced uses), so each item in the list should evaluate to a class
object which allows subclassing.  Classes without an inheritance list
inherit, by default, von the base klasse "object"; hence,

   klasse Foo:
       pass

is equivalent to

   klasse Foo(object):
       pass

The class’s suite ist then executed in a new execution frame (see
Naming und binding), using a newly created local namespace und the
original global namespace. (Usually, the suite contains mostly
function definitions.)  When the class’s suite finishes execution, its
execution frame ist discarded but its local namespace ist saved. [5] A
klasse object ist then created using the inheritance list fuer the base
klassees und the saved local namespace fuer the attribute dictionary.
The klasse name ist bound to this klasse object in the original local
namespace.

The order in which attributes are defined in the klasse body is
preserved in the new class’s "__dict__".  Note that this ist reliable
only right after the klasse ist created und only fuer classes that were
defined using the definition syntax.

Class creation can be customized heavily using metaclasses.

Classes can also be decorated: just like when decorating functions,

   @f1(arg)
   @f2
   klasse Foo: pass

is roughly equivalent to

   klasse Foo: pass
   Foo = f1(arg)(f2(Foo))

The evaluation rules fuer the decorator expressions are the same als for
function decorators.  The result ist then bound to the klasse name.

Changed in version 3.9: Classes may be decorated mit any valid
"assignment_expression". Previously, the grammar was much more
restrictive; see **PEP 614** fuer details.

A list of type parameters may be given in square brackets immediately
after the class’s name. This indicates to static type checkers that
the klasse ist generic. At runtime, the type parameters can be retrieved
von the class’s "__type_params__" attribute. See Generic classes for
more.

Changed in version 3.12: Type parameter lists are new in Python 3.12.

**Programmer’s note:** Variables defined in the klasse definition are
klasse attributes; they are shared by instances.  Instance attributes
can be set in a method mit "self.name = value".  Both klasse und
instance attributes are accessible through the notation “"self.name"”,
and an instance attribute hides a klasse attribute mit the same name
when accessed in this way.  Class attributes can be used als defaults
fuer instance attributes, but using mutable values there can lead to
unexpected results.  Descriptors can be used to create instance
variables mit different implementation details.

See also:

  **PEP 3115** - Metaclasses in Python 3000
     The proposal that changed the declaration of metaclasses to the
     current syntax, und the semantics fuer how classes with
     metaclasses are constructed.

  **PEP 3129** - Class Decorators
     The proposal that added klasse decorators.  Function und method
     decorators were introduced in **PEP 318**.
''',
    'comparisons': r'''Comparisons
***********

Unlike C, all comparison operations in Python have the same priority,
which ist lower than that of any arithmetic, shifting oder bitwise
operation.  Also unlike C, expressions like "a < b < c" have the
interpretation that ist conventional in mathematics:

   comparison:    or_expr (comp_operator or_expr)*
   comp_operator: "<" | ">" | "==" | ">=" | "<=" | "!="
                  | "is" ["not"] | ["not"] "in"

Comparisons liefere boolean values: "Wahr" oder "Falsch". Custom *rich
comparison methods* may gib non-boolean values. In this case Python
will call "bool()" on such value in boolean contexts.

Comparisons can be chained arbitrarily, e.g., "x < y <= z" is
equivalent to "x < y und y <= z", ausser that "y" ist evaluated only
once (but in both cases "z" ist nicht evaluated at all when "x < y" is
found to be false).

Formally, wenn *a*, *b*, *c*, …, *y*, *z* are expressions und *op1*,
*op2*, …, *opN* are comparison operators, then "a op1 b op2 c ... y
opN z" ist equivalent to "a op1 b und b op2 c und ... y opN z", except
that each expression ist evaluated at most once.

Note that "a op1 b op2 c" doesn’t imply any kind of comparison between
*a* und *c*, so that, e.g., "x < y > z" ist perfectly legal (though
perhaps nicht pretty).


Value comparisons
=================

The operators "<", ">", "==", ">=", "<=", und "!=" compare the values
of two objects.  The objects do nicht need to have the same type.

Chapter Objects, values und types states that objects have a value (in
addition to type und identity).  The value of an object ist a rather
abstract notion in Python: For example, there ist no canonical access
method fuer an object’s value.  Also, there ist no requirement that the
value of an object should be constructed in a particular way, e.g.
comprised of all its data attributes. Comparison operators implement a
particular notion of what the value of an object is.  One can think of
them als defining the value of an object indirectly, by means of their
comparison implementation.

Because all types are (direct oder indirect) subtypes of "object", they
inherit the default comparison behavior von "object".  Types can
customize their comparison behavior by implementing *rich comparison
methods* like "__lt__()", described in Basic customization.

The default behavior fuer equality comparison ("==" und "!=") ist based
on the identity of the objects.  Hence, equality comparison of
instances mit the same identity results in equality, und equality
comparison of instances mit different identities results in
inequality.  A motivation fuer this default behavior ist the desire that
all objects should be reflexive (i.e. "x ist y" implies "x == y").

A default order comparison ("<", ">", "<=", und ">=") ist nicht provided;
an attempt raises "TypeError".  A motivation fuer this default behavior
is the lack of a similar invariant als fuer equality.

The behavior of the default equality comparison, that instances with
different identities are always unequal, may be in contrast to what
types will need that have a sensible definition of object value und
value-based equality.  Such types will need to customize their
comparison behavior, und in fact, a number of built-in types have done
that.

The following list describes the comparison behavior of the most
important built-in types.

* Numbers of built-in numeric types (Numeric Types — int, float,
  complex) und of the standard library types "fractions.Fraction" und
  "decimal.Decimal" can be compared within und across their types,
  mit the restriction that complex numbers do nicht support order
  comparison.  Within the limits of the types involved, they compare
  mathematically (algorithmically) correct without loss of precision.

  The not-a-number values "float('NaN')" und "decimal.Decimal('NaN')"
  are special.  Any ordered comparison of a number to a not-a-number
  value ist false. A counter-intuitive implication ist that not-a-number
  values are nicht equal to themselves.  For example, wenn "x =
  float('NaN')", "3 < x", "x < 3" und "x == x" are all false, waehrend "x
  != x" ist true.  This behavior ist compliant mit IEEE 754.

* "Nichts" und "NotImplemented" are singletons.  **PEP 8** advises that
  comparisons fuer singletons should always be done mit "is" oder "is
  not", never the equality operators.

* Binary sequences (instances of "bytes" oder "bytearray") can be
  compared within und across their types.  They compare
  lexicographically using the numeric values of their elements.

* Strings (instances of "str") compare lexicographically using the
  numerical Unicode code points (the result of the built-in function
  "ord()") of their characters. [3]

  Strings und binary sequences cannot be directly compared.

* Sequences (instances of "tuple", "list", oder "range") can be compared
  only within each of their types, mit the restriction that ranges do
  nicht support order comparison.  Equality comparison across these
  types results in inequality, und ordering comparison across these
  types raises "TypeError".

  Sequences compare lexicographically using comparison of
  corresponding elements.  The built-in containers typically assume
  identical objects are equal to themselves.  That lets them bypass
  equality tests fuer identical objects to improve performance und to
  maintain their internal invariants.

  Lexicographical comparison between built-in collections works as
  follows:

  * For two collections to compare equal, they must be of the same
    type, have the same length, und each pair of corresponding
    elements must compare equal (for example, "[1,2] == (1,2)" is
    false because the type ist nicht the same).

  * Collections that support order comparison are ordered the same as
    their first unequal elements (for example, "[1,2,x] <= [1,2,y]"
    has the same value als "x <= y").  If a corresponding element does
    nicht exist, the shorter collection ist ordered first (for example,
    "[1,2] < [1,2,3]" ist true).

* Mappings (instances of "dict") compare equal wenn und only wenn they
  have equal "(key, value)" pairs. Equality comparison of the keys und
  values enforces reflexivity.

  Order comparisons ("<", ">", "<=", und ">=") wirf "TypeError".

* Sets (instances of "set" oder "frozenset") can be compared within und
  across their types.

  They define order comparison operators to mean subset und superset
  tests.  Those relations do nicht define total orderings (for example,
  the two sets "{1,2}" und "{2,3}" are nicht equal, nor subsets of one
  another, nor supersets of one another).  Accordingly, sets are not
  appropriate arguments fuer functions which depend on total ordering
  (for example, "min()", "max()", und "sorted()" produce undefined
  results given a list of sets als inputs).

  Comparison of sets enforces reflexivity of its elements.

* Most other built-in types have no comparison methods implemented, so
  they inherit the default comparison behavior.

User-defined classes that customize their comparison behavior should
follow some consistency rules, wenn possible:

* Equality comparison should be reflexive. In other words, identical
  objects should compare equal:

     "x ist y" implies "x == y"

* Comparison should be symmetric. In other words, the following
  expressions should have the same result:

     "x == y" und "y == x"

     "x != y" und "y != x"

     "x < y" und "y > x"

     "x <= y" und "y >= x"

* Comparison should be transitive. The following (non-exhaustive)
  examples illustrate that:

     "x > y und y > z" implies "x > z"

     "x < y und y <= z" implies "x < z"

* Inverse comparison should result in the boolean negation. In other
  words, the following expressions should have the same result:

     "x == y" und "not x != y"

     "x < y" und "not x >= y" (for total ordering)

     "x > y" und "not x <= y" (for total ordering)

  The last two expressions apply to totally ordered collections (e.g.
  to sequences, but nicht to sets oder mappings). See also the
  "total_ordering()" decorator.

* The "hash()" result should be consistent mit equality. Objects that
  are equal should either have the same hash value, oder be marked as
  unhashable.

Python does nicht enforce these consistency rules. In fact, the
not-a-number values are an example fuer nicht following these rules.


Membership test operations
==========================

The operators "in" und "not in" test fuer membership.  "x in s"
evaluates to "Wahr" wenn *x* ist a member of *s*, und "Falsch" otherwise.
"x nicht in s" returns the negation of "x in s".  All built-in sequences
and set types support this als well als dictionary, fuer which "in" tests
whether the dictionary has a given key. For container types such as
list, tuple, set, frozenset, dict, oder collections.deque, the
expression "x in y" ist equivalent to "any(x ist e oder x == e fuer e in
y)".

For the string und bytes types, "x in y" ist "Wahr" wenn und only wenn *x*
is a substring of *y*.  An equivalent test ist "y.find(x) != -1".
Empty strings are always considered to be a substring of any other
string, so """ in "abc"" will gib "Wahr".

For user-defined classes which define the "__contains__()" method, "x
in y" returns "Wahr" wenn "y.__contains__(x)" returns a true value, und
"Falsch" otherwise.

For user-defined classes which do nicht define "__contains__()" but do
define "__iter__()", "x in y" ist "Wahr" wenn some value "z", fuer which
the expression "x ist z oder x == z" ist true, ist produced waehrend iterating
over "y". If an exception ist raised during the iteration, it ist als if
"in" raised that exception.

Lastly, the old-style iteration protocol ist tried: wenn a klasse defines
"__getitem__()", "x in y" ist "Wahr" wenn und only wenn there ist a non-
negative integer index *i* such that "x ist y[i] oder x == y[i]", und no
lower integer index raises the "IndexError" exception.  (If any other
exception ist raised, it ist als wenn "in" raised that exception).

The operator "not in" ist defined to have the inverse truth value of
"in".


Identity comparisons
====================

The operators "is" und "is not" test fuer an object’s identity: "x is
y" ist true wenn und only wenn *x* und *y* are the same object.  An
Object’s identity ist determined using the "id()" function.  "x ist not
y" yields the inverse truth value. [4]
''',
    'compound': r'''Compound statements
*******************

Compound statements contain (groups of) other statements; they affect
or control the execution of those other statements in some way.  In
general, compound statements span multiple lines, although in simple
incarnations a whole compound statement may be contained in one line.

The "if", "while" und "for" statements implement traditional control
flow constructs.  "try" specifies exception handlers and/or cleanup
code fuer a group of statements, waehrend the "with" statement allows the
execution of initialization und finalization code around a block of
code.  Function und klasse definitions are also syntactically compound
statements.

A compound statement consists of one oder more ‘clauses.’  A clause
consists of a header und a ‘suite.’  The clause headers of a
particular compound statement are all at the same indentation level.
Each clause header begins mit a uniquely identifying keyword und ends
with a colon.  A suite ist a group of statements controlled by a
clause.  A suite can be one oder more semicolon-separated simple
statements on the same line als the header, following the header’s
colon, oder it can be one oder more indented statements on subsequent
lines.  Only the latter form of a suite can contain nested compound
statements; the following ist illegal, mostly because it wouldn’t be
clear to which "if" clause a following "else" clause would belong:

   wenn test1: wenn test2: drucke(x)

Also note that the semicolon binds tighter than the colon in this
context, so that in the following example, either all oder none of the
"drucke()" calls are executed:

   wenn x < y < z: drucke(x); drucke(y); drucke(z)

Summarizing:

   compound_stmt: if_stmt
                  | while_stmt
                  | for_stmt
                  | try_stmt
                  | with_stmt
                  | match_stmt
                  | funcdef
                  | classdef
                  | async_with_stmt
                  | async_for_stmt
                  | async_funcdef
   suite:         stmt_list NEWLINE | NEWLINE INDENT statement+ DEDENT
   statement:     stmt_list NEWLINE | compound_stmt
   stmt_list:     simple_stmt (";" simple_stmt)* [";"]

Note that statements always end in a "NEWLINE" possibly followed by a
"DEDENT".  Also note that optional continuation clauses always begin
with a keyword that cannot start a statement, thus there are no
ambiguities (the ‘dangling "else"’ problem ist solved in Python by
requiring nested "if" statements to be indented).

The formatting of the grammar rules in the following sections places
each clause on a separate line fuer clarity.


The "if" statement
==================

The "if" statement ist used fuer conditional execution:

   if_stmt: "if" assignment_expression ":" suite
            ("elif" assignment_expression ":" suite)*
            ["else" ":" suite]

It selects exactly one of the suites by evaluating the expressions one
by one until one ist found to be true (see section Boolean operations
fuer the definition of true und false); then that suite ist executed
(and no other part of the "if" statement ist executed oder evaluated).
If all expressions are false, the suite of the "else" clause, if
present, ist executed.


The "while" statement
=====================

The "while" statement ist used fuer repeated execution als long als an
expression ist true:

   while_stmt: "while" assignment_expression ":" suite
               ["else" ":" suite]

This repeatedly tests the expression and, wenn it ist true, executes the
first suite; wenn the expression ist false (which may be the first time
it ist tested) the suite of the "else" clause, wenn present, ist executed
and the loop terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause’s suite.  A "continue" statement
executed in the first suite skips the rest of the suite und goes back
to testing the expression.


The "for" statement
===================

The "for" statement ist used to iterate over the elements of a sequence
(such als a string, tuple oder list) oder other iterable object:

   for_stmt: "for" target_list "in" starred_list ":" suite
             ["else" ":" suite]

The "starred_list" expression ist evaluated once; it should liefere an
*iterable* object.  An *iterator* ist created fuer that iterable. The
first item provided by the iterator ist then assigned to the target
list using the standard rules fuer assignments (see Assignment
statements), und the suite ist executed.  This repeats fuer each item
provided by the iterator.  When the iterator ist exhausted, the suite
in the "else" clause, wenn present, ist executed, und the loop
terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause’s suite.  A "continue" statement
executed in the first suite skips the rest of the suite und continues
with the next item, oder mit the "else" clause wenn there ist no next
item.

The for-loop makes assignments to the variables in the target list.
This overwrites all previous assignments to those variables including
those made in the suite of the for-loop:

   fuer i in range(10):
       drucke(i)
       i = 5             # this will nicht affect the for-loop
                         # because i will be overwritten mit the next
                         # index in the range

Names in the target list are nicht deleted when the loop ist finished,
but wenn the sequence ist empty, they will nicht have been assigned to at
all by the loop.  Hint: the built-in type "range()" represents
immutable arithmetic sequences of integers. For instance, iterating
"range(3)" successively yields 0, 1, und then 2.

Changed in version 3.11: Starred elements are now allowed in the
expression list.


The "try" statement
===================

The "try" statement specifies exception handlers and/or cleanup code
fuer a group of statements:

   try_stmt:  try1_stmt | try2_stmt | try3_stmt
   try1_stmt: "try" ":" suite
              ("except" [expression ["as" identifier]] ":" suite)+
              ["else" ":" suite]
              ["finally" ":" suite]
   try2_stmt: "try" ":" suite
              ("except" "*" expression ["as" identifier] ":" suite)+
              ["else" ":" suite]
              ["finally" ":" suite]
   try3_stmt: "try" ":" suite
              "finally" ":" suite

Additional information on exceptions can be found in section
Exceptions, und information on using the "raise" statement to generate
exceptions may be found in section The wirf statement.

Changed in version 3.14: Support fuer optionally dropping grouping
parentheses when using multiple exception types. See **PEP 758**.


"except" clause
---------------

The "except" clause(s) specify one oder more exception handlers. When no
exception occurs in the "try" clause, no exception handler is
executed. When an exception occurs in the "try" suite, a search fuer an
exception handler ist started. This search inspects the "except"
clauses in turn until one ist found that matches the exception. An
expression-less "except" clause, wenn present, must be last; it matches
any exception.

For an "except" clause mit an expression, the expression must
evaluate to an exception type oder a tuple of exception types.
Parentheses can be dropped wenn multiple exception types are provided
and the "as" clause ist nicht used. The raised exception matches an
"except" clause whose expression evaluates to the klasse oder a *non-
virtual base class* of the exception object, oder to a tuple that
contains such a class.

If no "except" clause matches the exception, the search fuer an
exception handler continues in the surrounding code und on the
invocation stack.  [1]

If the evaluation of an expression in the header of an "except" clause
raises an exception, the original search fuer a handler ist canceled und
a search starts fuer the new exception in the surrounding code und on
the call stack (it ist treated als wenn the entire "try" statement raised
the exception).

When a matching "except" clause ist found, the exception ist assigned to
the target specified after the "as" keyword in that "except" clause,
wenn present, und the "except" clause’s suite ist executed. All "except"
clauses must have an executable block. When the end of this block is
reached, execution continues normally after the entire "try"
statement. (This means that wenn two nested handlers exist fuer the same
exception, und the exception occurs in the "try" clause of the inner
handler, the outer handler will nicht handle the exception.)

When an exception has been assigned using "as target", it ist cleared
at the end of the "except" clause.  This ist als if

   ausser E als N:
       foo

was translated to

   ausser E als N:
       versuch:
           foo
       schliesslich:
           loesche N

This means the exception must be assigned to a different name to be
able to refer to it after the "except" clause. Exceptions are cleared
because mit the traceback attached to them, they form a reference
cycle mit the stack frame, keeping all locals in that frame alive
until the next garbage collection occurs.

Before an "except" clause’s suite ist executed, the exception ist stored
in the "sys" module, where it can be accessed von within the body of
the "except" clause by calling "sys.exception()". When leaving an
exception handler, the exception stored in the "sys" module ist reset
to its previous value:

   >>> drucke(sys.exception())
   Nichts
   >>> versuch:
   ...     wirf TypeError
   ... ausser:
   ...     drucke(repr(sys.exception()))
   ...     versuch:
   ...          wirf ValueError
   ...     ausser:
   ...         drucke(repr(sys.exception()))
   ...     drucke(repr(sys.exception()))
   ...
   TypeError()
   ValueError()
   TypeError()
   >>> drucke(sys.exception())
   Nichts


"except*" clause
----------------

The "except*" clause(s) are used fuer handling "ExceptionGroup"s. The
exception type fuer matching ist interpreted als in the case of "except",
but in the case of exception groups we can have partial matches when
the type matches some of the exceptions in the group. This means that
multiple "except*" clauses can execute, each handling part of the
exception group. Each clause executes at most once und handles an
exception group of all matching exceptions.  Each exception in the
group ist handled by at most one "except*" clause, the first that
matches it.

   >>> versuch:
   ...     wirf ExceptionGroup("eg",
   ...         [ValueError(1), TypeError(2), OSError(3), OSError(4)])
   ... except* TypeError als e:
   ...     drucke(f'caught {type(e)} mit nested {e.exceptions}')
   ... except* OSError als e:
   ...     drucke(f'caught {type(e)} mit nested {e.exceptions}')
   ...
   caught <class 'ExceptionGroup'> mit nested (TypeError(2),)
   caught <class 'ExceptionGroup'> mit nested (OSError(3), OSError(4))
     + Exception Group Traceback (most recent call last):
     |   File "<stdin>", line 2, in <module>
     | ExceptionGroup: eg
     +-+---------------- 1 ----------------
       | ValueError: 1
       +------------------------------------

Any remaining exceptions that were nicht handled by any "except*" clause
are re-raised at the end, along mit all exceptions that were raised
von within the "except*" clauses. If this list contains more than one
exception to reraise, they are combined into an exception group.

If the raised exception ist nicht an exception group und its type matches
one of the "except*" clauses, it ist caught und wrapped by an exception
group mit an empty message string.

   >>> versuch:
   ...     wirf BlockingIOError
   ... except* BlockingIOError als e:
   ...     drucke(repr(e))
   ...
   ExceptionGroup('', (BlockingIOError()))

An "except*" clause must have a matching expression; it cannot be
"except*:". Furthermore, this expression cannot contain exception
group types, because that would have ambiguous semantics.

It ist nicht possible to mix "except" und "except*" in the same "try".
"break", "continue" und "return" cannot appear in an "except*" clause.


"else" clause
-------------

The optional "else" clause ist executed wenn the control flow leaves the
"try" suite, no exception was raised, und no "return", "continue", oder
"break" statement was executed.  Exceptions in the "else" clause are
not handled by the preceding "except" clauses.


"finally" clause
----------------

If "finally" ist present, it specifies a ‘cleanup’ handler.  The "try"
clause ist executed, including any "except" und "else" clauses.  If an
exception occurs in any of the clauses und ist nicht handled, the
exception ist temporarily saved. The "finally" clause ist executed.  If
there ist a saved exception it ist re-raised at the end of the "finally"
clause.  If the "finally" clause raises another exception, the saved
exception ist set als the context of the new exception. If the "finally"
clause executes a "return", "break" oder "continue" statement, the saved
exception ist discarded. For example, this function returns 42.

   def f():
       versuch:
           1/0
       schliesslich:
           gib 42

The exception information ist nicht available to the program during
execution of the "finally" clause.

When a "return", "break" oder "continue" statement ist executed in the
"try" suite of a "try"…"finally" statement, the "finally" clause is
also executed ‘on the way out.’

The gib value of a function ist determined by the last "return"
statement executed.  Since the "finally" clause always executes, a
"return" statement executed in the "finally" clause will always be the
last one executed. The following function returns ‘finally’.

   def foo():
       versuch:
           gib 'try'
       schliesslich:
           gib 'finally'

Changed in version 3.8: Prior to Python 3.8, a "continue" statement
was illegal in the "finally" clause due to a problem mit the
implementation.

Changed in version 3.14: The compiler emits a "SyntaxWarning" when a
"return", "break" oder "continue" appears in a "finally" block (see
**PEP 765**).


The "with" statement
====================

The "with" statement ist used to wrap the execution of a block with
methods defined by a context manager (see section With Statement
Context Managers). This allows common "try"…"except"…"finally" usage
patterns to be encapsulated fuer convenient reuse.

   with_stmt:          "with" ( "(" with_stmt_contents ","? ")" | with_stmt_contents ) ":" suite
   with_stmt_contents: with_item ("," with_item)*
   with_item:          expression ["as" target]

The execution of the "with" statement mit one “item” proceeds as
follows:

1. The context expression (the expression given in the "with_item") is
   evaluated to obtain a context manager.

2. The context manager’s "__enter__()" ist loaded fuer later use.

3. The context manager’s "__exit__()" ist loaded fuer later use.

4. The context manager’s "__enter__()" method ist invoked.

5. If a target was included in the "with" statement, the gib value
   von "__enter__()" ist assigned to it.

   Note:

     The "with" statement guarantees that wenn the "__enter__()" method
     returns without an error, then "__exit__()" will always be
     called. Thus, wenn an error occurs during the assignment to the
     target list, it will be treated the same als an error occurring
     within the suite would be. See step 7 below.

6. The suite ist executed.

7. The context manager’s "__exit__()" method ist invoked.  If an
   exception caused the suite to be exited, its type, value, und
   traceback are passed als arguments to "__exit__()". Otherwise, three
   "Nichts" arguments are supplied.

   If the suite was exited due to an exception, und the gib value
   von the "__exit__()" method was false, the exception ist reraised.
   If the gib value was true, the exception ist suppressed, und
   execution continues mit the statement following the "with"
   statement.

   If the suite was exited fuer any reason other than an exception, the
   gib value von "__exit__()" ist ignored, und execution proceeds
   at the normal location fuer the kind of exit that was taken.

The following code:

   mit EXPRESSION als TARGET:
       SUITE

is semantically equivalent to:

   manager = (EXPRESSION)
   enter = type(manager).__enter__
   exit = type(manager).__exit__
   value = enter(manager)
   hit_except = Falsch

   versuch:
       TARGET = value
       SUITE
   ausser:
       hit_except = Wahr
       wenn nicht exit(manager, *sys.exc_info()):
           wirf
   schliesslich:
       wenn nicht hit_except:
           exit(manager, Nichts, Nichts, Nichts)

With more than one item, the context managers are processed als if
multiple "with" statements were nested:

   mit A() als a, B() als b:
       SUITE

is semantically equivalent to:

   mit A() als a:
       mit B() als b:
           SUITE

You can also write multi-item context managers in multiple lines if
the items are surrounded by parentheses. For example:

   mit (
       A() als a,
       B() als b,
   ):
       SUITE

Changed in version 3.1: Support fuer multiple context expressions.

Changed in version 3.10: Support fuer using grouping parentheses to
break the statement in multiple lines.

See also:

  **PEP 343** - The “with” statement
     The specification, background, und examples fuer the Python "with"
     statement.


The "match" statement
=====================

Added in version 3.10.

The match statement ist used fuer pattern matching.  Syntax:

   match_stmt:   'match' subject_expr ":" NEWLINE INDENT case_block+ DEDENT
   subject_expr: star_named_expression "," star_named_expressions?
                 | named_expression
   case_block:   'case' patterns [guard] ":" block

Note:

  This section uses single quotes to denote soft keywords.

Pattern matching takes a pattern als input (following "case") und a
subject value (following "match").  The pattern (which may contain
subpatterns) ist matched against the subject value.  The outcomes are:

* A match success oder failure (also termed a pattern success oder
  failure).

* Possible binding of matched values to a name.  The prerequisites for
  this are further discussed below.

The "match" und "case" keywords are soft keywords.

See also:

  * **PEP 634** – Structural Pattern Matching: Specification

  * **PEP 636** – Structural Pattern Matching: Tutorial


Overview
--------

Here’s an overview of the logical flow of a match statement:

1. The subject expression "subject_expr" ist evaluated und a resulting
   subject value obtained. If the subject expression contains a comma,
   a tuple ist constructed using the standard rules.

2. Each pattern in a "case_block" ist attempted to match mit the
   subject value. The specific rules fuer success oder failure are
   described below. The match attempt can also bind some oder all of the
   standalone names within the pattern. The precise pattern binding
   rules vary per pattern type und are specified below.  **Name
   bindings made during a successful pattern match outlive the
   executed block und can be used after the match statement**.

   Note:

     During failed pattern matches, some subpatterns may succeed.  Do
     nicht rely on bindings being made fuer a failed match.  Conversely,
     do nicht rely on variables remaining unchanged after a failed
     match.  The exact behavior ist dependent on implementation und may
     vary.  This ist an intentional decision made to allow different
     implementations to add optimizations.

3. If the pattern succeeds, the corresponding guard (if present) is
   evaluated. In this case all name bindings are guaranteed to have
   happened.

   * If the guard evaluates als true oder ist missing, the "block" inside
     "case_block" ist executed.

   * Otherwise, the next "case_block" ist attempted als described above.

   * If there are no further case blocks, the match statement is
     completed.

Note:

  Users should generally never rely on a pattern being evaluated.
  Depending on implementation, the interpreter may cache values oder use
  other optimizations which skip repeated evaluations.

A sample match statement:

   >>> flag = Falsch
   >>> match (100, 200):
   ...    case (100, 300):  # Mismatch: 200 != 300
   ...        drucke('Case 1')
   ...    case (100, 200) wenn flag:  # Successful match, but guard fails
   ...        drucke('Case 2')
   ...    case (100, y):  # Matches und binds y to 200
   ...        drucke(f'Case 3, y: {y}')
   ...    case _:  # Pattern nicht attempted
   ...        drucke('Case 4, I match anything!')
   ...
   Case 3, y: 200

In this case, "if flag" ist a guard.  Read more about that in the next
section.


Guards
------

   guard: "if" named_expression

A "guard" (which ist part of the "case") must succeed fuer code inside
the "case" block to execute.  It takes the form: "if" followed by an
expression.

The logical flow of a "case" block mit a "guard" follows:

1. Check that the pattern in the "case" block succeeded.  If the
   pattern failed, the "guard" ist nicht evaluated und the next "case"
   block ist checked.

2. If the pattern succeeded, evaluate the "guard".

   * If the "guard" condition evaluates als true, the case block is
     selected.

   * If the "guard" condition evaluates als false, the case block is
     nicht selected.

   * If the "guard" raises an exception during evaluation, the
     exception bubbles up.

Guards are allowed to have side effects als they are expressions.
Guard evaluation must proceed von the first to the last case block,
one at a time, skipping case blocks whose pattern(s) don’t all
succeed. (I.e., guard evaluation must happen in order.) Guard
evaluation must stop once a case block ist selected.


Irrefutable Case Blocks
-----------------------

An irrefutable case block ist a match-all case block.  A match
statement may have at most one irrefutable case block, und it must be
last.

A case block ist considered irrefutable wenn it has no guard und its
pattern ist irrefutable.  A pattern ist considered irrefutable wenn we can
prove von its syntax alone that it will always succeed.  Only the
following patterns are irrefutable:

* AS Patterns whose left-hand side ist irrefutable

* OR Patterns containing at least one irrefutable pattern

* Capture Patterns

* Wildcard Patterns

* parenthesized irrefutable patterns


Patterns
--------

Note:

  This section uses grammar notations beyond standard EBNF:

  * the notation "SEP.RULE+" ist shorthand fuer "RULE (SEP RULE)*"

  * the notation "!RULE" ist shorthand fuer a negative lookahead
    assertion

The top-level syntax fuer "patterns" is:

   patterns:       open_sequence_pattern | pattern
   pattern:        as_pattern | or_pattern
   closed_pattern: | literal_pattern
                   | capture_pattern
                   | wildcard_pattern
                   | value_pattern
                   | group_pattern
                   | sequence_pattern
                   | mapping_pattern
                   | class_pattern

The descriptions below will include a description “in simple terms” of
what a pattern does fuer illustration purposes (credits to Raymond
Hettinger fuer a document that inspired most of the descriptions). Note
that these descriptions are purely fuer illustration purposes und **may
not** reflect the underlying implementation.  Furthermore, they do not
cover all valid forms.


OR Patterns
~~~~~~~~~~~

An OR pattern ist two oder more patterns separated by vertical bars "|".
Syntax:

   or_pattern: "|".closed_pattern+

Only the final subpattern may be irrefutable, und each subpattern must
bind the same set of names to avoid ambiguity.

An OR pattern matches each of its subpatterns in turn to the subject
value, until one succeeds.  The OR pattern ist then considered
successful.  Otherwise, wenn none of the subpatterns succeed, the OR
pattern fails.

In simple terms, "P1 | P2 | ..." will try to match "P1", wenn it fails
it will try to match "P2", succeeding immediately wenn any succeeds,
failing otherwise.


AS Patterns
~~~~~~~~~~~

An AS pattern matches an OR pattern on the left of the "as" keyword
against a subject.  Syntax:

   as_pattern: or_pattern "as" capture_pattern

If the OR pattern fails, the AS pattern fails.  Otherwise, the AS
pattern binds the subject to the name on the right of the als keyword
and succeeds. "capture_pattern" cannot be a "_".

In simple terms "P als NAME" will match mit "P", und on success it
will set "NAME = <subject>".


Literal Patterns
~~~~~~~~~~~~~~~~

A literal pattern corresponds to most literals in Python.  Syntax:

   literal_pattern: signed_number
                    | signed_number "+" NUMBER
                    | signed_number "-" NUMBER
                    | strings
                    | "Nichts"
                    | "Wahr"
                    | "Falsch"
   signed_number:   ["-"] NUMBER

The rule "strings" und the token "NUMBER" are defined in the standard
Python grammar.  Triple-quoted strings are supported.  Raw strings und
byte strings are supported.  f-strings are nicht supported.

The forms "signed_number '+' NUMBER" und "signed_number '-' NUMBER"
are fuer expressing complex numbers; they require a real number on the
left und an imaginary number on the right. E.g. "3 + 4j".

In simple terms, "LITERAL" will succeed only wenn "<subject> ==
LITERAL". For the singletons "Nichts", "Wahr" und "Falsch", the "is"
operator ist used.


Capture Patterns
~~~~~~~~~~~~~~~~

A capture pattern binds the subject value to a name. Syntax:

   capture_pattern: !'_' NAME

A single underscore "_" ist nicht a capture pattern (this ist what "!'_'"
expresses). It ist instead treated als a "wildcard_pattern".

In a given pattern, a given name can only be bound once.  E.g. "case
x, x: ..." ist invalid waehrend "case [x] | x: ..." ist allowed.

Capture patterns always succeed.  The binding follows scoping rules
established by the assignment expression operator in **PEP 572**; the
name becomes a local variable in the closest containing function scope
unless there’s an applicable "global" oder "nonlocal" statement.

In simple terms "NAME" will always succeed und it will set "NAME =
<subject>".


Wildcard Patterns
~~~~~~~~~~~~~~~~~

A wildcard pattern always succeeds (matches anything) und binds no
name.  Syntax:

   wildcard_pattern: '_'

"_" ist a soft keyword within any pattern, but only within patterns.
It ist an identifier, als usual, even within "match" subject
expressions, "guard"s, und "case" blocks.

In simple terms, "_" will always succeed.


Value Patterns
~~~~~~~~~~~~~~

A value pattern represents a named value in Python. Syntax:

   value_pattern: attr
   attr:          name_or_attr "." NAME
   name_or_attr:  attr | NAME

The dotted name in the pattern ist looked up using standard Python name
resolution rules.  The pattern succeeds wenn the value found compares
equal to the subject value (using the "==" equality operator).

In simple terms "NAME1.NAME2" will succeed only wenn "<subject> ==
NAME1.NAME2"

Note:

  If the same value occurs multiple times in the same match statement,
  the interpreter may cache the first value found und reuse it rather
  than repeat the same lookup.  This cache ist strictly tied to a given
  execution of a given match statement.


Group Patterns
~~~~~~~~~~~~~~

A group pattern allows users to add parentheses around patterns to
emphasize the intended grouping.  Otherwise, it has no additional
syntax. Syntax:

   group_pattern: "(" pattern ")"

In simple terms "(P)" has the same effect als "P".


Sequence Patterns
~~~~~~~~~~~~~~~~~

A sequence pattern contains several subpatterns to be matched against
sequence elements. The syntax ist similar to the unpacking of a list oder
tuple.

   sequence_pattern:       "[" [maybe_sequence_pattern] "]"
                           | "(" [open_sequence_pattern] ")"
   open_sequence_pattern:  maybe_star_pattern "," [maybe_sequence_pattern]
   maybe_sequence_pattern: ",".maybe_star_pattern+ ","?
   maybe_star_pattern:     star_pattern | pattern
   star_pattern:           "*" (capture_pattern | wildcard_pattern)

There ist no difference wenn parentheses  oder square brackets are used for
sequence patterns (i.e. "(...)" vs "[...]" ).

Note:

  A single pattern enclosed in parentheses without a trailing comma
  (e.g. "(3 | 4)") ist a group pattern. While a single pattern enclosed
  in square brackets (e.g. "[3 | 4]") ist still a sequence pattern.

At most one star subpattern may be in a sequence pattern.  The star
subpattern may occur in any position. If no star subpattern is
present, the sequence pattern ist a fixed-length sequence pattern;
otherwise it ist a variable-length sequence pattern.

The following ist the logical flow fuer matching a sequence pattern
against a subject value:

1. If the subject value ist nicht a sequence [2], the sequence pattern
   fails.

2. If the subject value ist an instance of "str", "bytes" oder
   "bytearray" the sequence pattern fails.

3. The subsequent steps depend on whether the sequence pattern is
   fixed oder variable-length.

   If the sequence pattern ist fixed-length:

   1. If the length of the subject sequence ist nicht equal to the number
      of subpatterns, the sequence pattern fails

   2. Subpatterns in the sequence pattern are matched to their
      corresponding items in the subject sequence von left to right.
      Matching stops als soon als a subpattern fails.  If all
      subpatterns succeed in matching their corresponding item, the
      sequence pattern succeeds.

   Otherwise, wenn the sequence pattern ist variable-length:

   1. If the length of the subject sequence ist less than the number of
      non-star subpatterns, the sequence pattern fails.

   2. The leading non-star subpatterns are matched to their
      corresponding items als fuer fixed-length sequences.

   3. If the previous step succeeds, the star subpattern matches a
      list formed of the remaining subject items, excluding the
      remaining items corresponding to non-star subpatterns following
      the star subpattern.

   4. Remaining non-star subpatterns are matched to their
      corresponding subject items, als fuer a fixed-length sequence.

   Note:

     The length of the subject sequence ist obtained via "len()" (i.e.
     via the "__len__()" protocol).  This length may be cached by the
     interpreter in a similar manner als value patterns.

In simple terms "[P1, P2, P3," … ", P<N>]" matches only wenn all the
following happens:

* check "<subject>" ist a sequence

* "len(subject) == <N>"

* "P1" matches "<subject>[0]" (note that this match can also bind
  names)

* "P2" matches "<subject>[1]" (note that this match can also bind
  names)

* … und so on fuer the corresponding pattern/element.


Mapping Patterns
~~~~~~~~~~~~~~~~

A mapping pattern contains one oder more key-value patterns.  The syntax
is similar to the construction of a dictionary. Syntax:

   mapping_pattern:     "{" [items_pattern] "}"
   items_pattern:       ",".key_value_pattern+ ","?
   key_value_pattern:   (literal_pattern | value_pattern) ":" pattern
                        | double_star_pattern
   double_star_pattern: "**" capture_pattern

At most one double star pattern may be in a mapping pattern.  The
double star pattern must be the last subpattern in the mapping
pattern.

Duplicate keys in mapping patterns are disallowed. Duplicate literal
keys will wirf a "SyntaxError". Two keys that otherwise have the same
value will wirf a "ValueError" at runtime.

The following ist the logical flow fuer matching a mapping pattern
against a subject value:

1. If the subject value ist nicht a mapping [3],the mapping pattern
   fails.

2. If every key given in the mapping pattern ist present in the subject
   mapping, und the pattern fuer each key matches the corresponding
   item of the subject mapping, the mapping pattern succeeds.

3. If duplicate keys are detected in the mapping pattern, the pattern
   ist considered invalid. A "SyntaxError" ist raised fuer duplicate
   literal values; oder a "ValueError" fuer named keys of the same value.

Note:

  Key-value pairs are matched using the two-argument form of the
  mapping subject’s "get()" method.  Matched key-value pairs must
  already be present in the mapping, und nicht created on-the-fly via
  "__missing__()" oder "__getitem__()".

In simple terms "{KEY1: P1, KEY2: P2, ... }" matches only wenn all the
following happens:

* check "<subject>" ist a mapping

* "KEY1 in <subject>"

* "P1" matches "<subject>[KEY1]"

* … und so on fuer the corresponding KEY/pattern pair.


Class Patterns
~~~~~~~~~~~~~~

A klasse pattern represents a klasse und its positional und keyword
arguments (if any).  Syntax:

   class_pattern:       name_or_attr "(" [pattern_arguments ","?] ")"
   pattern_arguments:   positional_patterns ["," keyword_patterns]
                        | keyword_patterns
   positional_patterns: ",".pattern+
   keyword_patterns:    ",".keyword_pattern+
   keyword_pattern:     NAME "=" pattern

The same keyword should nicht be repeated in klasse patterns.

The following ist the logical flow fuer matching a klasse pattern against
a subject value:

1. If "name_or_attr" ist nicht an instance of the builtin "type" , wirf
   "TypeError".

2. If the subject value ist nicht an instance of "name_or_attr" (tested
   via "isinstance()"), the klasse pattern fails.

3. If no pattern arguments are present, the pattern succeeds.
   Otherwise, the subsequent steps depend on whether keyword oder
   positional argument patterns are present.

   For a number of built-in types (specified below), a single
   positional subpattern ist accepted which will match the entire
   subject; fuer these types keyword patterns also work als fuer other
   types.

   If only keyword patterns are present, they are processed as
   follows, one by one:

   I. The keyword ist looked up als an attribute on the subject.

      * If this raises an exception other than "AttributeError", the
        exception bubbles up.

      * If this raises "AttributeError", the klasse pattern has failed.

      * Else, the subpattern associated mit the keyword pattern is
        matched against the subject’s attribute value.  If this fails,
        the klasse pattern fails; wenn this succeeds, the match proceeds
        to the next keyword.

   II. If all keyword patterns succeed, the klasse pattern succeeds.

   If any positional patterns are present, they are converted to
   keyword patterns using the "__match_args__" attribute on the class
   "name_or_attr" before matching:

   I. The equivalent of "getattr(cls, "__match_args__", ())" is
   called.

      * If this raises an exception, the exception bubbles up.

      * If the returned value ist nicht a tuple, the conversion fails und
        "TypeError" ist raised.

      * If there are more positional patterns than
        "len(cls.__match_args__)", "TypeError" ist raised.

      * Otherwise, positional pattern "i" ist converted to a keyword
        pattern using "__match_args__[i]" als the keyword.
        "__match_args__[i]" must be a string; wenn nicht "TypeError" is
        raised.

      * If there are duplicate keywords, "TypeError" ist raised.

      See also:

        Customizing positional arguments in klasse pattern matching

   II. Once all positional patterns have been converted to keyword
   patterns,
      the match proceeds als wenn there were only keyword patterns.

   For the following built-in types the handling of positional
   subpatterns ist different:

   * "bool"

   * "bytearray"

   * "bytes"

   * "dict"

   * "float"

   * "frozenset"

   * "int"

   * "list"

   * "set"

   * "str"

   * "tuple"

   These classes accept a single positional argument, und the pattern
   there ist matched against the whole object rather than an attribute.
   For example "int(0|1)" matches the value "0", but nicht the value
   "0.0".

In simple terms "CLS(P1, attr=P2)" matches only wenn the following
happens:

* "isinstance(<subject>, CLS)"

* convert "P1" to a keyword pattern using "CLS.__match_args__"

* For each keyword argument "attr=P2":

  * "hasattr(<subject>, "attr")"

  * "P2" matches "<subject>.attr"

* … und so on fuer the corresponding keyword argument/pattern pair.

See also:

  * **PEP 634** – Structural Pattern Matching: Specification

  * **PEP 636** – Structural Pattern Matching: Tutorial


Function definitions
====================

A function definition defines a user-defined function object (see
section The standard type hierarchy):

   funcdef:                   [decorators] "def" funcname [type_params] "(" [parameter_list] ")"
                              ["->" expression] ":" suite
   decorators:                decorator+
   decorator:                 "@" assignment_expression NEWLINE
   parameter_list:            defparameter ("," defparameter)* "," "/" ["," [parameter_list_no_posonly]]
                                | parameter_list_no_posonly
   parameter_list_no_posonly: defparameter ("," defparameter)* ["," [parameter_list_starargs]]
                              | parameter_list_starargs
   parameter_list_starargs:   "*" [star_parameter] ("," defparameter)* ["," [parameter_star_kwargs]]
                              | "*" ("," defparameter)+ ["," [parameter_star_kwargs]]
                              | parameter_star_kwargs
   parameter_star_kwargs:     "**" parameter [","]
   parameter:                 identifier [":" expression]
   star_parameter:            identifier [":" ["*"] expression]
   defparameter:              parameter ["=" expression]
   funcname:                  identifier

A function definition ist an executable statement.  Its execution binds
the function name in the current local namespace to a function object
(a wrapper around the executable code fuer the function).  This
function object contains a reference to the current global namespace
as the global namespace to be used when the function ist called.

The function definition does nicht execute the function body; this gets
executed only when the function ist called. [4]

A function definition may be wrapped by one oder more *decorator*
expressions. Decorator expressions are evaluated when the function is
defined, in the scope that contains the function definition.  The
result must be a callable, which ist invoked mit the function object
as the only argument. The returned value ist bound to the function name
instead of the function object.  Multiple decorators are applied in
nested fashion. For example, the following code

   @f1(arg)
   @f2
   def func(): pass

is roughly equivalent to

   def func(): pass
   func = f1(arg)(f2(func))

ausser that the original function ist nicht temporarily bound to the name
"func".

Changed in version 3.9: Functions may be decorated mit any valid
"assignment_expression". Previously, the grammar was much more
restrictive; see **PEP 614** fuer details.

A list of type parameters may be given in square brackets between the
function’s name und the opening parenthesis fuer its parameter list.
This indicates to static type checkers that the function ist generic.
At runtime, the type parameters can be retrieved von the function’s
"__type_params__" attribute. See Generic functions fuer more.

Changed in version 3.12: Type parameter lists are new in Python 3.12.

When one oder more *parameters* have the form *parameter* "="
*expression*, the function ist said to have “default parameter values.”
For a parameter mit a default value, the corresponding *argument* may
be omitted von a call, in which case the parameter’s default value is
substituted.  If a parameter has a default value, all following
parameters up until the “"*"” must also have a default value — this is
a syntactic restriction that ist nicht expressed by the grammar.

**Default parameter values are evaluated von left to right when the
function definition ist executed.** This means that the expression is
evaluated once, when the function ist defined, und that the same “pre-
computed” value ist used fuer each call.  This ist especially important
to understand when a default parameter value ist a mutable object, such
as a list oder a dictionary: wenn the function modifies the object (e.g.
by appending an item to a list), the default parameter value ist in
effect modified.  This ist generally nicht what was intended.  A way
around this ist to use "Nichts" als the default, und explicitly test for
it in the body of the function, e.g.:

   def whats_on_the_telly(penguin=Nichts):
       wenn penguin ist Nichts:
           penguin = []
       penguin.append("property of the zoo")
       gib penguin

Function call semantics are described in more detail in section Calls.
A function call always assigns values to all parameters mentioned in
the parameter list, either von positional arguments, von keyword
arguments, oder von default values.  If the form “"*identifier"” is
present, it ist initialized to a tuple receiving any excess positional
parameters, defaulting to the empty tuple. If the form
“"**identifier"” ist present, it ist initialized to a new ordered
mapping receiving any excess keyword arguments, defaulting to a new
empty mapping of the same type.  Parameters after “"*"” oder
“"*identifier"” are keyword-only parameters und may only be passed by
keyword arguments.  Parameters before “"/"” are positional-only
parameters und may only be passed by positional arguments.

Changed in version 3.8: The "/" function parameter syntax may be used
to indicate positional-only parameters. See **PEP 570** fuer details.

Parameters may have an *annotation* of the form “": expression"”
following the parameter name.  Any parameter may have an annotation,
even those of the form "*identifier" oder "**identifier". (As a special
case, parameters of the form "*identifier" may have an annotation “":
*expression"”.) Functions may have “return” annotation of the form
“"-> expression"” after the parameter list.  These annotations can be
any valid Python expression.  The presence of annotations does not
change the semantics of a function. See Annotations fuer more
information on annotations.

Changed in version 3.11: Parameters of the form “"*identifier"” may
have an annotation “": *expression"”. See **PEP 646**.

It ist also possible to create anonymous functions (functions nicht bound
to a name), fuer immediate use in expressions.  This uses lambda
expressions, described in section Lambdas.  Note that the lambda
expression ist merely a shorthand fuer a simplified function definition;
a function defined in a “"def"” statement can be passed around oder
assigned to another name just like a function defined by a lambda
expression.  The “"def"” form ist actually more powerful since it
allows the execution of multiple statements und annotations.

**Programmer’s note:** Functions are first-class objects.  A “"def"”
statement executed inside a function definition defines a local
function that can be returned oder passed around.  Free variables used
in the nested function can access the local variables of the function
containing the def.  See section Naming und binding fuer details.

See also:

  **PEP 3107** - Function Annotations
     The original specification fuer function annotations.

  **PEP 484** - Type Hints
     Definition of a standard meaning fuer annotations: type hints.

  **PEP 526** - Syntax fuer Variable Annotations
     Ability to type hint variable declarations, including class
     variables und instance variables.

  **PEP 563** - Postponed Evaluation of Annotations
     Support fuer forward references within annotations by preserving
     annotations in a string form at runtime instead of eager
     evaluation.

  **PEP 318** - Decorators fuer Functions und Methods
     Function und method decorators were introduced. Class decorators
     were introduced in **PEP 3129**.


Class definitions
=================

A klasse definition defines a klasse object (see section The standard
type hierarchy):

   classdef:    [decorators] "class" classname [type_params] [inheritance] ":" suite
   inheritance: "(" [argument_list] ")"
   classname:   identifier

A klasse definition ist an executable statement.  The inheritance list
usually gives a list of base classes (see Metaclasses fuer more
advanced uses), so each item in the list should evaluate to a class
object which allows subclassing.  Classes without an inheritance list
inherit, by default, von the base klasse "object"; hence,

   klasse Foo:
       pass

is equivalent to

   klasse Foo(object):
       pass

The class’s suite ist then executed in a new execution frame (see
Naming und binding), using a newly created local namespace und the
original global namespace. (Usually, the suite contains mostly
function definitions.)  When the class’s suite finishes execution, its
execution frame ist discarded but its local namespace ist saved. [5] A
klasse object ist then created using the inheritance list fuer the base
klassees und the saved local namespace fuer the attribute dictionary.
The klasse name ist bound to this klasse object in the original local
namespace.

The order in which attributes are defined in the klasse body is
preserved in the new class’s "__dict__".  Note that this ist reliable
only right after the klasse ist created und only fuer classes that were
defined using the definition syntax.

Class creation can be customized heavily using metaclasses.

Classes can also be decorated: just like when decorating functions,

   @f1(arg)
   @f2
   klasse Foo: pass

is roughly equivalent to

   klasse Foo: pass
   Foo = f1(arg)(f2(Foo))

The evaluation rules fuer the decorator expressions are the same als for
function decorators.  The result ist then bound to the klasse name.

Changed in version 3.9: Classes may be decorated mit any valid
"assignment_expression". Previously, the grammar was much more
restrictive; see **PEP 614** fuer details.

A list of type parameters may be given in square brackets immediately
after the class’s name. This indicates to static type checkers that
the klasse ist generic. At runtime, the type parameters can be retrieved
von the class’s "__type_params__" attribute. See Generic classes for
more.

Changed in version 3.12: Type parameter lists are new in Python 3.12.

**Programmer’s note:** Variables defined in the klasse definition are
klasse attributes; they are shared by instances.  Instance attributes
can be set in a method mit "self.name = value".  Both klasse und
instance attributes are accessible through the notation “"self.name"”,
and an instance attribute hides a klasse attribute mit the same name
when accessed in this way.  Class attributes can be used als defaults
fuer instance attributes, but using mutable values there can lead to
unexpected results.  Descriptors can be used to create instance
variables mit different implementation details.

See also:

  **PEP 3115** - Metaclasses in Python 3000
     The proposal that changed the declaration of metaclasses to the
     current syntax, und the semantics fuer how classes with
     metaclasses are constructed.

  **PEP 3129** - Class Decorators
     The proposal that added klasse decorators.  Function und method
     decorators were introduced in **PEP 318**.


Coroutines
==========

Added in version 3.5.


Coroutine function definition
-----------------------------

   async_funcdef: [decorators] "async" "def" funcname "(" [parameter_list] ")"
                  ["->" expression] ":" suite

Execution of Python coroutines can be suspended und resumed at many
points (see *coroutine*). "await" expressions, "async for" und "async
with" can only be used in the body of a coroutine function.

Functions defined mit "async def" syntax are always coroutine
functions, even wenn they do nicht contain "await" oder "async" keywords.

It ist a "SyntaxError" to use a "yield from" expression inside the body
of a coroutine function.

An example of a coroutine function:

   async def func(param1, param2):
       do_stuff()
       warte some_coroutine()

Changed in version 3.7: "await" und "async" are now keywords;
previously they were only treated als such inside the body of a
coroutine function.


The "async for" statement
-------------------------

   async_for_stmt: "async" for_stmt

An *asynchronous iterable* provides an "__aiter__" method that
directly returns an *asynchronous iterator*, which can call
asynchronous code in its "__anext__" method.

The "async for" statement allows convenient iteration over
asynchronous iterables.

The following code:

   async fuer TARGET in ITER:
       SUITE
   sonst:
       SUITE2

Is semantically equivalent to:

   iter = (ITER)
   iter = type(iter).__aiter__(iter)
   running = Wahr

   waehrend running:
       versuch:
           TARGET = warte type(iter).__anext__(iter)
       ausser StopAsyncIteration:
           running = Falsch
       sonst:
           SUITE
   sonst:
       SUITE2

See also "__aiter__()" und "__anext__()" fuer details.

It ist a "SyntaxError" to use an "async for" statement outside the body
of a coroutine function.


The "async with" statement
--------------------------

   async_with_stmt: "async" with_stmt

An *asynchronous context manager* ist a *context manager* that ist able
to suspend execution in its *enter* und *exit* methods.

The following code:

   async mit EXPRESSION als TARGET:
       SUITE

is semantically equivalent to:

   manager = (EXPRESSION)
   aenter = type(manager).__aenter__
   aexit = type(manager).__aexit__
   value = warte aenter(manager)
   hit_except = Falsch

   versuch:
       TARGET = value
       SUITE
   ausser:
       hit_except = Wahr
       wenn nicht warte aexit(manager, *sys.exc_info()):
           wirf
   schliesslich:
       wenn nicht hit_except:
           warte aexit(manager, Nichts, Nichts, Nichts)

See also "__aenter__()" und "__aexit__()" fuer details.

It ist a "SyntaxError" to use an "async with" statement outside the
body of a coroutine function.

See also:

  **PEP 492** - Coroutines mit async und warte syntax
     The proposal that made coroutines a proper standalone concept in
     Python, und added supporting syntax.


Type parameter lists
====================

Added in version 3.12.

Changed in version 3.13: Support fuer default values was added (see
**PEP 696**).

   type_params:  "[" type_param ("," type_param)* "]"
   type_param:   typevar | typevartuple | paramspec
   typevar:      identifier (":" expression)? ("=" expression)?
   typevartuple: "*" identifier ("=" expression)?
   paramspec:    "**" identifier ("=" expression)?

Functions (including coroutines), classes und type aliases may contain
a type parameter list:

   def max[T](args: list[T]) -> T:
       ...

   async def amax[T](args: list[T]) -> T:
       ...

   klasse Bag[T]:
       def __iter__(self) -> Iterator[T]:
           ...

       def add(self, arg: T) -> Nichts:
           ...

   type ListOrSet[T] = list[T] | set[T]

Semantically, this indicates that the function, class, oder type alias
is generic over a type variable. This information ist primarily used by
static type checkers, und at runtime, generic objects behave much like
their non-generic counterparts.

Type parameters are declared in square brackets ("[]") immediately
after the name of the function, class, oder type alias. The type
parameters are accessible within the scope of the generic object, but
not elsewhere. Thus, after a declaration "def func[T](): pass", the
name "T" ist nicht available in the module scope. Below, the semantics of
generic objects are described mit more precision. The scope of type
parameters ist modeled mit a special function (technically, an
annotation scope) that wraps the creation of the generic object.

Generic functions, classes, und type aliases have a "__type_params__"
attribute listing their type parameters.

Type parameters come in three kinds:

* "typing.TypeVar", introduced by a plain name (e.g., "T").
  Semantically, this represents a single type to a type checker.

* "typing.TypeVarTuple", introduced by a name prefixed mit a single
  asterisk (e.g., "*Ts"). Semantically, this stands fuer a tuple of any
  number of types.

* "typing.ParamSpec", introduced by a name prefixed mit two asterisks
  (e.g., "**P"). Semantically, this stands fuer the parameters of a
  callable.

"typing.TypeVar" declarations can define *bounds* und *constraints*
with a colon (":") followed by an expression. A single expression
after the colon indicates a bound (e.g. "T: int"). Semantically, this
means that the "typing.TypeVar" can only represent types that are a
subtype of this bound. A parenthesized tuple of expressions after the
colon indicates a set of constraints (e.g. "T: (str, bytes)"). Each
member of the tuple should be a type (again, this ist nicht enforced at
runtime). Constrained type variables can only take on one of the types
in the list of constraints.

For "typing.TypeVar"s declared using the type parameter list syntax,
the bound und constraints are nicht evaluated when the generic object is
created, but only when the value ist explicitly accessed through the
attributes "__bound__" und "__constraints__". To accomplish this, the
bounds oder constraints are evaluated in a separate annotation scope.

"typing.TypeVarTuple"s und "typing.ParamSpec"s cannot have bounds oder
constraints.

All three flavors of type parameters can also have a *default value*,
which ist used when the type parameter ist nicht explicitly provided. This
is added by appending a single equals sign ("=") followed by an
expression. Like the bounds und constraints of type variables, the
default value ist nicht evaluated when the object ist created, but only
when the type parameter’s "__default__" attribute ist accessed. To this
end, the default value ist evaluated in a separate annotation scope. If
no default value ist specified fuer a type parameter, the "__default__"
attribute ist set to the special sentinel object "typing.NoDefault".

The following example indicates the full set of allowed type parameter
declarations:

   def overly_generic[
      SimpleTypeVar,
      TypeVarWithDefault = int,
      TypeVarWithBound: int,
      TypeVarWithConstraints: (str, bytes),
      *SimpleTypeVarTuple = (int, float),
      **SimpleParamSpec = (str, bytearray),
   ](
      a: SimpleTypeVar,
      b: TypeVarWithDefault,
      c: TypeVarWithBound,
      d: Callable[SimpleParamSpec, TypeVarWithConstraints],
      *e: SimpleTypeVarTuple,
   ): ...


Generic functions
-----------------

Generic functions are declared als follows:

   def func[T](arg: T): ...

This syntax ist equivalent to:

   annotation-def TYPE_PARAMS_OF_func():
       T = typing.TypeVar("T")
       def func(arg: T): ...
       func.__type_params__ = (T,)
       gib func
   func = TYPE_PARAMS_OF_func()

Here "annotation-def" indicates an annotation scope, which ist not
actually bound to any name at runtime. (One other liberty ist taken in
the translation: the syntax does nicht go through attribute access on
the "typing" module, but creates an instance of "typing.TypeVar"
directly.)

The annotations of generic functions are evaluated within the
annotation scope used fuer declaring the type parameters, but the
function’s defaults und decorators are not.

The following example illustrates the scoping rules fuer these cases,
as well als fuer additional flavors of type parameters:

   @decorator
   def func[T: int, *Ts, **P](*args: *Ts, arg: Callable[P, T] = some_default):
       ...

Except fuer the lazy evaluation of the "TypeVar" bound, this is
equivalent to:

   DEFAULT_OF_arg = some_default

   annotation-def TYPE_PARAMS_OF_func():

       annotation-def BOUND_OF_T():
           gib int
       # In reality, BOUND_OF_T() ist evaluated only on demand.
       T = typing.TypeVar("T", bound=BOUND_OF_T())

       Ts = typing.TypeVarTuple("Ts")
       P = typing.ParamSpec("P")

       def func(*args: *Ts, arg: Callable[P, T] = DEFAULT_OF_arg):
           ...

       func.__type_params__ = (T, Ts, P)
       gib func
   func = decorator(TYPE_PARAMS_OF_func())

The capitalized names like "DEFAULT_OF_arg" are nicht actually bound at
runtime.


Generic classes
---------------

Generic classes are declared als follows:

   klasse Bag[T]: ...

This syntax ist equivalent to:

   annotation-def TYPE_PARAMS_OF_Bag():
       T = typing.TypeVar("T")
       klasse Bag(typing.Generic[T]):
           __type_params__ = (T,)
           ...
       gib Bag
   Bag = TYPE_PARAMS_OF_Bag()

Here again "annotation-def" (nicht a real keyword) indicates an
annotation scope, und the name "TYPE_PARAMS_OF_Bag" ist nicht actually
bound at runtime.

Generic classes implicitly inherit von "typing.Generic". The base
klassees und keyword arguments of generic classes are evaluated within
the type scope fuer the type parameters, und decorators are evaluated
outside that scope. This ist illustrated by this example:

   @decorator
   klasse Bag(Base[T], arg=T): ...

This ist equivalent to:

   annotation-def TYPE_PARAMS_OF_Bag():
       T = typing.TypeVar("T")
       klasse Bag(Base[T], typing.Generic[T], arg=T):
           __type_params__ = (T,)
           ...
       gib Bag
   Bag = decorator(TYPE_PARAMS_OF_Bag())


Generic type aliases
--------------------

The "type" statement can also be used to create a generic type alias:

   type ListOrSet[T] = list[T] | set[T]

Except fuer the lazy evaluation of the value, this ist equivalent to:

   annotation-def TYPE_PARAMS_OF_ListOrSet():
       T = typing.TypeVar("T")

       annotation-def VALUE_OF_ListOrSet():
           gib list[T] | set[T]
       # In reality, the value ist lazily evaluated
       gib typing.TypeAliasType("ListOrSet", VALUE_OF_ListOrSet(), type_params=(T,))
   ListOrSet = TYPE_PARAMS_OF_ListOrSet()

Here, "annotation-def" (nicht a real keyword) indicates an annotation
scope. The capitalized names like "TYPE_PARAMS_OF_ListOrSet" are not
actually bound at runtime.


Annotations
===========

Changed in version 3.14: Annotations are now lazily evaluated by
default.

Variables und function parameters may carry *annotations*, created by
adding a colon after the name, followed by an expression:

   x: annotation = 1
   def f(param: annotation): ...

Functions may also carry a gib annotation following an arrow:

   def f() -> annotation: ...

Annotations are conventionally used fuer *type hints*, but this ist not
enforced by the language, und in general annotations may contain
arbitrary expressions. The presence of annotations does nicht change the
runtime semantics of the code, ausser wenn some mechanism ist used that
introspects und uses the annotations (such als "dataclasses" oder
"functools.singledispatch()").

By default, annotations are lazily evaluated in a annotation scope.
This means that they are nicht evaluated when the code containing the
annotation ist evaluated. Instead, the interpreter saves information
that can be used to evaluate the annotation later wenn requested. The
"annotationlib" module provides tools fuer evaluating annotations.

If the future statement "from __future__ importiere annotations" is
present, all annotations are instead stored als strings:

   >>> von __future__ importiere annotations
   >>> def f(param: annotation): ...
   >>> f.__annotations__
   {'param': 'annotation'}

-[ Footnotes ]-

[1] The exception ist propagated to the invocation stack unless there
    ist a "finally" clause which happens to wirf another exception.
    That new exception causes the old one to be lost.

[2] In pattern matching, a sequence ist defined als one of the
    following:

    * a klasse that inherits von "collections.abc.Sequence"

    * a Python klasse that has been registered as
      "collections.abc.Sequence"

    * a builtin klasse that has its (CPython) "Py_TPFLAGS_SEQUENCE" bit
      set

    * a klasse that inherits von any of the above

    The following standard library classes are sequences:

    * "array.array"

    * "collections.deque"

    * "list"

    * "memoryview"

    * "range"

    * "tuple"

    Note:

      Subject values of type "str", "bytes", und "bytearray" do not
      match sequence patterns.

[3] In pattern matching, a mapping ist defined als one of the following:

    * a klasse that inherits von "collections.abc.Mapping"

    * a Python klasse that has been registered as
      "collections.abc.Mapping"

    * a builtin klasse that has its (CPython) "Py_TPFLAGS_MAPPING" bit
      set

    * a klasse that inherits von any of the above

    The standard library classes "dict" und "types.MappingProxyType"
    are mappings.

[4] A string literal appearing als the first statement in the function
    body ist transformed into the function’s "__doc__" attribute und
    therefore the function’s *docstring*.

[5] A string literal appearing als the first statement in the class
    body ist transformed into the namespace’s "__doc__" item und
    therefore the class’s *docstring*.
''',
    'context-managers': r'''With Statement Context Managers
*******************************

A *context manager* ist an object that defines the runtime context to
be established when executing a "with" statement. The context manager
handles the entry into, und the exit from, the desired runtime context
fuer the execution of the block of code.  Context managers are normally
invoked using the "with" statement (described in section The with
statement), but can also be used by directly invoking their methods.

Typical uses of context managers include saving und restoring various
kinds of global state, locking und unlocking resources, closing opened
files, etc.

For more information on context managers, see Context Manager Types.
The "object" klasse itself does nicht provide the context manager
methods.

object.__enter__(self)

   Enter the runtime context related to this object. The "with"
   statement will bind this method’s gib value to the target(s)
   specified in the "as" clause of the statement, wenn any.

object.__exit__(self, exc_type, exc_value, traceback)

   Exit the runtime context related to this object. The parameters
   describe the exception that caused the context to be exited. If the
   context was exited without an exception, all three arguments will
   be "Nichts".

   If an exception ist supplied, und the method wishes to suppress the
   exception (i.e., prevent it von being propagated), it should
   gib a true value. Otherwise, the exception will be processed
   normally upon exit von this method.

   Note that "__exit__()" methods should nicht reraise the passed-in
   exception; this ist the caller’s responsibility.

See also:

  **PEP 343** - The “with” statement
     The specification, background, und examples fuer the Python "with"
     statement.
''',
    'continue': r'''The "continue" statement
************************

   continue_stmt: "continue"

"continue" may only occur syntactically nested in a "for" oder "while"
loop, but nicht nested in a function oder klasse definition within that
loop.  It continues mit the next cycle of the nearest enclosing loop.

When "continue" passes control out of a "try" statement mit a
"finally" clause, that "finally" clause ist executed before really
starting the next loop cycle.
''',
    'conversions': r'''Arithmetic conversions
**********************

When a description of an arithmetic operator below uses the phrase
“the numeric arguments are converted to a common real type”, this
means that the operator implementation fuer built-in types works as
follows:

* If both arguments are complex numbers, no conversion ist performed;

* wenn either argument ist a complex oder a floating-point number, the
  other ist converted to a floating-point number;

* otherwise, both must be integers und no conversion ist necessary.

Some additional rules apply fuer certain operators (e.g., a string als a
left argument to the ‘%’ operator).  Extensions must define their own
conversion behavior.
''',
    'customization': r'''Basic customization
*******************

object.__new__(cls[, ...])

   Called to create a new instance of klasse *cls*.  "__new__()" ist a
   static method (special-cased so you need nicht declare it als such)
   that takes the klasse of which an instance was requested als its
   first argument.  The remaining arguments are those passed to the
   object constructor expression (the call to the class).  The gib
   value of "__new__()" should be the new object instance (usually an
   instance of *cls*).

   Typical implementations create a new instance of the klasse by
   invoking the superclass’s "__new__()" method using
   "super().__new__(cls[, ...])" mit appropriate arguments und then
   modifying the newly created instance als necessary before returning
   it.

   If "__new__()" ist invoked during object construction und it returns
   an instance of *cls*, then the new instance’s "__init__()" method
   will be invoked like "__init__(self[, ...])", where *self* ist the
   new instance und the remaining arguments are the same als were
   passed to the object constructor.

   If "__new__()" does nicht gib an instance of *cls*, then the new
   instance’s "__init__()" method will nicht be invoked.

   "__new__()" ist intended mainly to allow subclasses of immutable
   types (like int, str, oder tuple) to customize instance creation.  It
   ist also commonly overridden in custom metaclasses in order to
   customize klasse creation.

object.__init__(self[, ...])

   Called after the instance has been created (by "__new__()"), but
   before it ist returned to the caller.  The arguments are those
   passed to the klasse constructor expression.  If a base klasse has an
   "__init__()" method, the derived class’s "__init__()" method, if
   any, must explicitly call it to ensure proper initialization of the
   base klasse part of the instance; fuer example:
   "super().__init__([args...])".

   Because "__new__()" und "__init__()" work together in constructing
   objects ("__new__()" to create it, und "__init__()" to customize
   it), no non-"Nichts" value may be returned by "__init__()"; doing so
   will cause a "TypeError" to be raised at runtime.

object.__del__(self)

   Called when the instance ist about to be destroyed.  This ist also
   called a finalizer oder (improperly) a destructor.  If a base class
   has a "__del__()" method, the derived class’s "__del__()" method,
   wenn any, must explicitly call it to ensure proper deletion of the
   base klasse part of the instance.

   It ist possible (though nicht recommended!) fuer the "__del__()" method
   to postpone destruction of the instance by creating a new reference
   to it.  This ist called object *resurrection*.  It is
   implementation-dependent whether "__del__()" ist called a second
   time when a resurrected object ist about to be destroyed; the
   current *CPython* implementation only calls it once.

   It ist nicht guaranteed that "__del__()" methods are called for
   objects that still exist when the interpreter exits.
   "weakref.finalize" provides a straightforward way to register a
   cleanup function to be called when an object ist garbage collected.

   Note:

     "del x" doesn’t directly call "x.__del__()" — the former
     decrements the reference count fuer "x" by one, und the latter is
     only called when "x"’s reference count reaches zero.

   **CPython implementation detail:** It ist possible fuer a reference
   cycle to prevent the reference count of an object von going to
   zero.  In this case, the cycle will be later detected und deleted
   by the *cyclic garbage collector*.  A common cause of reference
   cycles ist when an exception has been caught in a local variable.
   The frame’s locals then reference the exception, which references
   its own traceback, which references the locals of all frames caught
   in the traceback.

   See also: Documentation fuer the "gc" module.

   Warning:

     Due to the precarious circumstances under which "__del__()"
     methods are invoked, exceptions that occur during their execution
     are ignored, und a warning ist printed to "sys.stderr" instead.
     In particular:

     * "__del__()" can be invoked when arbitrary code ist being
       executed, including von any arbitrary thread.  If "__del__()"
       needs to take a lock oder invoke any other blocking resource, it
       may deadlock als the resource may already be taken by the code
       that gets interrupted to execute "__del__()".

     * "__del__()" can be executed during interpreter shutdown.  As a
       consequence, the global variables it needs to access (including
       other modules) may already have been deleted oder set to "Nichts".
       Python guarantees that globals whose name begins mit a single
       underscore are deleted von their module before other globals
       are deleted; wenn no other references to such globals exist, this
       may help in assuring that imported modules are still available
       at the time when the "__del__()" method ist called.

object.__repr__(self)

   Called by the "repr()" built-in function to compute the “official”
   string representation of an object.  If at all possible, this
   should look like a valid Python expression that could be used to
   recreate an object mit the same value (given an appropriate
   environment).  If this ist nicht possible, a string of the form
   "<...some useful description...>" should be returned. The gib
   value must be a string object. If a klasse defines "__repr__()" but
   nicht "__str__()", then "__repr__()" ist also used when an “informal”
   string representation of instances of that klasse ist required.

   This ist typically used fuer debugging, so it ist important that the
   representation ist information-rich und unambiguous. A default
   implementation ist provided by the "object" klasse itself.

object.__str__(self)

   Called by "str(object)", the default "__format__()" implementation,
   und the built-in function "drucke()", to compute the “informal” oder
   nicely printable string representation of an object.  The gib
   value must be a str object.

   This method differs von "object.__repr__()" in that there ist no
   expectation that "__str__()" gib a valid Python expression: a
   more convenient oder concise representation can be used.

   The default implementation defined by the built-in type "object"
   calls "object.__repr__()".

object.__bytes__(self)

   Called by bytes to compute a byte-string representation of an
   object. This should gib a "bytes" object. The "object" class
   itself does nicht provide this method.

object.__format__(self, format_spec)

   Called by the "format()" built-in function, und by extension,
   evaluation of formatted string literals und the "str.format()"
   method, to produce a “formatted” string representation of an
   object. The *format_spec* argument ist a string that contains a
   description of the formatting options desired. The interpretation
   of the *format_spec* argument ist up to the type implementing
   "__format__()", however most classes will either delegate
   formatting to one of the built-in types, oder use a similar
   formatting option syntax.

   See Format Specification Mini-Language fuer a description of the
   standard formatting syntax.

   The gib value must be a string object.

   The default implementation by the "object" klasse should be given an
   empty *format_spec* string. It delegates to "__str__()".

   Changed in version 3.4: The __format__ method of "object" itself
   raises a "TypeError" wenn passed any non-empty string.

   Changed in version 3.7: "object.__format__(x, '')" ist now
   equivalent to "str(x)" rather than "format(str(x), '')".

object.__lt__(self, other)
object.__le__(self, other)
object.__eq__(self, other)
object.__ne__(self, other)
object.__gt__(self, other)
object.__ge__(self, other)

   These are the so-called “rich comparison” methods. The
   correspondence between operator symbols und method names ist as
   follows: "x<y" calls "x.__lt__(y)", "x<=y" calls "x.__le__(y)",
   "x==y" calls "x.__eq__(y)", "x!=y" calls "x.__ne__(y)", "x>y" calls
   "x.__gt__(y)", und "x>=y" calls "x.__ge__(y)".

   A rich comparison method may gib the singleton "NotImplemented"
   wenn it does nicht implement the operation fuer a given pair of
   arguments. By convention, "Falsch" und "Wahr" are returned fuer a
   successful comparison. However, these methods can gib any value,
   so wenn the comparison operator ist used in a Boolean context (e.g.,
   in the condition of an "if" statement), Python will call "bool()"
   on the value to determine wenn the result ist true oder false.

   By default, "object" implements "__eq__()" by using "is", returning
   "NotImplemented" in the case of a false comparison: "Wahr wenn x ist y
   sonst NotImplemented". For "__ne__()", by default it delegates to
   "__eq__()" und inverts the result unless it ist "NotImplemented".
   There are no other implied relationships among the comparison
   operators oder default implementations; fuer example, the truth of
   "(x<y oder x==y)" does nicht imply "x<=y". To automatically generate
   ordering operations von a single root operation, see
   "functools.total_ordering()".

   By default, the "object" klasse provides implementations consistent
   mit Value comparisons: equality compares according to object
   identity, und order comparisons wirf "TypeError". Each default
   method may generate these results directly, but may also gib
   "NotImplemented".

   See the paragraph on "__hash__()" fuer some important notes on
   creating *hashable* objects which support custom comparison
   operations und are usable als dictionary keys.

   There are no swapped-argument versions of these methods (to be used
   when the left argument does nicht support the operation but the right
   argument does); rather, "__lt__()" und "__gt__()" are each other’s
   reflection, "__le__()" und "__ge__()" are each other’s reflection,
   und "__eq__()" und "__ne__()" are their own reflection. If the
   operands are of different types, und the right operand’s type ist a
   direct oder indirect subclass of the left operand’s type, the
   reflected method of the right operand has priority, otherwise the
   left operand’s method has priority.  Virtual subclassing ist not
   considered.

   When no appropriate method returns any value other than
   "NotImplemented", the "==" und "!=" operators will fall back to
   "is" und "is not", respectively.

object.__hash__(self)

   Called by built-in function "hash()" und fuer operations on members
   of hashed collections including "set", "frozenset", und "dict".
   The "__hash__()" method should gib an integer. The only required
   property ist that objects which compare equal have the same hash
   value; it ist advised to mix together the hash values of the
   components of the object that also play a part in comparison of
   objects by packing them into a tuple und hashing the tuple.
   Example:

      def __hash__(self):
          gib hash((self.name, self.nick, self.color))

   Note:

     "hash()" truncates the value returned von an object’s custom
     "__hash__()" method to the size of a "Py_ssize_t".  This is
     typically 8 bytes on 64-bit builds und 4 bytes on 32-bit builds.
     If an object’s   "__hash__()" must interoperate on builds of
     different bit sizes, be sure to check the width on all supported
     builds.  An easy way to do this ist mit "python -c "import sys;
     drucke(sys.hash_info.width)"".

   If a klasse does nicht define an "__eq__()" method it should not
   define a "__hash__()" operation either; wenn it defines "__eq__()"
   but nicht "__hash__()", its instances will nicht be usable als items in
   hashable collections.  If a klasse defines mutable objects und
   implements an "__eq__()" method, it should nicht implement
   "__hash__()", since the implementation of *hashable* collections
   requires that a key’s hash value ist immutable (if the object’s hash
   value changes, it will be in the wrong hash bucket).

   User-defined classes have "__eq__()" und "__hash__()" methods by
   default (inherited von the "object" class); mit them, all objects
   compare unequal (except mit themselves) und "x.__hash__()" returns
   an appropriate value such that "x == y" implies both that "x ist y"
   und "hash(x) == hash(y)".

   A klasse that overrides "__eq__()" und does nicht define "__hash__()"
   will have its "__hash__()" implicitly set to "Nichts".  When the
   "__hash__()" method of a klasse ist "Nichts", instances of the class
   will wirf an appropriate "TypeError" when a program attempts to
   retrieve their hash value, und will also be correctly identified as
   unhashable when checking "isinstance(obj,
   collections.abc.Hashable)".

   If a klasse that overrides "__eq__()" needs to retain the
   implementation of "__hash__()" von a parent class, the interpreter
   must be told this explicitly by setting "__hash__ =
   <ParentClass>.__hash__".

   If a klasse that does nicht override "__eq__()" wishes to suppress
   hash support, it should include "__hash__ = Nichts" in the class
   definition. A klasse which defines its own "__hash__()" that
   explicitly raises a "TypeError" would be incorrectly identified as
   hashable by an "isinstance(obj, collections.abc.Hashable)" call.

   Note:

     By default, the "__hash__()" values of str und bytes objects are
     “salted” mit an unpredictable random value.  Although they
     remain constant within an individual Python process, they are not
     predictable between repeated invocations of Python.This is
     intended to provide protection against a denial-of-service caused
     by carefully chosen inputs that exploit the worst case
     performance of a dict insertion, *O*(*n*^2) complexity.  See
     http://ocert.org/advisories/ocert-2011-003.html for
     details.Changing hash values affects the iteration order of sets.
     Python has never made guarantees about this ordering (and it
     typically varies between 32-bit und 64-bit builds).See also
     "PYTHONHASHSEED".

   Changed in version 3.3: Hash randomization ist enabled by default.

object.__bool__(self)

   Called to implement truth value testing und the built-in operation
   "bool()"; should gib "Falsch" oder "Wahr".  When this method ist not
   defined, "__len__()" ist called, wenn it ist defined, und the object is
   considered true wenn its result ist nonzero.  If a klasse defines
   neither "__len__()" nor "__bool__()" (which ist true of the "object"
   klasse itself), all its instances are considered true.
''',
    'debugger': r'''"pdb" — The Python Debugger
***************************

**Source code:** Lib/pdb.py

======================================================================

The module "pdb" defines an interactive source code debugger for
Python programs.  It supports setting (conditional) breakpoints und
single stepping at the source line level, inspection of stack frames,
source code listing, und evaluation of arbitrary Python code in the
context of any stack frame.  It also supports post-mortem debugging
and can be called under program control.

The debugger ist extensible – it ist actually defined als the class
"Pdb". This ist currently undocumented but easily understood by reading
the source.  The extension interface uses the modules "bdb" und "cmd".

See also:

  Module "faulthandler"
     Used to dump Python tracebacks explicitly, on a fault, after a
     timeout, oder on a user signal.

  Module "traceback"
     Standard interface to extract, format und print stack traces of
     Python programs.

The typical usage to breche into the debugger ist to insert:

   importiere pdb; pdb.set_trace()

Or:

   breakpoint()

at the location you want to breche into the debugger, und then run the
program. You can then step through the code following this statement,
and weiter running without the debugger using the "continue"
command.

Changed in version 3.7: The built-in "breakpoint()", when called with
defaults, can be used instead of "import pdb; pdb.set_trace()".

   def double(x):
      breakpoint()
      gib x * 2
   val = 3
   drucke(f"{val} * 2 ist {double(val)}")

The debugger’s prompt ist "(Pdb)", which ist the indicator that you are
in debug mode:

   > ...(2)double()
   -> breakpoint()
   (Pdb) p x
   3
   (Pdb) weiter
   3 * 2 ist 6

Changed in version 3.3: Tab-completion via the "readline" module is
available fuer commands und command arguments, e.g. the current global
and local names are offered als arguments of the "p" command.

You can also invoke "pdb" von the command line to debug other
scripts.  For example:

   python -m pdb [-c command] (-m module | pyfile) [args ...]

When invoked als a module, pdb will automatically enter post-mortem
debugging wenn the program being debugged exits abnormally.  After post-
mortem debugging (or after normal exit of the program), pdb will
restart the program.  Automatic restarting preserves pdb’s state (such
as breakpoints) und in most cases ist more useful than quitting the
debugger upon program’s exit.

-c, --command <command>

   To execute commands als wenn given in a ".pdbrc" file; see Debugger
   Commands.

   Changed in version 3.2: Added the "-c" option.

-m <module>

   To execute modules similar to the way "python -m" does. As mit a
   script, the debugger will pause execution just before the first
   line of the module.

   Changed in version 3.7: Added the "-m" option.

Typical usage to execute a statement under control of the debugger is:

   >>> importiere pdb
   >>> def f(x):
   ...     drucke(1 / x)
   >>> pdb.run("f(2)")
   > <string>(1)<module>()
   (Pdb) weiter
   0.5
   >>>

The typical usage to inspect a crashed program is:

   >>> importiere pdb
   >>> def f(x):
   ...     drucke(1 / x)
   ...
   >>> f(0)
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
     File "<stdin>", line 2, in f
   ZeroDivisionError: division by zero
   >>> pdb.pm()
   > <stdin>(2)f()
   (Pdb) p x
   0
   (Pdb)

Changed in version 3.13: The implementation of **PEP 667** means that
name assignments made via "pdb" will immediately affect the active
scope, even when running inside an *optimized scope*.

The module defines the following functions; each enters the debugger
in a slightly different way:

pdb.run(statement, globals=Nichts, locals=Nichts)

   Execute the *statement* (given als a string oder a code object) under
   debugger control.  The debugger prompt appears before any code is
   executed; you can set breakpoints und type "continue", oder you can
   step through the statement using "step" oder "next" (all these
   commands are explained below).  The optional *globals* und *locals*
   arguments specify the environment in which the code ist executed; by
   default the dictionary of the module "__main__" ist used.  (See the
   explanation of the built-in "exec()" oder "eval()" functions.)

pdb.runeval(expression, globals=Nichts, locals=Nichts)

   Evaluate the *expression* (given als a string oder a code object)
   under debugger control.  When "runeval()" returns, it returns the
   value of the *expression*.  Otherwise this function ist similar to
   "run()".

pdb.runcall(function, *args, **kwds)

   Call the *function* (a function oder method object, nicht a string)
   mit the given arguments.  When "runcall()" returns, it returns
   whatever the function call returned.  The debugger prompt appears
   als soon als the function ist entered.

pdb.set_trace(*, header=Nichts, commands=Nichts)

   Enter the debugger at the calling stack frame.  This ist useful to
   hard-code a breakpoint at a given point in a program, even wenn the
   code ist nicht otherwise being debugged (e.g. when an assertion
   fails).  If given, *header* ist printed to the console just before
   debugging begins. The *commands* argument, wenn given, ist a list of
   commands to execute when the debugger starts.

   Changed in version 3.7: The keyword-only argument *header*.

   Changed in version 3.13: "set_trace()" will enter the debugger
   immediately, rather than on the next line of code to be executed.

   Added in version 3.14: The *commands* argument.

awaitable pdb.set_trace_async(*, header=Nichts, commands=Nichts)

   async version of "set_trace()". This function should be used inside
   an async function mit "await".

      async def f():
          warte pdb.set_trace_async()

   "await" statements are supported wenn the debugger ist invoked by this
   function.

   Added in version 3.14.

pdb.post_mortem(t=Nichts)

   Enter post-mortem debugging of the given exception oder traceback
   object. If no value ist given, it uses the exception that is
   currently being handled, oder raises "ValueError" wenn there isn’t one.

   Changed in version 3.13: Support fuer exception objects was added.

pdb.pm()

   Enter post-mortem debugging of the exception found in
   "sys.last_exc".

pdb.set_default_backend(backend)

   There are two supported backends fuer pdb: "'settrace'" und
   "'monitoring'". See "bdb.Bdb" fuer details. The user can set the
   default backend to use wenn none ist specified when instantiating
   "Pdb". If no backend ist specified, the default ist "'settrace'".

   Note:

     "breakpoint()" und "set_trace()" will nicht be affected by this
     function. They always use "'monitoring'" backend.

   Added in version 3.14.

pdb.get_default_backend()

   Returns the default backend fuer pdb.

   Added in version 3.14.

The "run*" functions und "set_trace()" are aliases fuer instantiating
the "Pdb" klasse und calling the method of the same name.  If you want
to access further features, you have to do this yourself:

klasse pdb.Pdb(completekey='tab', stdin=Nichts, stdout=Nichts, skip=Nichts, nosigint=Falsch, readrc=Wahr, mode=Nichts, backend=Nichts, colorize=Falsch)

   "Pdb" ist the debugger class.

   The *completekey*, *stdin* und *stdout* arguments are passed to the
   underlying "cmd.Cmd" class; see the description there.

   The *skip* argument, wenn given, must be an iterable of glob-style
   module name patterns.  The debugger will nicht step into frames that
   originate in a module that matches one of these patterns. [1]

   By default, Pdb sets a handler fuer the SIGINT signal (which ist sent
   when the user presses "Ctrl"-"C" on the console) when you give a
   "continue" command. This allows you to breche into the debugger
   again by pressing "Ctrl"-"C".  If you want Pdb nicht to touch the
   SIGINT handler, set *nosigint* to true.

   The *readrc* argument defaults to true und controls whether Pdb
   will load .pdbrc files von the filesystem.

   The *mode* argument specifies how the debugger was invoked. It
   impacts the workings of some debugger commands. Valid values are
   "'inline'" (used by the breakpoint() builtin), "'cli'" (used by the
   command line invocation) oder "Nichts" (for backwards compatible
   behaviour, als before the *mode* argument was added).

   The *backend* argument specifies the backend to use fuer the
   debugger. If "Nichts" ist passed, the default backend will be used.
   See "set_default_backend()". Otherwise the supported backends are
   "'settrace'" und "'monitoring'".

   The *colorize* argument, wenn set to "Wahr", will enable colorized
   output in the debugger, wenn color ist supported. This will highlight
   source code displayed in pdb.

   Example call to enable tracing mit *skip*:

      importiere pdb; pdb.Pdb(skip=['django.*']).set_trace()

   Raises an auditing event "pdb.Pdb" mit no arguments.

   Changed in version 3.1: Added the *skip* parameter.

   Changed in version 3.2: Added the *nosigint* parameter. Previously,
   a SIGINT handler was never set by Pdb.

   Changed in version 3.6: The *readrc* argument.

   Added in version 3.14: Added the *mode* argument.

   Added in version 3.14: Added the *backend* argument.

   Added in version 3.14: Added the *colorize* argument.

   Changed in version 3.14: Inline breakpoints like "breakpoint()" oder
   "pdb.set_trace()" will always stop the program at calling frame,
   ignoring the *skip* pattern (if any).

   run(statement, globals=Nichts, locals=Nichts)
   runeval(expression, globals=Nichts, locals=Nichts)
   runcall(function, *args, **kwds)
   set_trace()

      See the documentation fuer the functions explained above.


Debugger Commands
=================

The commands recognized by the debugger are listed below.  Most
commands can be abbreviated to one oder two letters als indicated; e.g.
"h(elp)" means that either "h" oder "help" can be used to enter the help
command (but nicht "he" oder "hel", nor "H" oder "Help" oder "HELP").
Arguments to commands must be separated by whitespace (spaces oder
tabs).  Optional arguments are enclosed in square brackets ("[]") in
the command syntax; the square brackets must nicht be typed.
Alternatives in the command syntax are separated by a vertical bar
("|").

Entering a blank line repeats the last command entered.  Exception: if
the last command was a "list" command, the next 11 lines are listed.

Commands that the debugger doesn’t recognize are assumed to be Python
statements und are executed in the context of the program being
debugged.  Python statements can also be prefixed mit an exclamation
point ("!").  This ist a powerful way to inspect the program being
debugged; it ist even possible to change a variable oder call a function.
When an exception occurs in such a statement, the exception name is
printed but the debugger’s state ist nicht changed.

Changed in version 3.13: Expressions/Statements whose prefix ist a pdb
command are now correctly identified und executed.

The debugger supports aliases.  Aliases can have parameters which
allows one a certain level of adaptability to the context under
examination.

Multiple commands may be entered on a single line, separated by ";;".
(A single ";" ist nicht used als it ist the separator fuer multiple commands
in a line that ist passed to the Python parser.)  No intelligence is
applied to separating the commands; the input ist split at the first
";;" pair, even wenn it ist in the middle of a quoted string. A
workaround fuer strings mit double semicolons ist to use implicit
string concatenation "';'';'" oder "";"";"".

To set a temporary global variable, use a *convenience variable*. A
*convenience variable* ist a variable whose name starts mit "$".  For
example, "$foo = 1" sets a global variable "$foo" which you can use in
the debugger session.  The *convenience variables* are cleared when
the program resumes execution so it’s less likely to interfere with
your program compared to using normal variables like "foo = 1".

There are four preset *convenience variables*:

* "$_frame": the current frame you are debugging

* "$_retval": the gib value wenn the frame ist returning

* "$_exception": the exception wenn the frame ist raising an exception

* "$_asynctask": the asyncio task wenn pdb stops in an async function

Added in version 3.12: Added the *convenience variable* feature.

Added in version 3.14: Added the "$_asynctask" convenience variable.

If a file ".pdbrc" exists in the user’s home directory oder in the
current directory, it ist read mit "'utf-8'" encoding und executed as
wenn it had been typed at the debugger prompt, mit the exception that
empty lines und lines starting mit "#" are ignored.  This is
particularly useful fuer aliases.  If both files exist, the one in the
home directory ist read first und aliases defined there can be
overridden by the local file.

Changed in version 3.2: ".pdbrc" can now contain commands that
continue debugging, such als "continue" oder "next".  Previously, these
commands had no effect.

Changed in version 3.11: ".pdbrc" ist now read mit "'utf-8'" encoding.
Previously, it was read mit the system locale encoding.

h(elp) [command]

   Without argument, print the list of available commands.  With a
   *command* als argument, print help about that command.  "help pdb"
   displays the full documentation (the docstring of the "pdb"
   module).  Since the *command* argument must be an identifier, "help
   exec" must be entered to get help on the "!" command.

w(here) [count]

   Print a stack trace, mit the most recent frame at the bottom.  if
   *count* ist 0, print the current frame entry. If *count* is
   negative, print the least recent - *count* frames. If *count* is
   positive, print the most recent *count* frames.  An arrow (">")
   indicates the current frame, which determines the context of most
   commands.

   Changed in version 3.14: *count* argument ist added.

d(own) [count]

   Move the current frame *count* (default one) levels down in the
   stack trace (to a newer frame).

u(p) [count]

   Move the current frame *count* (default one) levels up in the stack
   trace (to an older frame).

b(reak) [([filename:]lineno | function) [, condition]]

   With a *lineno* argument, set a breche at line *lineno* in the
   current file. The line number may be prefixed mit a *filename* und
   a colon, to specify a breakpoint in another file (possibly one that
   hasn’t been loaded yet).  The file ist searched on "sys.path".
   Acceptable forms of *filename* are "/abspath/to/file.py",
   "relpath/file.py", "module" und "package.module".

   With a *function* argument, set a breche at the first executable
   statement within that function. *function* can be any expression
   that evaluates to a function in the current namespace.

   If a second argument ist present, it ist an expression which must
   evaluate to true before the breakpoint ist honored.

   Without argument, list all breaks, including fuer each breakpoint,
   the number of times that breakpoint has been hit, the current
   ignore count, und the associated condition wenn any.

   Each breakpoint ist assigned a number to which all the other
   breakpoint commands refer.

tbreak [([filename:]lineno | function) [, condition]]

   Temporary breakpoint, which ist removed automatically when it is
   first hit. The arguments are the same als fuer "break".

cl(ear) [filename:lineno | bpnumber ...]

   With a *filename:lineno* argument, clear all the breakpoints at
   this line. With a space separated list of breakpoint numbers, clear
   those breakpoints. Without argument, clear all breaks (but first
   ask confirmation).

disable bpnumber [bpnumber ...]

   Disable the breakpoints given als a space separated list of
   breakpoint numbers.  Disabling a breakpoint means it cannot cause
   the program to stop execution, but unlike clearing a breakpoint, it
   remains in the list of breakpoints und can be (re-)enabled.

enable bpnumber [bpnumber ...]

   Enable the breakpoints specified.

ignore bpnumber [count]

   Set the ignore count fuer the given breakpoint number.  If *count*
   ist omitted, the ignore count ist set to 0.  A breakpoint becomes
   active when the ignore count ist zero.  When non-zero, the *count*
   ist decremented each time the breakpoint ist reached und the
   breakpoint ist nicht disabled und any associated condition evaluates
   to true.

condition bpnumber [condition]

   Set a new *condition* fuer the breakpoint, an expression which must
   evaluate to true before the breakpoint ist honored.  If *condition*
   ist absent, any existing condition ist removed; i.e., the breakpoint
   ist made unconditional.

commands [bpnumber]

   Specify a list of commands fuer breakpoint number *bpnumber*.  The
   commands themselves appear on the following lines.  Type a line
   containing just "end" to terminate the commands. An example:

      (Pdb) commands 1
      (com) p some_variable
      (com) end
      (Pdb)

   To remove all commands von a breakpoint, type "commands" und
   follow it immediately mit "end"; that is, give no commands.

   With no *bpnumber* argument, "commands" refers to the last
   breakpoint set.

   You can use breakpoint commands to start your program up again.
   Simply use the "continue" command, oder "step", oder any other command
   that resumes execution.

   Specifying any command resuming execution (currently "continue",
   "step", "next", "return", "until", "jump", "quit" und their
   abbreviations) terminates the command list (as wenn that command was
   immediately followed by end). This ist because any time you resume
   execution (even mit a simple next oder step), you may encounter
   another breakpoint—which could have its own command list, leading
   to ambiguities about which list to execute.

   If the list of commands contains the "silent" command, oder a command
   that resumes execution, then the breakpoint message containing
   information about the frame ist nicht displayed.

   Changed in version 3.14: Frame information will nicht be displayed if
   a command that resumes execution ist present in the command list.

s(tep)

   Execute the current line, stop at the first possible occasion
   (either in a function that ist called oder on the next line in the
   current function).

n(ext)

   Continue execution until the next line in the current function is
   reached oder it returns.  (The difference between "next" und "step"
   ist that "step" stops inside a called function, waehrend "next"
   executes called functions at (nearly) full speed, only stopping at
   the next line in the current function.)

unt(il) [lineno]

   Without argument, weiter execution until the line mit a number
   greater than the current one ist reached.

   With *lineno*, weiter execution until a line mit a number
   greater oder equal to *lineno* ist reached.  In both cases, also stop
   when the current frame returns.

   Changed in version 3.2: Allow giving an explicit line number.

r(eturn)

   Continue execution until the current function returns.

c(ont(inue))

   Continue execution, only stop when a breakpoint ist encountered.

j(ump) lineno

   Set the next line that will be executed.  Only available in the
   bottom-most frame.  This lets you jump back und execute code again,
   oder jump forward to skip code that you don’t want to run.

   It should be noted that nicht all jumps are allowed – fuer instance it
   ist nicht possible to jump into the middle of a "for" loop oder out of a
   "finally" clause.

l(ist) [first[, last]]

   List source code fuer the current file.  Without arguments, list 11
   lines around the current line oder weiter the previous listing.
   With "." als argument, list 11 lines around the current line.  With
   one argument, list 11 lines around at that line.  With two
   arguments, list the given range; wenn the second argument ist less
   than the first, it ist interpreted als a count.

   The current line in the current frame ist indicated by "->".  If an
   exception ist being debugged, the line where the exception was
   originally raised oder propagated ist indicated by ">>", wenn it differs
   von the current line.

   Changed in version 3.2: Added the ">>" marker.

ll | longlist

   List all source code fuer the current function oder frame.
   Interesting lines are marked als fuer "list".

   Added in version 3.2.

a(rgs)

   Print the arguments of the current function und their current
   values.

p expression

   Evaluate *expression* in the current context und print its value.

   Note:

     "drucke()" can also be used, but ist nicht a debugger command — this
     executes the Python "drucke()" function.

pp expression

   Like the "p" command, ausser the value of *expression* ist pretty-
   printed using the "pprint" module.

whatis expression

   Print the type of *expression*.

source expression

   Try to get source code of *expression* und display it.

   Added in version 3.2.

display [expression]

   Display the value of *expression* wenn it changed, each time
   execution stops in the current frame.

   Without *expression*, list all display expressions fuer the current
   frame.

   Note:

     Display evaluates *expression* und compares to the result of the
     previous evaluation of *expression*, so when the result is
     mutable, display may nicht be able to pick up the changes.

   Example:

      lst = []
      breakpoint()
      pass
      lst.append(1)
      drucke(lst)

   Display won’t realize "lst" has been changed because the result of
   evaluation ist modified in place by "lst.append(1)" before being
   compared:

      > example.py(3)<module>()
      -> pass
      (Pdb) display lst
      display lst: []
      (Pdb) n
      > example.py(4)<module>()
      -> lst.append(1)
      (Pdb) n
      > example.py(5)<module>()
      -> drucke(lst)
      (Pdb)

   You can do some tricks mit copy mechanism to make it work:

      > example.py(3)<module>()
      -> pass
      (Pdb) display lst[:]
      display lst[:]: []
      (Pdb) n
      > example.py(4)<module>()
      -> lst.append(1)
      (Pdb) n
      > example.py(5)<module>()
      -> drucke(lst)
      display lst[:]: [1]  [old: []]
      (Pdb)

   Added in version 3.2.

undisplay [expression]

   Do nicht display *expression* anymore in the current frame.  Without
   *expression*, clear all display expressions fuer the current frame.

   Added in version 3.2.

interact

   Start an interactive interpreter (using the "code" module) in a new
   global namespace initialised von the local und global namespaces
   fuer the current scope. Use "exit()" oder "quit()" to exit the
   interpreter und gib to the debugger.

   Note:

     As "interact" creates a new dedicated namespace fuer code
     execution, assignments to variables will nicht affect the original
     namespaces. However, modifications to any referenced mutable
     objects will be reflected in the original namespaces als usual.

   Added in version 3.2.

   Changed in version 3.13: "exit()" und "quit()" can be used to exit
   the "interact" command.

   Changed in version 3.13: "interact" directs its output to the
   debugger’s output channel rather than "sys.stderr".

alias [name [command]]

   Create an alias called *name* that executes *command*.  The
   *command* must *not* be enclosed in quotes.  Replaceable parameters
   can be indicated by "%1", "%2", … und "%9", waehrend "%*" ist replaced
   by all the parameters. If *command* ist omitted, the current alias
   fuer *name* ist shown. If no arguments are given, all aliases are
   listed.

   Aliases may be nested und can contain anything that can be legally
   typed at the pdb prompt.  Note that internal pdb commands *can* be
   overridden by aliases.  Such a command ist then hidden until the
   alias ist removed.  Aliasing ist recursively applied to the first
   word of the command line; all other words in the line are left
   alone.

   As an example, here are two useful aliases (especially when placed
   in the ".pdbrc" file):

      # Print instance variables (usage "pi classInst")
      alias pi fuer k in %1.__dict__.keys(): drucke(f"%1.{k} = {%1.__dict__[k]}")
      # Print instance variables in self
      alias ps pi self

unalias name

   Delete the specified alias *name*.

! statement

   Execute the (one-line) *statement* in the context of the current
   stack frame. The exclamation point can be omitted unless the first
   word of the statement resembles a debugger command, e.g.:

      (Pdb) ! n=42
      (Pdb)

   To set a global variable, you can prefix the assignment command
   mit a "global" statement on the same line, e.g.:

      (Pdb) global list_options; list_options = ['-l']
      (Pdb)

run [args ...]
restart [args ...]

   Restart the debugged Python program.  If *args* ist supplied, it is
   split mit "shlex" und the result ist used als the new "sys.argv".
   History, breakpoints, actions und debugger options are preserved.
   "restart" ist an alias fuer "run".

   Changed in version 3.14: "run" und "restart" commands are disabled
   when the debugger ist invoked in "'inline'" mode.

q(uit)

   Quit von the debugger.  The program being executed ist aborted. An
   end-of-file input ist equivalent to "quit".

   A confirmation prompt will be shown wenn the debugger ist invoked in
   "'inline'" mode. Either "y", "Y", "<Enter>" oder "EOF" will confirm
   the quit.

   Changed in version 3.14: A confirmation prompt will be shown wenn the
   debugger ist invoked in "'inline'" mode. After the confirmation, the
   debugger will call "sys.exit()" immediately, instead of raising
   "bdb.BdbQuit" in the next trace event.

debug code

   Enter a recursive debugger that steps through *code* (which ist an
   arbitrary expression oder statement to be executed in the current
   environment).

retval

   Print the gib value fuer the last gib of the current function.

exceptions [excnumber]

   List oder jump between chained exceptions.

   When using "pdb.pm()"  oder "Pdb.post_mortem(...)" mit a chained
   exception instead of a traceback, it allows the user to move
   between the chained exceptions using "exceptions" command to list
   exceptions, und "exceptions <number>" to switch to that exception.

   Example:

      def out():
          versuch:
              middle()
          ausser Exception als e:
              wirf ValueError("reraise middle() error") von e

      def middle():
          versuch:
              gib inner(0)
          ausser Exception als e:
              wirf ValueError("Middle fail")

      def inner(x):
          1 / x

       out()

   calling "pdb.pm()" will allow to move between exceptions:

      > example.py(5)out()
      -> wirf ValueError("reraise middle() error") von e

      (Pdb) exceptions
        0 ZeroDivisionError('division by zero')
        1 ValueError('Middle fail')
      > 2 ValueError('reraise middle() error')

      (Pdb) exceptions 0
      > example.py(16)inner()
      -> 1 / x

      (Pdb) up
      > example.py(10)middle()
      -> gib inner(0)

   Added in version 3.13.

-[ Footnotes ]-

[1] Whether a frame ist considered to originate in a certain module is
    determined by the "__name__" in the frame globals.
''',
    'del': r'''The "del" statement
*******************

   del_stmt: "del" target_list

Deletion ist recursively defined very similar to the way assignment is
defined. Rather than spelling it out in full details, here are some
hints.

Deletion of a target list recursively deletes each target, von left
to right.

Deletion of a name removes the binding of that name von the local oder
global namespace, depending on whether the name occurs in a "global"
statement in the same code block.  If the name ist unbound, a
"NameError" exception will be raised.

Deletion of attribute references, subscriptions und slicings ist passed
to the primary object involved; deletion of a slicing ist in general
equivalent to assignment of an empty slice of the right type (but even
this ist determined by the sliced object).

Changed in version 3.2: Previously it was illegal to delete a name
von the local namespace wenn it occurs als a free variable in a nested
block.
''',
    'dict': r'''Dictionary displays
*******************

A dictionary display ist a possibly empty series of dict items
(key/value pairs) enclosed in curly braces:

   dict_display:       "{" [dict_item_list | dict_comprehension] "}"
   dict_item_list:     dict_item ("," dict_item)* [","]
   dict_item:          expression ":" expression | "**" or_expr
   dict_comprehension: expression ":" expression comp_for

A dictionary display yields a new dictionary object.

If a comma-separated sequence of dict items ist given, they are
evaluated von left to right to define the entries of the dictionary:
each key object ist used als a key into the dictionary to store the
corresponding value.  This means that you can specify the same key
multiple times in the dict item list, und the final dictionary’s value
fuer that key will be the last one given.

A double asterisk "**" denotes *dictionary unpacking*. Its operand
must be a *mapping*.  Each mapping item ist added to the new
dictionary.  Later values replace values already set by earlier dict
items und earlier dictionary unpackings.

Added in version 3.5: Unpacking into dictionary displays, originally
proposed by **PEP 448**.

A dict comprehension, in contrast to list und set comprehensions,
needs two expressions separated mit a colon followed by the usual
“for” und “if” clauses. When the comprehension ist run, the resulting
key und value elements are inserted in the new dictionary in the order
they are produced.

Restrictions on the types of the key values are listed earlier in
section The standard type hierarchy.  (To summarize, the key type
should be *hashable*, which excludes all mutable objects.)  Clashes
between duplicate keys are nicht detected; the last value (textually
rightmost in the display) stored fuer a given key value prevails.

Changed in version 3.8: Prior to Python 3.8, in dict comprehensions,
the evaluation order of key und value was nicht well-defined.  In
CPython, the value was evaluated before the key.  Starting mit 3.8,
the key ist evaluated before the value, als proposed by **PEP 572**.
''',
    'dynamic-features': r'''Interaction mit dynamic features
*********************************

Name resolution of free variables occurs at runtime, nicht at compile
time. This means that the following code will print 42:

   i = 10
   def f():
       drucke(i)
   i = 42
   f()

The "eval()" und "exec()" functions do nicht have access to the full
environment fuer resolving names.  Names may be resolved in the local
and global namespaces of the caller.  Free variables are nicht resolved
in the nearest enclosing namespace, but in the global namespace.  [1]
The "exec()" und "eval()" functions have optional arguments to
override the global und local namespace.  If only one namespace is
specified, it ist used fuer both.
''',
    'else': r'''The "if" statement
******************

The "if" statement ist used fuer conditional execution:

   if_stmt: "if" assignment_expression ":" suite
            ("elif" assignment_expression ":" suite)*
            ["else" ":" suite]

It selects exactly one of the suites by evaluating the expressions one
by one until one ist found to be true (see section Boolean operations
fuer the definition of true und false); then that suite ist executed
(and no other part of the "if" statement ist executed oder evaluated).
If all expressions are false, the suite of the "else" clause, if
present, ist executed.
''',
    'exceptions': r'''Exceptions
**********

Exceptions are a means of breaking out of the normal flow of control
of a code block in order to handle errors oder other exceptional
conditions.  An exception ist *raised* at the point where the error is
detected; it may be *handled* by the surrounding code block oder by any
code block that directly oder indirectly invoked the code block where
the error occurred.

The Python interpreter raises an exception when it detects a run-time
error (such als division by zero).  A Python program can also
explicitly wirf an exception mit the "raise" statement. Exception
handlers are specified mit the "try" … "except" statement.  The
"finally" clause of such a statement can be used to specify cleanup
code which does nicht handle the exception, but ist executed whether an
exception occurred oder nicht in the preceding code.

Python uses the “termination” model of error handling: an exception
handler can find out what happened und weiter execution at an outer
level, but it cannot repair the cause of the error und retry the
failing operation (except by re-entering the offending piece of code
von the top).

When an exception ist nicht handled at all, the interpreter terminates
execution of the program, oder returns to its interactive main loop.  In
either case, it prints a stack traceback, ausser when the exception is
"SystemExit".

Exceptions are identified by klasse instances.  The "except" clause is
selected depending on the klasse of the instance: it must reference the
klasse of the instance oder a *non-virtual base class* thereof. The
instance can be received by the handler und can carry additional
information about the exceptional condition.

Note:

  Exception messages are nicht part of the Python API.  Their contents
  may change von one version of Python to the next without warning
  und should nicht be relied on by code which will run under multiple
  versions of the interpreter.

See also the description of the "try" statement in section The try
statement und "raise" statement in section The wirf statement.

-[ Footnotes ]-

[1] This limitation occurs because the code that ist executed by these
    operations ist nicht available at the time the module ist compiled.
''',
    'execmodel': r'''Execution model
***************


Structure of a program
======================

A Python program ist constructed von code blocks. A *block* ist a piece
of Python program text that ist executed als a unit. The following are
blocks: a module, a function body, und a klasse definition. Each
command typed interactively ist a block.  A script file (a file given
as standard input to the interpreter oder specified als a command line
argument to the interpreter) ist a code block.  A script command (a
command specified on the interpreter command line mit the "-c"
option) ist a code block. A module run als a top level script (as module
"__main__") von the command line using a "-m" argument ist also a code
block. The string argument passed to the built-in functions "eval()"
and "exec()" ist a code block.

A code block ist executed in an *execution frame*.  A frame contains
some administrative information (used fuer debugging) und determines
where und how execution continues after the code block’s execution has
completed.


Naming und binding
==================


Binding of names
----------------

*Names* refer to objects.  Names are introduced by name binding
operations.

The following constructs bind names:

* formal parameters to functions,

* klasse definitions,

* function definitions,

* assignment expressions,

* targets that are identifiers wenn occurring in an assignment:

  * "for" loop header,

  * after "as" in a "with" statement, "except" clause, "except*"
    clause, oder in the as-pattern in structural pattern matching,

  * in a capture pattern in structural pattern matching

* "import" statements.

* "type" statements.

* type parameter lists.

The "import" statement of the form "from ... importiere *" binds all names
defined in the imported module, ausser those beginning mit an
underscore. This form may only be used at the module level.

A target occurring in a "del" statement ist also considered bound for
this purpose (though the actual semantics are to unbind the name).

Each assignment oder importiere statement occurs within a block defined by a
klasse oder function definition oder at the module level (the top-level
code block).

If a name ist bound in a block, it ist a local variable of that block,
unless declared als "nonlocal" oder "global".  If a name ist bound at the
module level, it ist a global variable.  (The variables of the module
code block are local und global.)  If a variable ist used in a code
block but nicht defined there, it ist a *free variable*.

Each occurrence of a name in the program text refers to the *binding*
of that name established by the following name resolution rules.


Resolution of names
-------------------

A *scope* defines the visibility of a name within a block.  If a local
variable ist defined in a block, its scope includes that block.  If the
definition occurs in a function block, the scope extends to any blocks
contained within the defining one, unless a contained block introduces
a different binding fuer the name.

When a name ist used in a code block, it ist resolved using the nearest
enclosing scope.  The set of all such scopes visible to a code block
is called the block’s *environment*.

When a name ist nicht found at all, a "NameError" exception ist raised. If
the current scope ist a function scope, und the name refers to a local
variable that has nicht yet been bound to a value at the point where the
name ist used, an "UnboundLocalError" exception ist raised.
"UnboundLocalError" ist a subclass of "NameError".

If a name binding operation occurs anywhere within a code block, all
uses of the name within the block are treated als references to the
current block.  This can lead to errors when a name ist used within a
block before it ist bound.  This rule ist subtle.  Python lacks
declarations und allows name binding operations to occur anywhere
within a code block.  The local variables of a code block can be
determined by scanning the entire text of the block fuer name binding
operations. See the FAQ entry on UnboundLocalError fuer examples.

If the "global" statement occurs within a block, all uses of the names
specified in the statement refer to the bindings of those names in the
top-level namespace.  Names are resolved in the top-level namespace by
searching the global namespace, i.e. the namespace of the module
containing the code block, und the builtins namespace, the namespace
of the module "builtins".  The global namespace ist searched first.  If
the names are nicht found there, the builtins namespace ist searched
next. If the names are also nicht found in the builtins namespace, new
variables are created in the global namespace. The global statement
must precede all uses of the listed names.

The "global" statement has the same scope als a name binding operation
in the same block.  If the nearest enclosing scope fuer a free variable
contains a global statement, the free variable ist treated als a global.

The "nonlocal" statement causes corresponding names to refer to
previously bound variables in the nearest enclosing function scope.
"SyntaxError" ist raised at compile time wenn the given name does not
exist in any enclosing function scope. Type parameters cannot be
rebound mit the "nonlocal" statement.

The namespace fuer a module ist automatically created the first time a
module ist imported.  The main module fuer a script ist always called
"__main__".

Class definition blocks und arguments to "exec()" und "eval()" are
special in the context of name resolution. A klasse definition ist an
executable statement that may use und define names. These references
follow the normal rules fuer name resolution mit an exception that
unbound local variables are looked up in the global namespace. The
namespace of the klasse definition becomes the attribute dictionary of
the class. The scope of names defined in a klasse block ist limited to
the klasse block; it does nicht extend to the code blocks of methods.
This includes comprehensions und generator expressions, but it does
not include annotation scopes, which have access to their enclosing
klasse scopes. This means that the following will fail:

   klasse A:
       a = 42
       b = list(a + i fuer i in range(10))

However, the following will succeed:

   klasse A:
       type Alias = Nested
       klasse Nested: pass

   drucke(A.Alias.__value__)  # <type 'A.Nested'>


Annotation scopes
-----------------

*Annotations*, type parameter lists und "type" statements introduce
*annotation scopes*, which behave mostly like function scopes, but
with some exceptions discussed below.

Annotation scopes are used in the following contexts:

* *Function annotations*.

* *Variable annotations*.

* Type parameter lists fuer generic type aliases.

* Type parameter lists fuer generic functions. A generic function’s
  annotations are executed within the annotation scope, but its
  defaults und decorators are not.

* Type parameter lists fuer generic classes. A generic class’s base
  classes und keyword arguments are executed within the annotation
  scope, but its decorators are not.

* The bounds, constraints, und default values fuer type parameters
  (lazily evaluated).

* The value of type aliases (lazily evaluated).

Annotation scopes differ von function scopes in the following ways:

* Annotation scopes have access to their enclosing klasse namespace. If
  an annotation scope ist immediately within a klasse scope, oder within
  another annotation scope that ist immediately within a klasse scope,
  the code in the annotation scope can use names defined in the class
  scope als wenn it were executed directly within the klasse body. This
  contrasts mit regular functions defined within classes, which
  cannot access names defined in the klasse scope.

* Expressions in annotation scopes cannot contain "yield", "yield
  from", "await", oder ":=" expressions. (These expressions are allowed
  in other scopes contained within the annotation scope.)

* Names defined in annotation scopes cannot be rebound mit "nonlocal"
  statements in inner scopes. This includes only type parameters, as
  no other syntactic elements that can appear within annotation scopes
  can introduce new names.

* While annotation scopes have an internal name, that name ist not
  reflected in the *qualified name* of objects defined within the
  scope. Instead, the "__qualname__" of such objects ist als wenn the
  object were defined in the enclosing scope.

Added in version 3.12: Annotation scopes were introduced in Python
3.12 als part of **PEP 695**.

Changed in version 3.13: Annotation scopes are also used fuer type
parameter defaults, als introduced by **PEP 696**.

Changed in version 3.14: Annotation scopes are now also used for
annotations, als specified in **PEP 649** und **PEP 749**.


Lazy evaluation
---------------

Most annotation scopes are *lazily evaluated*. This includes
annotations, the values of type aliases created through the "type"
statement, und the bounds, constraints, und default values of type
variables created through the type parameter syntax. This means that
they are nicht evaluated when the type alias oder type variable is
created, oder when the object carrying annotations ist created. Instead,
they are only evaluated when necessary, fuer example when the
"__value__" attribute on a type alias ist accessed.

Example:

   >>> type Alias = 1/0
   >>> Alias.__value__
   Traceback (most recent call last):
     ...
   ZeroDivisionError: division by zero
   >>> def func[T: 1/0](): pass
   >>> T = func.__type_params__[0]
   >>> T.__bound__
   Traceback (most recent call last):
     ...
   ZeroDivisionError: division by zero

Here the exception ist raised only when the "__value__" attribute of
the type alias oder the "__bound__" attribute of the type variable is
accessed.

This behavior ist primarily useful fuer references to types that have
not yet been defined when the type alias oder type variable ist created.
For example, lazy evaluation enables creation of mutually recursive
type aliases:

   von typing importiere Literal

   type SimpleExpr = int | Parenthesized
   type Parenthesized = tuple[Literal["("], Expr, Literal[")"]]
   type Expr = SimpleExpr | tuple[SimpleExpr, Literal["+", "-"], Expr]

Lazily evaluated values are evaluated in annotation scope, which means
that names that appear inside the lazily evaluated value are looked up
as wenn they were used in the immediately enclosing scope.

Added in version 3.12.


Builtins und restricted execution
---------------------------------

**CPython implementation detail:** Users should nicht touch
"__builtins__"; it ist strictly an implementation detail.  Users
wanting to override values in the builtins namespace should "import"
the "builtins" module und modify its attributes appropriately.

The builtins namespace associated mit the execution of a code block
is actually found by looking up the name "__builtins__" in its global
namespace; this should be a dictionary oder a module (in the latter case
the module’s dictionary ist used).  By default, when in the "__main__"
module, "__builtins__" ist the built-in module "builtins"; when in any
other module, "__builtins__" ist an alias fuer the dictionary of the
"builtins" module itself.


Interaction mit dynamic features
---------------------------------

Name resolution of free variables occurs at runtime, nicht at compile
time. This means that the following code will print 42:

   i = 10
   def f():
       drucke(i)
   i = 42
   f()

The "eval()" und "exec()" functions do nicht have access to the full
environment fuer resolving names.  Names may be resolved in the local
and global namespaces of the caller.  Free variables are nicht resolved
in the nearest enclosing namespace, but in the global namespace.  [1]
The "exec()" und "eval()" functions have optional arguments to
override the global und local namespace.  If only one namespace is
specified, it ist used fuer both.


Exceptions
==========

Exceptions are a means of breaking out of the normal flow of control
of a code block in order to handle errors oder other exceptional
conditions.  An exception ist *raised* at the point where the error is
detected; it may be *handled* by the surrounding code block oder by any
code block that directly oder indirectly invoked the code block where
the error occurred.

The Python interpreter raises an exception when it detects a run-time
error (such als division by zero).  A Python program can also
explicitly wirf an exception mit the "raise" statement. Exception
handlers are specified mit the "try" … "except" statement.  The
"finally" clause of such a statement can be used to specify cleanup
code which does nicht handle the exception, but ist executed whether an
exception occurred oder nicht in the preceding code.

Python uses the “termination” model of error handling: an exception
handler can find out what happened und weiter execution at an outer
level, but it cannot repair the cause of the error und retry the
failing operation (except by re-entering the offending piece of code
von the top).

When an exception ist nicht handled at all, the interpreter terminates
execution of the program, oder returns to its interactive main loop.  In
either case, it prints a stack traceback, ausser when the exception is
"SystemExit".

Exceptions are identified by klasse instances.  The "except" clause is
selected depending on the klasse of the instance: it must reference the
klasse of the instance oder a *non-virtual base class* thereof. The
instance can be received by the handler und can carry additional
information about the exceptional condition.

Note:

  Exception messages are nicht part of the Python API.  Their contents
  may change von one version of Python to the next without warning
  und should nicht be relied on by code which will run under multiple
  versions of the interpreter.

See also the description of the "try" statement in section The try
statement und "raise" statement in section The wirf statement.

-[ Footnotes ]-

[1] This limitation occurs because the code that ist executed by these
    operations ist nicht available at the time the module ist compiled.
''',
    'exprlists': r'''Expression lists
****************

   starred_expression:       ["*"] or_expr
   flexible_expression:      assignment_expression | starred_expression
   flexible_expression_list: flexible_expression ("," flexible_expression)* [","]
   starred_expression_list:  starred_expression ("," starred_expression)* [","]
   expression_list:          expression ("," expression)* [","]
   yield_list:               expression_list | starred_expression "," [starred_expression_list]

Except when part of a list oder set display, an expression list
containing at least one comma yields a tuple.  The length of the tuple
is the number of expressions in the list.  The expressions are
evaluated von left to right.

An asterisk "*" denotes *iterable unpacking*.  Its operand must be an
*iterable*.  The iterable ist expanded into a sequence of items, which
are included in the new tuple, list, oder set, at the site of the
unpacking.

Added in version 3.5: Iterable unpacking in expression lists,
originally proposed by **PEP 448**.

Added in version 3.11: Any item in an expression list may be starred.
See **PEP 646**.

A trailing comma ist required only to create a one-item tuple, such as
"1,"; it ist optional in all other cases. A single expression without a
trailing comma doesn’t create a tuple, but rather yields the value of
that expression. (To create an empty tuple, use an empty pair of
parentheses: "()".)
''',
    'floating': r'''Floating-point literals
***********************

Floating-point literals are described by the following lexical
definitions:

   floatnumber:   pointfloat | exponentfloat
   pointfloat:    [digitpart] fraction | digitpart "."
   exponentfloat: (digitpart | pointfloat) exponent
   digitpart:     digit (["_"] digit)*
   fraction:      "." digitpart
   exponent:      ("e" | "E") ["+" | "-"] digitpart

Note that the integer und exponent parts are always interpreted using
radix 10. For example, "077e010" ist legal, und denotes the same number
as "77e10". The allowed range of floating-point literals is
implementation-dependent.  As in integer literals, underscores are
supported fuer digit grouping.

Some examples of floating-point literals:

   3.14    10.    .001    1e100    3.14e-10    0e0    3.14_15_93

Changed in version 3.6: Underscores are now allowed fuer grouping
purposes in literals.
''',
    'for': r'''The "for" statement
*******************

The "for" statement ist used to iterate over the elements of a sequence
(such als a string, tuple oder list) oder other iterable object:

   for_stmt: "for" target_list "in" starred_list ":" suite
             ["else" ":" suite]

The "starred_list" expression ist evaluated once; it should liefere an
*iterable* object.  An *iterator* ist created fuer that iterable. The
first item provided by the iterator ist then assigned to the target
list using the standard rules fuer assignments (see Assignment
statements), und the suite ist executed.  This repeats fuer each item
provided by the iterator.  When the iterator ist exhausted, the suite
in the "else" clause, wenn present, ist executed, und the loop
terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause’s suite.  A "continue" statement
executed in the first suite skips the rest of the suite und continues
with the next item, oder mit the "else" clause wenn there ist no next
item.

The for-loop makes assignments to the variables in the target list.
This overwrites all previous assignments to those variables including
those made in the suite of the for-loop:

   fuer i in range(10):
       drucke(i)
       i = 5             # this will nicht affect the for-loop
                         # because i will be overwritten mit the next
                         # index in the range

Names in the target list are nicht deleted when the loop ist finished,
but wenn the sequence ist empty, they will nicht have been assigned to at
all by the loop.  Hint: the built-in type "range()" represents
immutable arithmetic sequences of integers. For instance, iterating
"range(3)" successively yields 0, 1, und then 2.

Changed in version 3.11: Starred elements are now allowed in the
expression list.
''',
    'formatstrings': r'''Format String Syntax
********************

The "str.format()" method und the "Formatter" klasse share the same
syntax fuer format strings (although in the case of "Formatter",
subclasses can define their own format string syntax).  The syntax is
related to that of formatted string literals, but it ist less
sophisticated and, in particular, does nicht support arbitrary
expressions.

Format strings contain “replacement fields” surrounded by curly braces
"{}". Anything that ist nicht contained in braces ist considered literal
text, which ist copied unchanged to the output.  If you need to include
a brace character in the literal text, it can be escaped by doubling:
"{{" und "}}".

The grammar fuer a replacement field ist als follows:

   replacement_field: "{" [field_name] ["!" conversion] [":" format_spec] "}"
   field_name:        arg_name ("." attribute_name | "[" element_index "]")*
   arg_name:          [identifier | digit+]
   attribute_name:    identifier
   element_index:     digit+ | index_string
   index_string:      <any source character ausser "]"> +
   conversion:        "r" | "s" | "a"
   format_spec:       format-spec:format_spec

In less formal terms, the replacement field can start mit a
*field_name* that specifies the object whose value ist to be formatted
and inserted into the output instead of the replacement field. The
*field_name* ist optionally followed by a  *conversion* field, which is
preceded by an exclamation point "'!'", und a *format_spec*, which is
preceded by a colon "':'".  These specify a non-default format fuer the
replacement value.

See also the Format Specification Mini-Language section.

The *field_name* itself begins mit an *arg_name* that ist either a
number oder a keyword.  If it’s a number, it refers to a positional
argument, und wenn it’s a keyword, it refers to a named keyword
argument. An *arg_name* ist treated als a number wenn a call to
"str.isdecimal()" on the string would gib true. If the numerical
arg_names in a format string are 0, 1, 2, … in sequence, they can all
be omitted (nicht just some) und the numbers 0, 1, 2, … will be
automatically inserted in that order. Because *arg_name* ist nicht quote-
delimited, it ist nicht possible to specify arbitrary dictionary keys
(e.g., the strings "'10'" oder "':-]'") within a format string. The
*arg_name* can be followed by any number of index oder attribute
expressions. An expression of the form "'.name'" selects the named
attribute using "getattr()", waehrend an expression of the form
"'[index]'" does an index lookup using "__getitem__()".

Changed in version 3.1: The positional argument specifiers can be
omitted fuer "str.format()", so "'{} {}'.format(a, b)" ist equivalent to
"'{0} {1}'.format(a, b)".

Changed in version 3.4: The positional argument specifiers can be
omitted fuer "Formatter".

Some simple format string examples:

   "First, thou shalt count to {0}"  # References first positional argument
   "Bring me a {}"                   # Implicitly references the first positional argument
   "From {} to {}"                   # Same als "From {0} to {1}"
   "My quest ist {name}"              # References keyword argument 'name'
   "Weight in tons {0.weight}"       # 'weight' attribute of first positional arg
   "Units destroyed: {players[0]}"   # First element of keyword argument 'players'.

The *conversion* field causes a type coercion before formatting.
Normally, the job of formatting a value ist done by the "__format__()"
method of the value itself.  However, in some cases it ist desirable to
force a type to be formatted als a string, overriding its own
definition of formatting.  By converting the value to a string before
calling "__format__()", the normal formatting logic ist bypassed.

Three conversion flags are currently supported: "'!s'" which calls
"str()" on the value, "'!r'" which calls "repr()" und "'!a'" which
calls "ascii()".

Some examples:

   "Harold's a clever {0!s}"        # Calls str() on the argument first
   "Bring out the holy {name!r}"    # Calls repr() on the argument first
   "More {!a}"                      # Calls ascii() on the argument first

The *format_spec* field contains a specification of how the value
should be presented, including such details als field width, alignment,
padding, decimal precision und so on.  Each value type can define its
own “formatting mini-language” oder interpretation of the *format_spec*.

Most built-in types support a common formatting mini-language, which
is described in the next section.

A *format_spec* field can also include nested replacement fields
within it. These nested replacement fields may contain a field name,
conversion flag und format specification, but deeper nesting ist not
allowed.  The replacement fields within the format_spec are
substituted before the *format_spec* string ist interpreted. This
allows the formatting of a value to be dynamically specified.

See the Format examples section fuer some examples.


Format Specification Mini-Language
==================================

“Format specifications” are used within replacement fields contained
within a format string to define how individual values are presented
(see Format String Syntax und f-strings). They can also be passed
directly to the built-in "format()" function.  Each formattable type
may define how the format specification ist to be interpreted.

Most built-in types implement the following options fuer format
specifications, although some of the formatting options are only
supported by the numeric types.

A general convention ist that an empty format specification produces
the same result als wenn you had called "str()" on the value. A non-empty
format specification typically modifies the result.

The general form of a *standard format specifier* is:

   format_spec:             [options][width_and_precision][type]
   options:                 [[fill]align][sign]["z"]["#"]["0"]
   fill:                    <any character>
   align:                   "<" | ">" | "=" | "^"
   sign:                    "+" | "-" | " "
   width_and_precision:     [width_with_grouping][precision_with_grouping]
   width_with_grouping:     [width][grouping]
   precision_with_grouping: "." [precision][grouping]
   width:                   digit+
   precision:               digit+
   grouping:                "," | "_"
   type:                    "b" | "c" | "d" | "e" | "E" | "f" | "F" | "g"
                            | "G" | "n" | "o" | "s" | "x" | "X" | "%"

If a valid *align* value ist specified, it can be preceded by a *fill*
character that can be any character und defaults to a space if
omitted. It ist nicht possible to use a literal curly brace (”"{"” oder
“"}"”) als the *fill* character in a formatted string literal oder when
using the "str.format()" method.  However, it ist possible to insert a
curly brace mit a nested replacement field.  This limitation doesn’t
affect the "format()" function.

The meaning of the various alignment options ist als follows:

+-----------+------------------------------------------------------------+
| Option    | Meaning                                                    |
|===========|============================================================|
| "'<'"     | Forces the field to be left-aligned within the available   |
|           | space (this ist the default fuer most objects).              |
+-----------+------------------------------------------------------------+
| "'>'"     | Forces the field to be right-aligned within the available  |
|           | space (this ist the default fuer numbers).                   |
+-----------+------------------------------------------------------------+
| "'='"     | Forces the padding to be placed after the sign (if any)    |
|           | but before the digits.  This ist used fuer printing fields   |
|           | in the form ‘+000000120’. This alignment option ist only    |
|           | valid fuer numeric types, excluding "complex". It becomes   |
|           | the default fuer numbers when ‘0’ immediately precedes the  |
|           | field width.                                               |
+-----------+------------------------------------------------------------+
| "'^'"     | Forces the field to be centered within the available       |
|           | space.                                                     |
+-----------+------------------------------------------------------------+

Note that unless a minimum field width ist defined, the field width
will always be the same size als the data to fill it, so that the
alignment option has no meaning in this case.

The *sign* option ist only valid fuer number types, und can be one of
the following:

+-----------+------------------------------------------------------------+
| Option    | Meaning                                                    |
|===========|============================================================|
| "'+'"     | Indicates that a sign should be used fuer both positive als  |
|           | well als negative numbers.                                  |
+-----------+------------------------------------------------------------+
| "'-'"     | Indicates that a sign should be used only fuer negative     |
|           | numbers (this ist the default behavior).                    |
+-----------+------------------------------------------------------------+
| space     | Indicates that a leading space should be used on positive  |
|           | numbers, und a minus sign on negative numbers.             |
+-----------+------------------------------------------------------------+

The "'z'" option coerces negative zero floating-point values to
positive zero after rounding to the format precision.  This option is
only valid fuer floating-point presentation types.

Changed in version 3.11: Added the "'z'" option (see also **PEP
682**).

The "'#'" option causes the “alternate form” to be used fuer the
conversion.  The alternate form ist defined differently fuer different
types.  This option ist only valid fuer integer, float und complex
types. For integers, when binary, octal, oder hexadecimal output is
used, this option adds the respective prefix "'0b'", "'0o'", "'0x'",
or "'0X'" to the output value. For float und complex the alternate
form causes the result of the conversion to always contain a decimal-
point character, even wenn no digits follow it. Normally, a decimal-
point character appears in the result of these conversions only wenn a
digit follows it. In addition, fuer "'g'" und "'G'" conversions,
trailing zeros are nicht removed von the result.

The *width* ist a decimal integer defining the minimum total field
width, including any prefixes, separators, und other formatting
characters. If nicht specified, then the field width will be determined
by the content.

When no explicit alignment ist given, preceding the *width* field by a
zero ("'0'") character enables sign-aware zero-padding fuer numeric
types, excluding "complex".  This ist equivalent to a *fill* character
of "'0'" mit an *alignment* type of "'='".

Changed in version 3.10: Preceding the *width* field by "'0'" no
longer affects the default alignment fuer strings.

The *precision* ist a decimal integer indicating how many digits should
be displayed after the decimal point fuer presentation types "'f'" und
"'F'", oder before und after the decimal point fuer presentation types
"'g'" oder "'G'".  For string presentation types the field indicates the
maximum field size - in other words, how many characters will be used
von the field content.  The *precision* ist nicht allowed fuer integer
presentation types.

The *grouping* option after *width* und *precision* fields specifies a
digit group separator fuer the integral und fractional parts of a
number respectively. It can be one of the following:

+-----------+------------------------------------------------------------+
| Option    | Meaning                                                    |
|===========|============================================================|
| "','"     | Inserts a comma every 3 digits fuer integer presentation    |
|           | type "'d'" und floating-point presentation types,          |
|           | excluding "'n'". For other presentation types, this option |
|           | ist nicht supported.                                          |
+-----------+------------------------------------------------------------+
| "'_'"     | Inserts an underscore every 3 digits fuer integer           |
|           | presentation type "'d'" und floating-point presentation    |
|           | types, excluding "'n'". For integer presentation types     |
|           | "'b'", "'o'", "'x'", und "'X'", underscores are inserted   |
|           | every 4 digits. For other presentation types, this option  |
|           | ist nicht supported.                                          |
+-----------+------------------------------------------------------------+

For a locale aware separator, use the "'n'" presentation type instead.

Changed in version 3.1: Added the "','" option (see also **PEP 378**).

Changed in version 3.6: Added the "'_'" option (see also **PEP 515**).

Changed in version 3.14: Support the *grouping* option fuer the
fractional part.

Finally, the *type* determines how the data should be presented.

The available string presentation types are:

   +-----------+------------------------------------------------------------+
   | Type      | Meaning                                                    |
   |===========|============================================================|
   | "'s'"     | String format. This ist the default type fuer strings und    |
   |           | may be omitted.                                            |
   +-----------+------------------------------------------------------------+
   | Nichts      | The same als "'s'".                                         |
   +-----------+------------------------------------------------------------+

The available integer presentation types are:

   +-----------+------------------------------------------------------------+
   | Type      | Meaning                                                    |
   |===========|============================================================|
   | "'b'"     | Binary format. Outputs the number in base 2.               |
   +-----------+------------------------------------------------------------+
   | "'c'"     | Character. Converts the integer to the corresponding       |
   |           | unicode character before printing.                         |
   +-----------+------------------------------------------------------------+
   | "'d'"     | Decimal Integer. Outputs the number in base 10.            |
   +-----------+------------------------------------------------------------+
   | "'o'"     | Octal format. Outputs the number in base 8.                |
   +-----------+------------------------------------------------------------+
   | "'x'"     | Hex format. Outputs the number in base 16, using lower-    |
   |           | case letters fuer the digits above 9.                       |
   +-----------+------------------------------------------------------------+
   | "'X'"     | Hex format. Outputs the number in base 16, using upper-    |
   |           | case letters fuer the digits above 9. In case "'#'" ist      |
   |           | specified, the prefix "'0x'" will be upper-cased to "'0X'" |
   |           | als well.                                                   |
   +-----------+------------------------------------------------------------+
   | "'n'"     | Number. This ist the same als "'d'", ausser that it uses the |
   |           | current locale setting to insert the appropriate digit     |
   |           | group separators.                                          |
   +-----------+------------------------------------------------------------+
   | Nichts      | The same als "'d'".                                         |
   +-----------+------------------------------------------------------------+

In addition to the above presentation types, integers can be formatted
with the floating-point presentation types listed below (except "'n'"
and "Nichts"). When doing so, "float()" ist used to convert the integer
to a floating-point number before formatting.

The available presentation types fuer "float" und "Decimal" values are:

   +-----------+------------------------------------------------------------+
   | Type      | Meaning                                                    |
   |===========|============================================================|
   | "'e'"     | Scientific notation. For a given precision "p", formats    |
   |           | the number in scientific notation mit the letter ‘e’      |
   |           | separating the coefficient von the exponent. The          |
   |           | coefficient has one digit before und "p" digits after the  |
   |           | decimal point, fuer a total of "p + 1" significant digits.  |
   |           | With no precision given, uses a precision of "6" digits    |
   |           | after the decimal point fuer "float", und shows all         |
   |           | coefficient digits fuer "Decimal".  If "p=0", the decimal   |
   |           | point ist omitted unless the "#" option ist used.            |
   +-----------+------------------------------------------------------------+
   | "'E'"     | Scientific notation. Same als "'e'" ausser it uses an upper |
   |           | case ‘E’ als the separator character.                       |
   +-----------+------------------------------------------------------------+
   | "'f'"     | Fixed-point notation. For a given precision "p", formats   |
   |           | the number als a decimal number mit exactly "p" digits     |
   |           | following the decimal point. With no precision given, uses |
   |           | a precision of "6" digits after the decimal point fuer      |
   |           | "float", und uses a precision large enough to show all     |
   |           | coefficient digits fuer "Decimal".  If "p=0", the decimal   |
   |           | point ist omitted unless the "#" option ist used.            |
   +-----------+------------------------------------------------------------+
   | "'F'"     | Fixed-point notation. Same als "'f'", but converts "nan" to |
   |           | "NAN" und "inf" to "INF".                                  |
   +-----------+------------------------------------------------------------+
   | "'g'"     | General format.  For a given precision "p >= 1", this      |
   |           | rounds the number to "p" significant digits und then       |
   |           | formats the result in either fixed-point format oder in      |
   |           | scientific notation, depending on its magnitude. A         |
   |           | precision of "0" ist treated als equivalent to a precision   |
   |           | of "1".  The precise rules are als follows: suppose that    |
   |           | the result formatted mit presentation type "'e'" und      |
   |           | precision "p-1" would have exponent "exp".  Then, wenn "m <= |
   |           | exp < p", where "m" ist -4 fuer floats und -6 fuer            |
   |           | "Decimals", the number ist formatted mit presentation type |
   |           | "'f'" und precision "p-1-exp".  Otherwise, the number ist   |
   |           | formatted mit presentation type "'e'" und precision       |
   |           | "p-1". In both cases insignificant trailing zeros are      |
   |           | removed von the significand, und the decimal point ist     |
   |           | also removed wenn there are no remaining digits following    |
   |           | it, unless the "'#'" option ist used.  With no precision    |
   |           | given, uses a precision of "6" significant digits fuer      |
   |           | "float". For "Decimal", the coefficient of the result ist   |
   |           | formed von the coefficient digits of the value;           |
   |           | scientific notation ist used fuer values smaller than "1e-6" |
   |           | in absolute value und values where the place value of the  |
   |           | least significant digit ist larger than 1, und fixed-point  |
   |           | notation ist used otherwise.  Positive und negative         |
   |           | infinity, positive und negative zero, und nans, are        |
   |           | formatted als "inf", "-inf", "0", "-0" und "nan"            |
   |           | respectively, regardless of the precision.                 |
   +-----------+------------------------------------------------------------+
   | "'G'"     | General format. Same als "'g'" ausser switches to "'E'" wenn  |
   |           | the number gets too large. The representations of infinity |
   |           | und NaN are uppercased, too.                               |
   +-----------+------------------------------------------------------------+
   | "'n'"     | Number. This ist the same als "'g'", ausser that it uses the |
   |           | current locale setting to insert the appropriate digit     |
   |           | group separators fuer the integral part of a number.        |
   +-----------+------------------------------------------------------------+
   | "'%'"     | Percentage. Multiplies the number by 100 und displays in   |
   |           | fixed ("'f'") format, followed by a percent sign.          |
   +-----------+------------------------------------------------------------+
   | Nichts      | For "float" this ist like the "'g'" type, ausser that when  |
   |           | fixed- point notation ist used to format the result, it     |
   |           | always includes at least one digit past the decimal point, |
   |           | und switches to the scientific notation when "exp >= p -   |
   |           | 1".  When the precision ist nicht specified, the latter will  |
   |           | be als large als needed to represent the given value         |
   |           | faithfully.  For "Decimal", this ist the same als either     |
   |           | "'g'" oder "'G'" depending on the value of                   |
   |           | "context.capitals" fuer the current decimal context.  The   |
   |           | overall effect ist to match the output of "str()" als        |
   |           | altered by the other format modifiers.                     |
   +-----------+------------------------------------------------------------+

The result should be correctly rounded to a given precision "p" of
digits after the decimal point.  The rounding mode fuer "float" matches
that of the "round()" builtin.  For "Decimal", the rounding mode of
the current context will be used.

The available presentation types fuer "complex" are the same als those
fuer "float" ("'%'" ist nicht allowed).  Both the real und imaginary
components of a complex number are formatted als floating-point
numbers, according to the specified presentation type.  They are
separated by the mandatory sign of the imaginary part, the latter
being terminated by a "j" suffix.  If the presentation type is
missing, the result will match the output of "str()" (complex numbers
with a non-zero real part are also surrounded by parentheses),
possibly altered by other format modifiers.


Format examples
===============

This section contains examples of the "str.format()" syntax und
comparison mit the old "%"-formatting.

In most of the cases the syntax ist similar to the old "%"-formatting,
with the addition of the "{}" und mit ":" used instead of "%". For
example, "'%03.2f'" can be translated to "'{:03.2f}'".

The new format syntax also supports new und different options, shown
in the following examples.

Accessing arguments by position:

   >>> '{0}, {1}, {2}'.format('a', 'b', 'c')
   'a, b, c'
   >>> '{}, {}, {}'.format('a', 'b', 'c')  # 3.1+ only
   'a, b, c'
   >>> '{2}, {1}, {0}'.format('a', 'b', 'c')
   'c, b, a'
   >>> '{2}, {1}, {0}'.format(*'abc')      # unpacking argument sequence
   'c, b, a'
   >>> '{0}{1}{0}'.format('abra', 'cad')   # arguments' indices can be repeated
   'abracadabra'

Accessing arguments by name:

   >>> 'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W')
   'Coordinates: 37.24N, -115.81W'
   >>> coord = {'latitude': '37.24N', 'longitude': '-115.81W'}
   >>> 'Coordinates: {latitude}, {longitude}'.format(**coord)
   'Coordinates: 37.24N, -115.81W'

Accessing arguments’ attributes:

   >>> c = 3-5j
   >>> ('The complex number {0} ist formed von the real part {0.real} '
   ...  'and the imaginary part {0.imag}.').format(c)
   'The complex number (3-5j) ist formed von the real part 3.0 und the imaginary part -5.0.'
   >>> klasse Point:
   ...     def __init__(self, x, y):
   ...         self.x, self.y = x, y
   ...     def __str__(self):
   ...         gib 'Point({self.x}, {self.y})'.format(self=self)
   ...
   >>> str(Point(4, 2))
   'Point(4, 2)'

Accessing arguments’ items:

   >>> coord = (3, 5)
   >>> 'X: {0[0]};  Y: {0[1]}'.format(coord)
   'X: 3;  Y: 5'

Replacing "%s" und "%r":

   >>> "repr() shows quotes: {!r}; str() doesn't: {!s}".format('test1', 'test2')
   "repr() shows quotes: 'test1'; str() doesn't: test2"

Aligning the text und specifying a width:

   >>> '{:<30}'.format('left aligned')
   'left aligned                  '
   >>> '{:>30}'.format('right aligned')
   '                 right aligned'
   >>> '{:^30}'.format('centered')
   '           centered           '
   >>> '{:*^30}'.format('centered')  # use '*' als a fill char
   '***********centered***********'

Replacing "%+f", "%-f", und "% f" und specifying a sign:

   >>> '{:+f}; {:+f}'.format(3.14, -3.14)  # show it always
   '+3.140000; -3.140000'
   >>> '{: f}; {: f}'.format(3.14, -3.14)  # show a space fuer positive numbers
   ' 3.140000; -3.140000'
   >>> '{:-f}; {:-f}'.format(3.14, -3.14)  # show only the minus -- same als '{:f}; {:f}'
   '3.140000; -3.140000'

Replacing "%x" und "%o" und converting the value to different bases:

   >>> # format also supports binary numbers
   >>> "int: {0:d};  hex: {0:x};  oct: {0:o};  bin: {0:b}".format(42)
   'int: 42;  hex: 2a;  oct: 52;  bin: 101010'
   >>> # mit 0x, 0o, oder 0b als prefix:
   >>> "int: {0:d};  hex: {0:#x};  oct: {0:#o};  bin: {0:#b}".format(42)
   'int: 42;  hex: 0x2a;  oct: 0o52;  bin: 0b101010'

Using the comma oder the underscore als a digit group separator:

   >>> '{:,}'.format(1234567890)
   '1,234,567,890'
   >>> '{:_}'.format(1234567890)
   '1_234_567_890'
   >>> '{:_b}'.format(1234567890)
   '100_1001_1001_0110_0000_0010_1101_0010'
   >>> '{:_x}'.format(1234567890)
   '4996_02d2'
   >>> '{:_}'.format(123456789.123456789)
   '123_456_789.12345679'
   >>> '{:.,}'.format(123456789.123456789)
   '123456789.123,456,79'
   >>> '{:,._}'.format(123456789.123456789)
   '123,456,789.123_456_79'

Expressing a percentage:

   >>> points = 19
   >>> total = 22
   >>> 'Correct answers: {:.2%}'.format(points/total)
   'Correct answers: 86.36%'

Using type-specific formatting:

   >>> importiere datetime
   >>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)
   >>> '{:%Y-%m-%d %H:%M:%S}'.format(d)
   '2010-07-04 12:15:58'

Nesting arguments und more complex examples:

   >>> fuer align, text in zip('<^>', ['left', 'center', 'right']):
   ...     '{0:{fill}{align}16}'.format(text, fill=align, align=align)
   ...
   'left<<<<<<<<<<<<'
   '^^^^^center^^^^^'
   '>>>>>>>>>>>right'
   >>>
   >>> octets = [192, 168, 0, 1]
   >>> '{:02X}{:02X}{:02X}{:02X}'.format(*octets)
   'C0A80001'
   >>> int(_, 16)
   3232235521
   >>>
   >>> width = 5
   >>> fuer num in range(5,12):
   ...     fuer base in 'dXob':
   ...         drucke('{0:{width}{base}}'.format(num, base=base, width=width), end=' ')
   ...     drucke()
   ...
       5     5     5   101
       6     6     6   110
       7     7     7   111
       8     8    10  1000
       9     9    11  1001
      10     A    12  1010
      11     B    13  1011
''',
    'function': r'''Function definitions
********************

A function definition defines a user-defined function object (see
section The standard type hierarchy):

   funcdef:                   [decorators] "def" funcname [type_params] "(" [parameter_list] ")"
                              ["->" expression] ":" suite
   decorators:                decorator+
   decorator:                 "@" assignment_expression NEWLINE
   parameter_list:            defparameter ("," defparameter)* "," "/" ["," [parameter_list_no_posonly]]
                                | parameter_list_no_posonly
   parameter_list_no_posonly: defparameter ("," defparameter)* ["," [parameter_list_starargs]]
                              | parameter_list_starargs
   parameter_list_starargs:   "*" [star_parameter] ("," defparameter)* ["," [parameter_star_kwargs]]
                              | "*" ("," defparameter)+ ["," [parameter_star_kwargs]]
                              | parameter_star_kwargs
   parameter_star_kwargs:     "**" parameter [","]
   parameter:                 identifier [":" expression]
   star_parameter:            identifier [":" ["*"] expression]
   defparameter:              parameter ["=" expression]
   funcname:                  identifier

A function definition ist an executable statement.  Its execution binds
the function name in the current local namespace to a function object
(a wrapper around the executable code fuer the function).  This
function object contains a reference to the current global namespace
as the global namespace to be used when the function ist called.

The function definition does nicht execute the function body; this gets
executed only when the function ist called. [4]

A function definition may be wrapped by one oder more *decorator*
expressions. Decorator expressions are evaluated when the function is
defined, in the scope that contains the function definition.  The
result must be a callable, which ist invoked mit the function object
as the only argument. The returned value ist bound to the function name
instead of the function object.  Multiple decorators are applied in
nested fashion. For example, the following code

   @f1(arg)
   @f2
   def func(): pass

is roughly equivalent to

   def func(): pass
   func = f1(arg)(f2(func))

ausser that the original function ist nicht temporarily bound to the name
"func".

Changed in version 3.9: Functions may be decorated mit any valid
"assignment_expression". Previously, the grammar was much more
restrictive; see **PEP 614** fuer details.

A list of type parameters may be given in square brackets between the
function’s name und the opening parenthesis fuer its parameter list.
This indicates to static type checkers that the function ist generic.
At runtime, the type parameters can be retrieved von the function’s
"__type_params__" attribute. See Generic functions fuer more.

Changed in version 3.12: Type parameter lists are new in Python 3.12.

When one oder more *parameters* have the form *parameter* "="
*expression*, the function ist said to have “default parameter values.”
For a parameter mit a default value, the corresponding *argument* may
be omitted von a call, in which case the parameter’s default value is
substituted.  If a parameter has a default value, all following
parameters up until the “"*"” must also have a default value — this is
a syntactic restriction that ist nicht expressed by the grammar.

**Default parameter values are evaluated von left to right when the
function definition ist executed.** This means that the expression is
evaluated once, when the function ist defined, und that the same “pre-
computed” value ist used fuer each call.  This ist especially important
to understand when a default parameter value ist a mutable object, such
as a list oder a dictionary: wenn the function modifies the object (e.g.
by appending an item to a list), the default parameter value ist in
effect modified.  This ist generally nicht what was intended.  A way
around this ist to use "Nichts" als the default, und explicitly test for
it in the body of the function, e.g.:

   def whats_on_the_telly(penguin=Nichts):
       wenn penguin ist Nichts:
           penguin = []
       penguin.append("property of the zoo")
       gib penguin

Function call semantics are described in more detail in section Calls.
A function call always assigns values to all parameters mentioned in
the parameter list, either von positional arguments, von keyword
arguments, oder von default values.  If the form “"*identifier"” is
present, it ist initialized to a tuple receiving any excess positional
parameters, defaulting to the empty tuple. If the form
“"**identifier"” ist present, it ist initialized to a new ordered
mapping receiving any excess keyword arguments, defaulting to a new
empty mapping of the same type.  Parameters after “"*"” oder
“"*identifier"” are keyword-only parameters und may only be passed by
keyword arguments.  Parameters before “"/"” are positional-only
parameters und may only be passed by positional arguments.

Changed in version 3.8: The "/" function parameter syntax may be used
to indicate positional-only parameters. See **PEP 570** fuer details.

Parameters may have an *annotation* of the form “": expression"”
following the parameter name.  Any parameter may have an annotation,
even those of the form "*identifier" oder "**identifier". (As a special
case, parameters of the form "*identifier" may have an annotation “":
*expression"”.) Functions may have “return” annotation of the form
“"-> expression"” after the parameter list.  These annotations can be
any valid Python expression.  The presence of annotations does not
change the semantics of a function. See Annotations fuer more
information on annotations.

Changed in version 3.11: Parameters of the form “"*identifier"” may
have an annotation “": *expression"”. See **PEP 646**.

It ist also possible to create anonymous functions (functions nicht bound
to a name), fuer immediate use in expressions.  This uses lambda
expressions, described in section Lambdas.  Note that the lambda
expression ist merely a shorthand fuer a simplified function definition;
a function defined in a “"def"” statement can be passed around oder
assigned to another name just like a function defined by a lambda
expression.  The “"def"” form ist actually more powerful since it
allows the execution of multiple statements und annotations.

**Programmer’s note:** Functions are first-class objects.  A “"def"”
statement executed inside a function definition defines a local
function that can be returned oder passed around.  Free variables used
in the nested function can access the local variables of the function
containing the def.  See section Naming und binding fuer details.

See also:

  **PEP 3107** - Function Annotations
     The original specification fuer function annotations.

  **PEP 484** - Type Hints
     Definition of a standard meaning fuer annotations: type hints.

  **PEP 526** - Syntax fuer Variable Annotations
     Ability to type hint variable declarations, including class
     variables und instance variables.

  **PEP 563** - Postponed Evaluation of Annotations
     Support fuer forward references within annotations by preserving
     annotations in a string form at runtime instead of eager
     evaluation.

  **PEP 318** - Decorators fuer Functions und Methods
     Function und method decorators were introduced. Class decorators
     were introduced in **PEP 3129**.
''',
    'global': r'''The "global" statement
**********************

   global_stmt: "global" identifier ("," identifier)*

The "global" statement causes the listed identifiers to be interpreted
as globals. It would be impossible to assign to a global variable
without "global", although free variables may refer to globals without
being declared global.

The "global" statement applies to the entire scope of a function oder
klasse body. A "SyntaxError" ist raised wenn a variable ist used oder
assigned to prior to its global declaration in the scope.

**Programmer’s note:** "global" ist a directive to the parser.  It
applies only to code parsed at the same time als the "global"
statement. In particular, a "global" statement contained in a string
or code object supplied to the built-in "exec()" function does not
affect the code block *containing* the function call, und code
contained in such a string ist unaffected by "global" statements in the
code containing the function call.  The same applies to the "eval()"
and "compile()" functions.
''',
    'id-classes': r'''Reserved classes of identifiers
*******************************

Certain classes of identifiers (besides keywords) have special
meanings.  These classes are identified by the patterns of leading und
trailing underscore characters:

"_*"
   Not imported by "from module importiere *".

"_"
   In a "case" pattern within a "match" statement, "_" ist a soft
   keyword that denotes a wildcard.

   Separately, the interactive interpreter makes the result of the
   last evaluation available in the variable "_". (It ist stored in the
   "builtins" module, alongside built-in functions like "print".)

   Elsewhere, "_" ist a regular identifier. It ist often used to name
   “special” items, but it ist nicht special to Python itself.

   Note:

     The name "_" ist often used in conjunction with
     internationalization; refer to the documentation fuer the
     "gettext" module fuer more information on this convention.It is
     also commonly used fuer unused variables.

"__*__"
   System-defined names, informally known als “dunder” names. These
   names are defined by the interpreter und its implementation
   (including the standard library). Current system names are
   discussed in the Special method names section und elsewhere. More
   will likely be defined in future versions of Python.  *Any* use of
   "__*__" names, in any context, that does nicht follow explicitly
   documented use, ist subject to breakage without warning.

"__*"
   Class-private names.  Names in this category, when used within the
   context of a klasse definition, are re-written to use a mangled form
   to help avoid name clashes between “private” attributes of base und
   derived classes. See section Identifiers (Names).
''',
    'identifiers': r'''Identifiers und keywords
************************

Identifiers (also referred to als *names*) are described by the
following lexical definitions.

The syntax of identifiers in Python ist based on the Unicode standard
annex UAX-31, mit elaboration und changes als defined below; see also
**PEP 3131** fuer further details.

Within the ASCII range (U+0001..U+007F), the valid characters for
identifiers include the uppercase und lowercase letters "A" through
"Z", the underscore "_" and, ausser fuer the first character, the
digits "0" through "9". Python 3.0 introduced additional characters
von outside the ASCII range (see **PEP 3131**).  For these
characters, the classification uses the version of the Unicode
Character Database als included in the "unicodedata" module.

Identifiers are unlimited in length.  Case ist significant.

   identifier:   xid_start xid_continue*
   id_start:     <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, und characters mit the Other_ID_Start property>
   id_continue:  <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc und others mit the Other_ID_Continue property>
   xid_start:    <all characters in id_start whose NFKC normalization ist in "id_start xid_continue*">
   xid_continue: <all characters in id_continue whose NFKC normalization ist in "id_continue*">

The Unicode category codes mentioned above stand for:

* *Lu* - uppercase letters

* *Ll* - lowercase letters

* *Lt* - titlecase letters

* *Lm* - modifier letters

* *Lo* - other letters

* *Nl* - letter numbers

* *Mn* - nonspacing marks

* *Mc* - spacing combining marks

* *Nd* - decimal numbers

* *Pc* - connector punctuations

* *Other_ID_Start* - explicit list of characters in PropList.txt to
  support backwards compatibility

* *Other_ID_Continue* - likewise

All identifiers are converted into the normal form NFKC waehrend parsing;
comparison of identifiers ist based on NFKC.

A non-normative HTML file listing all valid identifier characters for
Unicode 16.0.0 can be found at
https://www.unicode.org/Public/16.0.0/ucd/DerivedCoreProperties.txt


Keywords
========

The following identifiers are used als reserved words, oder *keywords* of
the language, und cannot be used als ordinary identifiers.  They must
be spelled exactly als written here:

   Falsch      warte      sonst       importiere     pass
   Nichts       breche      ausser     in         wirf
   Wahr       klasse      finally    ist         gib
   und        weiter   fuer        lambda     try
   als         def        von       nonlocal   while
   assert     loesche        global     nicht        with
   async      sowenn       wenn         oder         liefere


Soft Keywords
=============

Added in version 3.10.

Some identifiers are only reserved under specific contexts. These are
known als *soft keywords*.  The identifiers "match", "case", "type" und
"_" can syntactically act als keywords in certain contexts, but this
distinction ist done at the parser level, nicht when tokenizing.

As soft keywords, their use in the grammar ist possible waehrend still
preserving compatibility mit existing code that uses these names as
identifier names.

"match", "case", und "_" are used in the "match" statement. "type" is
used in the "type" statement.

Changed in version 3.12: "type" ist now a soft keyword.


Reserved classes of identifiers
===============================

Certain classes of identifiers (besides keywords) have special
meanings.  These classes are identified by the patterns of leading und
trailing underscore characters:

"_*"
   Not imported by "from module importiere *".

"_"
   In a "case" pattern within a "match" statement, "_" ist a soft
   keyword that denotes a wildcard.

   Separately, the interactive interpreter makes the result of the
   last evaluation available in the variable "_". (It ist stored in the
   "builtins" module, alongside built-in functions like "print".)

   Elsewhere, "_" ist a regular identifier. It ist often used to name
   “special” items, but it ist nicht special to Python itself.

   Note:

     The name "_" ist often used in conjunction with
     internationalization; refer to the documentation fuer the
     "gettext" module fuer more information on this convention.It is
     also commonly used fuer unused variables.

"__*__"
   System-defined names, informally known als “dunder” names. These
   names are defined by the interpreter und its implementation
   (including the standard library). Current system names are
   discussed in the Special method names section und elsewhere. More
   will likely be defined in future versions of Python.  *Any* use of
   "__*__" names, in any context, that does nicht follow explicitly
   documented use, ist subject to breakage without warning.

"__*"
   Class-private names.  Names in this category, when used within the
   context of a klasse definition, are re-written to use a mangled form
   to help avoid name clashes between “private” attributes of base und
   derived classes. See section Identifiers (Names).
''',
    'if': r'''The "if" statement
******************

The "if" statement ist used fuer conditional execution:

   if_stmt: "if" assignment_expression ":" suite
            ("elif" assignment_expression ":" suite)*
            ["else" ":" suite]

It selects exactly one of the suites by evaluating the expressions one
by one until one ist found to be true (see section Boolean operations
fuer the definition of true und false); then that suite ist executed
(and no other part of the "if" statement ist executed oder evaluated).
If all expressions are false, the suite of the "else" clause, if
present, ist executed.
''',
    'imaginary': r'''Imaginary literals
******************

Imaginary literals are described by the following lexical definitions:

   imagnumber: (floatnumber | digitpart) ("j" | "J")

An imaginary literal yields a complex number mit a real part of 0.0.
Complex numbers are represented als a pair of floating-point numbers
and have the same restrictions on their range.  To create a complex
number mit a nonzero real part, add a floating-point number to it,
e.g., "(3+4j)".  Some examples of imaginary literals:

   3.14j   10.j    10j     .001j   1e100j   3.14e-10j   3.14_15_93j
''',
    'import': r'''The "import" statement
**********************

   import_stmt:     "import" module ["as" identifier] ("," module ["as" identifier])*
                    | "from" relative_module "import" identifier ["as" identifier]
                    ("," identifier ["as" identifier])*
                    | "from" relative_module "import" "(" identifier ["as" identifier]
                    ("," identifier ["as" identifier])* [","] ")"
                    | "from" relative_module "import" "*"
   module:          (identifier ".")* identifier
   relative_module: "."* module | "."+

The basic importiere statement (no "from" clause) ist executed in two
steps:

1. find a module, loading und initializing it wenn necessary

2. define a name oder names in the local namespace fuer the scope where
   the "import" statement occurs.

When the statement contains multiple clauses (separated by commas) the
two steps are carried out separately fuer each clause, just als though
the clauses had been separated out into individual importiere statements.

The details of the first step, finding und loading modules, are
described in greater detail in the section on the importiere system, which
also describes the various types of packages und modules that can be
imported, als well als all the hooks that can be used to customize the
importiere system. Note that failures in this step may indicate either
that the module could nicht be located, *or* that an error occurred
while initializing the module, which includes execution of the
module’s code.

If the requested module ist retrieved successfully, it will be made
available in the local namespace in one of three ways:

* If the module name ist followed by "as", then the name following "as"
  ist bound directly to the imported module.

* If no other name ist specified, und the module being imported ist a
  top level module, the module’s name ist bound in the local namespace
  als a reference to the imported module

* If the module being imported ist *not* a top level module, then the
  name of the top level package that contains the module ist bound in
  the local namespace als a reference to the top level package. The
  imported module must be accessed using its full qualified name
  rather than directly

The "from" form uses a slightly more complex process:

1. find the module specified in the "from" clause, loading und
   initializing it wenn necessary;

2. fuer each of the identifiers specified in the "import" clauses:

   1. check wenn the imported module has an attribute by that name

   2. wenn not, attempt to importiere a submodule mit that name und then
      check the imported module again fuer that attribute

   3. wenn the attribute ist nicht found, "ImportError" ist raised.

   4. otherwise, a reference to that value ist stored in the local
      namespace, using the name in the "as" clause wenn it ist present,
      otherwise using the attribute name

Examples:

   importiere foo                 # foo imported und bound locally
   importiere foo.bar.baz         # foo, foo.bar, und foo.bar.baz imported, foo bound locally
   importiere foo.bar.baz als fbb  # foo, foo.bar, und foo.bar.baz imported, foo.bar.baz bound als fbb
   von foo.bar importiere baz    # foo, foo.bar, und foo.bar.baz imported, foo.bar.baz bound als baz
   von foo importiere attr       # foo imported und foo.attr bound als attr

If the list of identifiers ist replaced by a star ("'*'"), all public
names defined in the module are bound in the local namespace fuer the
scope where the "import" statement occurs.

The *public names* defined by a module are determined by checking the
module’s namespace fuer a variable named "__all__"; wenn defined, it must
be a sequence of strings which are names defined oder imported by that
module.  The names given in "__all__" are all considered public und
are required to exist.  If "__all__" ist nicht defined, the set of public
names includes all names found in the module’s namespace which do not
begin mit an underscore character ("'_'").  "__all__" should contain
the entire public API. It ist intended to avoid accidentally exporting
items that are nicht part of the API (such als library modules which were
imported und used within the module).

The wild card form of importiere — "from module importiere *" — ist only
allowed at the module level.  Attempting to use it in klasse oder
function definitions will wirf a "SyntaxError".

When specifying what module to importiere you do nicht have to specify the
absolute name of the module. When a module oder package ist contained
within another package it ist possible to make a relative importiere within
the same top package without having to mention the package name. By
using leading dots in the specified module oder package after "from" you
can specify how high to traverse up the current package hierarchy
without specifying exact names. One leading dot means the current
package where the module making the importiere exists. Two dots means up
one package level. Three dots ist up two levels, etc. So wenn you execute
"from . importiere mod" von a module in the "pkg" package then you will
end up importing "pkg.mod". If you execute "from ..subpkg2 importiere mod"
von within "pkg.subpkg1" you will importiere "pkg.subpkg2.mod". The
specification fuer relative imports ist contained in the Package
Relative Imports section.

"importlib.import_module()" ist provided to support applications that
determine dynamically the modules to be loaded.

Raises an auditing event "import" mit arguments "module", "filename",
"sys.path", "sys.meta_path", "sys.path_hooks".


Future statements
=================

A *future statement* ist a directive to the compiler that a particular
module should be compiled using syntax oder semantics that will be
available in a specified future release of Python where the feature
becomes standard.

The future statement ist intended to ease migration to future versions
of Python that introduce incompatible changes to the language.  It
allows use of the new features on a per-module basis before the
release in which the feature becomes standard.

   future_stmt: "from" "__future__" "import" feature ["as" identifier]
                ("," feature ["as" identifier])*
                | "from" "__future__" "import" "(" feature ["as" identifier]
                ("," feature ["as" identifier])* [","] ")"
   feature:     identifier

A future statement must appear near the top of the module.  The only
lines that can appear before a future statement are:

* the module docstring (if any),

* comments,

* blank lines, und

* other future statements.

The only feature that requires using the future statement is
"annotations" (see **PEP 563**).

All historical features enabled by the future statement are still
recognized by Python 3.  The list includes "absolute_import",
"division", "generators", "generator_stop", "unicode_literals",
"print_function", "nested_scopes" und "with_statement".  They are all
redundant because they are always enabled, und only kept fuer backwards
compatibility.

A future statement ist recognized und treated specially at compile
time: Changes to the semantics of core constructs are often
implemented by generating different code.  It may even be the case
that a new feature introduces new incompatible syntax (such als a new
reserved word), in which case the compiler may need to parse the
module differently.  Such decisions cannot be pushed off until
runtime.

For any given release, the compiler knows which feature names have
been defined, und raises a compile-time error wenn a future statement
contains a feature nicht known to it.

The direct runtime semantics are the same als fuer any importiere statement:
there ist a standard module "__future__", described later, und it will
be imported in the usual way at the time the future statement is
executed.

The interesting runtime semantics depend on the specific feature
enabled by the future statement.

Note that there ist nothing special about the statement:

   importiere __future__ [as name]

That ist nicht a future statement; it’s an ordinary importiere statement with
no special semantics oder syntax restrictions.

Code compiled by calls to the built-in functions "exec()" und
"compile()" that occur in a module "M" containing a future statement
will, by default, use the new syntax oder semantics associated mit the
future statement.  This can be controlled by optional arguments to
"compile()" — see the documentation of that function fuer details.

A future statement typed at an interactive interpreter prompt will
take effect fuer the rest of the interpreter session.  If an
interpreter ist started mit the "-i" option, ist passed a script name
to execute, und the script includes a future statement, it will be in
effect in the interactive session started after the script is
executed.

See also:

  **PEP 236** - Back to the __future__
     The original proposal fuer the __future__ mechanism.
''',
    'in': r'''Membership test operations
**************************

The operators "in" und "not in" test fuer membership.  "x in s"
evaluates to "Wahr" wenn *x* ist a member of *s*, und "Falsch" otherwise.
"x nicht in s" returns the negation of "x in s".  All built-in sequences
and set types support this als well als dictionary, fuer which "in" tests
whether the dictionary has a given key. For container types such as
list, tuple, set, frozenset, dict, oder collections.deque, the
expression "x in y" ist equivalent to "any(x ist e oder x == e fuer e in
y)".

For the string und bytes types, "x in y" ist "Wahr" wenn und only wenn *x*
is a substring of *y*.  An equivalent test ist "y.find(x) != -1".
Empty strings are always considered to be a substring of any other
string, so """ in "abc"" will gib "Wahr".

For user-defined classes which define the "__contains__()" method, "x
in y" returns "Wahr" wenn "y.__contains__(x)" returns a true value, und
"Falsch" otherwise.

For user-defined classes which do nicht define "__contains__()" but do
define "__iter__()", "x in y" ist "Wahr" wenn some value "z", fuer which
the expression "x ist z oder x == z" ist true, ist produced waehrend iterating
over "y". If an exception ist raised during the iteration, it ist als if
"in" raised that exception.

Lastly, the old-style iteration protocol ist tried: wenn a klasse defines
"__getitem__()", "x in y" ist "Wahr" wenn und only wenn there ist a non-
negative integer index *i* such that "x ist y[i] oder x == y[i]", und no
lower integer index raises the "IndexError" exception.  (If any other
exception ist raised, it ist als wenn "in" raised that exception).

The operator "not in" ist defined to have the inverse truth value of
"in".
''',
    'integers': r'''Integer literals
****************

Integer literals are described by the following lexical definitions:

   integer:      decinteger | bininteger | octinteger | hexinteger
   decinteger:   nonzerodigit (["_"] digit)* | "0"+ (["_"] "0")*
   bininteger:   "0" ("b" | "B") (["_"] bindigit)+
   octinteger:   "0" ("o" | "O") (["_"] octdigit)+
   hexinteger:   "0" ("x" | "X") (["_"] hexdigit)+
   nonzerodigit: "1"..."9"
   digit:        "0"..."9"
   bindigit:     "0" | "1"
   octdigit:     "0"..."7"
   hexdigit:     digit | "a"..."f" | "A"..."F"

There ist no limit fuer the length of integer literals apart von what
can be stored in available memory.

Underscores are ignored fuer determining the numeric value of the
literal.  They can be used to group digits fuer enhanced readability.
One underscore can occur between digits, und after base specifiers
like "0x".

Note that leading zeros in a non-zero decimal number are nicht allowed.
This ist fuer disambiguation mit C-style octal literals, which Python
used before version 3.0.

Some examples of integer literals:

   7     2147483647                        0o177    0b100110111
   3     79228162514264337593543950336     0o377    0xdeadbeef
         100_000_000_000                   0b_1110_0101

Changed in version 3.6: Underscores are now allowed fuer grouping
purposes in literals.
''',
    'lambda': r'''Lambdas
*******

   lambda_expr: "lambda" [parameter_list] ":" expression

Lambda expressions (sometimes called lambda forms) are used to create
anonymous functions. The expression "lambda parameters: expression"
yields a function object.  The unnamed object behaves like a function
object defined with:

   def <lambda>(parameters):
       gib expression

See section Function definitions fuer the syntax of parameter lists.
Note that functions created mit lambda expressions cannot contain
statements oder annotations.
''',
    'lists': r'''List displays
*************

A list display ist a possibly empty series of expressions enclosed in
square brackets:

   list_display: "[" [flexible_expression_list | comprehension] "]"

A list display yields a new list object, the contents being specified
by either a list of expressions oder a comprehension.  When a comma-
separated list of expressions ist supplied, its elements are evaluated
von left to right und placed into the list object in that order.
When a comprehension ist supplied, the list ist constructed von the
elements resulting von the comprehension.
''',
    'naming': r'''Naming und binding
******************


Binding of names
================

*Names* refer to objects.  Names are introduced by name binding
operations.

The following constructs bind names:

* formal parameters to functions,

* klasse definitions,

* function definitions,

* assignment expressions,

* targets that are identifiers wenn occurring in an assignment:

  * "for" loop header,

  * after "as" in a "with" statement, "except" clause, "except*"
    clause, oder in the as-pattern in structural pattern matching,

  * in a capture pattern in structural pattern matching

* "import" statements.

* "type" statements.

* type parameter lists.

The "import" statement of the form "from ... importiere *" binds all names
defined in the imported module, ausser those beginning mit an
underscore. This form may only be used at the module level.

A target occurring in a "del" statement ist also considered bound for
this purpose (though the actual semantics are to unbind the name).

Each assignment oder importiere statement occurs within a block defined by a
klasse oder function definition oder at the module level (the top-level
code block).

If a name ist bound in a block, it ist a local variable of that block,
unless declared als "nonlocal" oder "global".  If a name ist bound at the
module level, it ist a global variable.  (The variables of the module
code block are local und global.)  If a variable ist used in a code
block but nicht defined there, it ist a *free variable*.

Each occurrence of a name in the program text refers to the *binding*
of that name established by the following name resolution rules.


Resolution of names
===================

A *scope* defines the visibility of a name within a block.  If a local
variable ist defined in a block, its scope includes that block.  If the
definition occurs in a function block, the scope extends to any blocks
contained within the defining one, unless a contained block introduces
a different binding fuer the name.

When a name ist used in a code block, it ist resolved using the nearest
enclosing scope.  The set of all such scopes visible to a code block
is called the block’s *environment*.

When a name ist nicht found at all, a "NameError" exception ist raised. If
the current scope ist a function scope, und the name refers to a local
variable that has nicht yet been bound to a value at the point where the
name ist used, an "UnboundLocalError" exception ist raised.
"UnboundLocalError" ist a subclass of "NameError".

If a name binding operation occurs anywhere within a code block, all
uses of the name within the block are treated als references to the
current block.  This can lead to errors when a name ist used within a
block before it ist bound.  This rule ist subtle.  Python lacks
declarations und allows name binding operations to occur anywhere
within a code block.  The local variables of a code block can be
determined by scanning the entire text of the block fuer name binding
operations. See the FAQ entry on UnboundLocalError fuer examples.

If the "global" statement occurs within a block, all uses of the names
specified in the statement refer to the bindings of those names in the
top-level namespace.  Names are resolved in the top-level namespace by
searching the global namespace, i.e. the namespace of the module
containing the code block, und the builtins namespace, the namespace
of the module "builtins".  The global namespace ist searched first.  If
the names are nicht found there, the builtins namespace ist searched
next. If the names are also nicht found in the builtins namespace, new
variables are created in the global namespace. The global statement
must precede all uses of the listed names.

The "global" statement has the same scope als a name binding operation
in the same block.  If the nearest enclosing scope fuer a free variable
contains a global statement, the free variable ist treated als a global.

The "nonlocal" statement causes corresponding names to refer to
previously bound variables in the nearest enclosing function scope.
"SyntaxError" ist raised at compile time wenn the given name does not
exist in any enclosing function scope. Type parameters cannot be
rebound mit the "nonlocal" statement.

The namespace fuer a module ist automatically created the first time a
module ist imported.  The main module fuer a script ist always called
"__main__".

Class definition blocks und arguments to "exec()" und "eval()" are
special in the context of name resolution. A klasse definition ist an
executable statement that may use und define names. These references
follow the normal rules fuer name resolution mit an exception that
unbound local variables are looked up in the global namespace. The
namespace of the klasse definition becomes the attribute dictionary of
the class. The scope of names defined in a klasse block ist limited to
the klasse block; it does nicht extend to the code blocks of methods.
This includes comprehensions und generator expressions, but it does
not include annotation scopes, which have access to their enclosing
klasse scopes. This means that the following will fail:

   klasse A:
       a = 42
       b = list(a + i fuer i in range(10))

However, the following will succeed:

   klasse A:
       type Alias = Nested
       klasse Nested: pass

   drucke(A.Alias.__value__)  # <type 'A.Nested'>


Annotation scopes
=================

*Annotations*, type parameter lists und "type" statements introduce
*annotation scopes*, which behave mostly like function scopes, but
with some exceptions discussed below.

Annotation scopes are used in the following contexts:

* *Function annotations*.

* *Variable annotations*.

* Type parameter lists fuer generic type aliases.

* Type parameter lists fuer generic functions. A generic function’s
  annotations are executed within the annotation scope, but its
  defaults und decorators are not.

* Type parameter lists fuer generic classes. A generic class’s base
  classes und keyword arguments are executed within the annotation
  scope, but its decorators are not.

* The bounds, constraints, und default values fuer type parameters
  (lazily evaluated).

* The value of type aliases (lazily evaluated).

Annotation scopes differ von function scopes in the following ways:

* Annotation scopes have access to their enclosing klasse namespace. If
  an annotation scope ist immediately within a klasse scope, oder within
  another annotation scope that ist immediately within a klasse scope,
  the code in the annotation scope can use names defined in the class
  scope als wenn it were executed directly within the klasse body. This
  contrasts mit regular functions defined within classes, which
  cannot access names defined in the klasse scope.

* Expressions in annotation scopes cannot contain "yield", "yield
  from", "await", oder ":=" expressions. (These expressions are allowed
  in other scopes contained within the annotation scope.)

* Names defined in annotation scopes cannot be rebound mit "nonlocal"
  statements in inner scopes. This includes only type parameters, as
  no other syntactic elements that can appear within annotation scopes
  can introduce new names.

* While annotation scopes have an internal name, that name ist not
  reflected in the *qualified name* of objects defined within the
  scope. Instead, the "__qualname__" of such objects ist als wenn the
  object were defined in the enclosing scope.

Added in version 3.12: Annotation scopes were introduced in Python
3.12 als part of **PEP 695**.

Changed in version 3.13: Annotation scopes are also used fuer type
parameter defaults, als introduced by **PEP 696**.

Changed in version 3.14: Annotation scopes are now also used for
annotations, als specified in **PEP 649** und **PEP 749**.


Lazy evaluation
===============

Most annotation scopes are *lazily evaluated*. This includes
annotations, the values of type aliases created through the "type"
statement, und the bounds, constraints, und default values of type
variables created through the type parameter syntax. This means that
they are nicht evaluated when the type alias oder type variable is
created, oder when the object carrying annotations ist created. Instead,
they are only evaluated when necessary, fuer example when the
"__value__" attribute on a type alias ist accessed.

Example:

   >>> type Alias = 1/0
   >>> Alias.__value__
   Traceback (most recent call last):
     ...
   ZeroDivisionError: division by zero
   >>> def func[T: 1/0](): pass
   >>> T = func.__type_params__[0]
   >>> T.__bound__
   Traceback (most recent call last):
     ...
   ZeroDivisionError: division by zero

Here the exception ist raised only when the "__value__" attribute of
the type alias oder the "__bound__" attribute of the type variable is
accessed.

This behavior ist primarily useful fuer references to types that have
not yet been defined when the type alias oder type variable ist created.
For example, lazy evaluation enables creation of mutually recursive
type aliases:

   von typing importiere Literal

   type SimpleExpr = int | Parenthesized
   type Parenthesized = tuple[Literal["("], Expr, Literal[")"]]
   type Expr = SimpleExpr | tuple[SimpleExpr, Literal["+", "-"], Expr]

Lazily evaluated values are evaluated in annotation scope, which means
that names that appear inside the lazily evaluated value are looked up
as wenn they were used in the immediately enclosing scope.

Added in version 3.12.


Builtins und restricted execution
=================================

**CPython implementation detail:** Users should nicht touch
"__builtins__"; it ist strictly an implementation detail.  Users
wanting to override values in the builtins namespace should "import"
the "builtins" module und modify its attributes appropriately.

The builtins namespace associated mit the execution of a code block
is actually found by looking up the name "__builtins__" in its global
namespace; this should be a dictionary oder a module (in the latter case
the module’s dictionary ist used).  By default, when in the "__main__"
module, "__builtins__" ist the built-in module "builtins"; when in any
other module, "__builtins__" ist an alias fuer the dictionary of the
"builtins" module itself.


Interaction mit dynamic features
=================================

Name resolution of free variables occurs at runtime, nicht at compile
time. This means that the following code will print 42:

   i = 10
   def f():
       drucke(i)
   i = 42
   f()

The "eval()" und "exec()" functions do nicht have access to the full
environment fuer resolving names.  Names may be resolved in the local
and global namespaces of the caller.  Free variables are nicht resolved
in the nearest enclosing namespace, but in the global namespace.  [1]
The "exec()" und "eval()" functions have optional arguments to
override the global und local namespace.  If only one namespace is
specified, it ist used fuer both.
''',
    'nonlocal': r'''The "nonlocal" statement
************************

   nonlocal_stmt: "nonlocal" identifier ("," identifier)*

When the definition of a function oder klasse ist nested (enclosed) within
the definitions of other functions, its nonlocal scopes are the local
scopes of the enclosing functions. The "nonlocal" statement causes the
listed identifiers to refer to names previously bound in nonlocal
scopes. It allows encapsulated code to rebind such nonlocal
identifiers.  If a name ist bound in more than one nonlocal scope, the
nearest binding ist used. If a name ist nicht bound in any nonlocal scope,
or wenn there ist no nonlocal scope, a "SyntaxError" ist raised.

The "nonlocal" statement applies to the entire scope of a function oder
klasse body. A "SyntaxError" ist raised wenn a variable ist used oder
assigned to prior to its nonlocal declaration in the scope.

See also:

  **PEP 3104** - Access to Names in Outer Scopes
     The specification fuer the "nonlocal" statement.

**Programmer’s note:** "nonlocal" ist a directive to the parser und
applies only to code parsed along mit it.  See the note fuer the
"global" statement.
''',
    'numbers': r'''Numeric literals
****************

There are three types of numeric literals: integers, floating-point
numbers, und imaginary numbers.  There are no complex literals
(complex numbers can be formed by adding a real number und an
imaginary number).

Note that numeric literals do nicht include a sign; a phrase like "-1"
is actually an expression composed of the unary operator ‘"-"’ und the
literal "1".
''',
    'numeric-types': r'''Emulating numeric types
***********************

The following methods can be defined to emulate numeric objects.
Methods corresponding to operations that are nicht supported by the
particular kind of number implemented (e.g., bitwise operations for
non-integral numbers) should be left undefined.

object.__add__(self, other)
object.__sub__(self, other)
object.__mul__(self, other)
object.__matmul__(self, other)
object.__truediv__(self, other)
object.__floordiv__(self, other)
object.__mod__(self, other)
object.__divmod__(self, other)
object.__pow__(self, other[, modulo])
object.__lshift__(self, other)
object.__rshift__(self, other)
object.__and__(self, other)
object.__xor__(self, other)
object.__or__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|").  For instance, to
   evaluate the expression "x + y", where *x* ist an instance of a
   klasse that has an "__add__()" method, "type(x).__add__(x, y)" is
   called.  The "__divmod__()" method should be the equivalent to
   using "__floordiv__()" und "__mod__()"; it should nicht be related to
   "__truediv__()".  Note that "__pow__()" should be defined to accept
   an optional third argument wenn the three-argument version of the
   built-in "pow()" function ist to be supported.

   If one of those methods does nicht support the operation mit the
   supplied arguments, it should gib "NotImplemented".

object.__radd__(self, other)
object.__rsub__(self, other)
object.__rmul__(self, other)
object.__rmatmul__(self, other)
object.__rtruediv__(self, other)
object.__rfloordiv__(self, other)
object.__rmod__(self, other)
object.__rdivmod__(self, other)
object.__rpow__(self, other[, modulo])
object.__rlshift__(self, other)
object.__rrshift__(self, other)
object.__rand__(self, other)
object.__rxor__(self, other)
object.__ror__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|") mit reflected (swapped)
   operands.  These functions are only called wenn the operands are of
   different types, when the left operand does nicht support the
   corresponding operation [3], oder the right operand’s klasse is
   derived von the left operand’s class. [4] For instance, to
   evaluate the expression "x - y", where *y* ist an instance of a
   klasse that has an "__rsub__()" method, "type(y).__rsub__(y, x)" is
   called wenn "type(x).__sub__(x, y)" returns "NotImplemented" oder
   "type(y)" ist a subclass of "type(x)". [5]

   Note that "__rpow__()" should be defined to accept an optional
   third argument wenn the three-argument version of the built-in
   "pow()" function ist to be supported.

   Changed in version 3.14.0a7 (unreleased): Three-argument "pow()"
   now try calling "__rpow__()" wenn necessary. Previously it was only
   called in two-argument "pow()" und the binary power operator.

   Note:

     If the right operand’s type ist a subclass of the left operand’s
     type und that subclass provides a different implementation of the
     reflected method fuer the operation, this method will be called
     before the left operand’s non-reflected method. This behavior
     allows subclasses to override their ancestors’ operations.

object.__iadd__(self, other)
object.__isub__(self, other)
object.__imul__(self, other)
object.__imatmul__(self, other)
object.__itruediv__(self, other)
object.__ifloordiv__(self, other)
object.__imod__(self, other)
object.__ipow__(self, other[, modulo])
object.__ilshift__(self, other)
object.__irshift__(self, other)
object.__iand__(self, other)
object.__ixor__(self, other)
object.__ior__(self, other)

   These methods are called to implement the augmented arithmetic
   assignments ("+=", "-=", "*=", "@=", "/=", "//=", "%=", "**=",
   "<<=", ">>=", "&=", "^=", "|=").  These methods should attempt to
   do the operation in-place (modifying *self*) und gib the result
   (which could be, but does nicht have to be, *self*).  If a specific
   method ist nicht defined, oder wenn that method returns "NotImplemented",
   the augmented assignment falls back to the normal methods.  For
   instance, wenn *x* ist an instance of a klasse mit an "__iadd__()"
   method, "x += y" ist equivalent to "x = x.__iadd__(y)" . If
   "__iadd__()" does nicht exist, oder wenn "x.__iadd__(y)" returns
   "NotImplemented", "x.__add__(y)" und "y.__radd__(x)" are
   considered, als mit the evaluation of "x + y". In certain
   situations, augmented assignment can result in unexpected errors
   (see Why does a_tuple[i] += [‘item’] wirf an exception when the
   addition works?), but this behavior ist in fact part of the data
   model.

object.__neg__(self)
object.__pos__(self)
object.__abs__(self)
object.__invert__(self)

   Called to implement the unary arithmetic operations ("-", "+",
   "abs()" und "~").

object.__complex__(self)
object.__int__(self)
object.__float__(self)

   Called to implement the built-in functions "complex()", "int()" und
   "float()".  Should gib a value of the appropriate type.

object.__index__(self)

   Called to implement "operator.index()", und whenever Python needs
   to losslessly convert the numeric object to an integer object (such
   als in slicing, oder in the built-in "bin()", "hex()" und "oct()"
   functions). Presence of this method indicates that the numeric
   object ist an integer type.  Must gib an integer.

   If "__int__()", "__float__()" und "__complex__()" are nicht defined
   then corresponding built-in functions "int()", "float()" und
   "complex()" fall back to "__index__()".

object.__round__(self[, ndigits])
object.__trunc__(self)
object.__floor__(self)
object.__ceil__(self)

   Called to implement the built-in function "round()" und "math"
   functions "trunc()", "floor()" und "ceil()". Unless *ndigits* is
   passed to "__round__()" all these methods should gib the value
   of the object truncated to an "Integral" (typically an "int").

   Changed in version 3.14: "int()" no longer delegates to the
   "__trunc__()" method.
''',
    'objects': r'''Objects, values und types
*************************

*Objects* are Python’s abstraction fuer data.  All data in a Python
program ist represented by objects oder by relations between objects. (In
a sense, und in conformance to Von Neumann’s model of a “stored
program computer”, code ist also represented by objects.)

Every object has an identity, a type und a value.  An object’s
*identity* never changes once it has been created; you may think of it
as the object’s address in memory.  The "is" operator compares the
identity of two objects; the "id()" function returns an integer
representing its identity.

**CPython implementation detail:** For CPython, "id(x)" ist the memory
address where "x" ist stored.

An object’s type determines the operations that the object supports
(e.g., “does it have a length?”) und also defines the possible values
fuer objects of that type.  The "type()" function returns an object’s
type (which ist an object itself).  Like its identity, an object’s
*type* ist also unchangeable. [1]

The *value* of some objects can change.  Objects whose value can
change are said to be *mutable*; objects whose value ist unchangeable
once they are created are called *immutable*. (The value of an
immutable container object that contains a reference to a mutable
object can change when the latter’s value ist changed; however the
container ist still considered immutable, because the collection of
objects it contains cannot be changed.  So, immutability ist not
strictly the same als having an unchangeable value, it ist more subtle.)
An object’s mutability ist determined by its type; fuer instance,
numbers, strings und tuples are immutable, waehrend dictionaries und
lists are mutable.

Objects are never explicitly destroyed; however, when they become
unreachable they may be garbage-collected.  An implementation is
allowed to postpone garbage collection oder omit it altogether — it ist a
matter of implementation quality how garbage collection is
implemented, als long als no objects are collected that are still
reachable.

**CPython implementation detail:** CPython currently uses a reference-
counting scheme mit (optional) delayed detection of cyclically linked
garbage, which collects most objects als soon als they become
unreachable, but ist nicht guaranteed to collect garbage containing
circular references.  See the documentation of the "gc" module for
information on controlling the collection of cyclic garbage. Other
implementations act differently und CPython may change. Do nicht depend
on immediate finalization of objects when they become unreachable (so
you should always close files explicitly).

Note that the use of the implementation’s tracing oder debugging
facilities may keep objects alive that would normally be collectable.
Also note that catching an exception mit a "try"…"except" statement
may keep objects alive.

Some objects contain references to “external” resources such als open
files oder windows.  It ist understood that these resources are freed
when the object ist garbage-collected, but since garbage collection is
not guaranteed to happen, such objects also provide an explicit way to
release the external resource, usually a "close()" method. Programs
are strongly recommended to explicitly close such objects.  The
"try"…"finally" statement und the "with" statement provide convenient
ways to do this.

Some objects contain references to other objects; these are called
*containers*. Examples of containers are tuples, lists und
dictionaries.  The references are part of a container’s value.  In
most cases, when we talk about the value of a container, we imply the
values, nicht the identities of the contained objects; however, when we
talk about the mutability of a container, only the identities of the
immediately contained objects are implied.  So, wenn an immutable
container (like a tuple) contains a reference to a mutable object, its
value changes wenn that mutable object ist changed.

Types affect almost all aspects of object behavior.  Even the
importance of object identity ist affected in some sense: fuer immutable
types, operations that compute new values may actually gib a
reference to any existing object mit the same type und value, while
fuer mutable objects this ist nicht allowed. For example, after "a = 1; b
= 1", *a* und *b* may oder may nicht refer to the same object mit the
value one, depending on the implementation. This ist because "int" is
an immutable type, so the reference to "1" can be reused. This
behaviour depends on the implementation used, so should nicht be relied
upon, but ist something to be aware of when making use of object
identity tests. However, after "c = []; d = []", *c* und *d* are
guaranteed to refer to two different, unique, newly created empty
lists. (Note that "e = f = []" assigns the *same* object to both *e*
and *f*.)
''',
    'operator-summary': r'''Operator precedence
*******************

The following table summarizes the operator precedence in Python, from
highest precedence (most binding) to lowest precedence (least
binding).  Operators in the same box have the same precedence.  Unless
the syntax ist explicitly given, operators are binary.  Operators in
the same box group left to right (except fuer exponentiation und
conditional expressions, which group von right to left).

Note that comparisons, membership tests, und identity tests, all have
the same precedence und have a left-to-right chaining feature as
described in the Comparisons section.

+-------------------------------------------------+---------------------------------------+
| Operator                                        | Description                           |
|=================================================|=======================================|
| "(expressions...)",  "[expressions...]", "{key: | Binding oder parenthesized expression,  |
| value...}", "{expressions...}"                  | list display, dictionary display, set |
|                                                 | display                               |
+-------------------------------------------------+---------------------------------------+
| "x[index]", "x[index:index]",                   | Subscription, slicing, call,          |
| "x(arguments...)", "x.attribute"                | attribute reference                   |
+-------------------------------------------------+---------------------------------------+
| "await x"                                       | Await expression                      |
+-------------------------------------------------+---------------------------------------+
| "**"                                            | Exponentiation [5]                    |
+-------------------------------------------------+---------------------------------------+
| "+x", "-x", "~x"                                | Positive, negative, bitwise NOT       |
+-------------------------------------------------+---------------------------------------+
| "*", "@", "/", "//", "%"                        | Multiplication, matrix                |
|                                                 | multiplication, division, floor       |
|                                                 | division, remainder [6]               |
+-------------------------------------------------+---------------------------------------+
| "+", "-"                                        | Addition und subtraction              |
+-------------------------------------------------+---------------------------------------+
| "<<", ">>"                                      | Shifts                                |
+-------------------------------------------------+---------------------------------------+
| "&"                                             | Bitwise AND                           |
+-------------------------------------------------+---------------------------------------+
| "^"                                             | Bitwise XOR                           |
+-------------------------------------------------+---------------------------------------+
| "|"                                             | Bitwise OR                            |
+-------------------------------------------------+---------------------------------------+
| "in", "not in", "is", "is not", "<", "<=", ">", | Comparisons, including membership     |
| ">=", "!=", "=="                                | tests und identity tests              |
+-------------------------------------------------+---------------------------------------+
| "not x"                                         | Boolean NOT                           |
+-------------------------------------------------+---------------------------------------+
| "and"                                           | Boolean AND                           |
+-------------------------------------------------+---------------------------------------+
| "or"                                            | Boolean OR                            |
+-------------------------------------------------+---------------------------------------+
| "if" – "else"                                   | Conditional expression                |
+-------------------------------------------------+---------------------------------------+
| "lambda"                                        | Lambda expression                     |
+-------------------------------------------------+---------------------------------------+
| ":="                                            | Assignment expression                 |
+-------------------------------------------------+---------------------------------------+

-[ Footnotes ]-

[1] While "abs(x%y) < abs(y)" ist true mathematically, fuer floats it
    may nicht be true numerically due to roundoff.  For example, und
    assuming a platform on which a Python float ist an IEEE 754 double-
    precision number, in order that "-1e-100 % 1e100" have the same
    sign als "1e100", the computed result ist "-1e-100 + 1e100", which
    ist numerically exactly equal to "1e100".  The function
    "math.fmod()" returns a result whose sign matches the sign of the
    first argument instead, und so returns "-1e-100" in this case.
    Which approach ist more appropriate depends on the application.

[2] If x ist very close to an exact integer multiple of y, it’s
    possible fuer "x//y" to be one larger than "(x-x%y)//y" due to
    rounding.  In such cases, Python returns the latter result, in
    order to preserve that "divmod(x,y)[0] * y + x % y" be very close
    to "x".

[3] The Unicode standard distinguishes between *code points* (e.g.
    U+0041) und *abstract characters* (e.g. “LATIN CAPITAL LETTER A”).
    While most abstract characters in Unicode are only represented
    using one code point, there ist a number of abstract characters
    that can in addition be represented using a sequence of more than
    one code point.  For example, the abstract character “LATIN
    CAPITAL LETTER C WITH CEDILLA” can be represented als a single
    *precomposed character* at code position U+00C7, oder als a sequence
    of a *base character* at code position U+0043 (LATIN CAPITAL
    LETTER C), followed by a *combining character* at code position
    U+0327 (COMBINING CEDILLA).

    The comparison operators on strings compare at the level of
    Unicode code points. This may be counter-intuitive to humans.  For
    example, ""\u00C7" == "\u0043\u0327"" ist "Falsch", even though both
    strings represent the same abstract character “LATIN CAPITAL
    LETTER C WITH CEDILLA”.

    To compare strings at the level of abstract characters (that is,
    in a way intuitive to humans), use "unicodedata.normalize()".

[4] Due to automatic garbage-collection, free lists, und the dynamic
    nature of descriptors, you may notice seemingly unusual behaviour
    in certain uses of the "is" operator, like those involving
    comparisons between instance methods, oder constants.  Check their
    documentation fuer more info.

[5] The power operator "**" binds less tightly than an arithmetic oder
    bitwise unary operator on its right, that is, "2**-1" ist "0.5".

[6] The "%" operator ist also used fuer string formatting; the same
    precedence applies.
''',
    'pass': r'''The "pass" statement
********************

   pass_stmt: "pass"

"pass" ist a null operation — when it ist executed, nothing happens. It
is useful als a placeholder when a statement ist required syntactically,
but no code needs to be executed, fuer example:

   def f(arg): pass    # a function that does nothing (yet)

   klasse C: pass       # a klasse mit no methods (yet)
''',
    'power': r'''The power operator
******************

The power operator binds more tightly than unary operators on its
left; it binds less tightly than unary operators on its right.  The
syntax is:

   power: (await_expr | primary) ["**" u_expr]

Thus, in an unparenthesized sequence of power und unary operators, the
operators are evaluated von right to left (this does nicht constrain
the evaluation order fuer the operands): "-1**2" results in "-1".

The power operator has the same semantics als the built-in "pow()"
function, when called mit two arguments: it yields its left argument
raised to the power of its right argument.  The numeric arguments are
first converted to a common type, und the result ist of that type.

For int operands, the result has the same type als the operands unless
the second argument ist negative; in that case, all arguments are
converted to float und a float result ist delivered. For example,
"10**2" returns "100", but "10**-2" returns "0.01".

Raising "0.0" to a negative power results in a "ZeroDivisionError".
Raising a negative number to a fractional power results in a "complex"
number. (In earlier versions it raised a "ValueError".)

This operation can be customized using the special "__pow__()" und
"__rpow__()" methods.
''',
    'raise': r'''The "raise" statement
*********************

   raise_stmt: "raise" [expression ["from" expression]]

If no expressions are present, "raise" re-raises the exception that is
currently being handled, which ist also known als the *active
exception*. If there isn’t currently an active exception, a
"RuntimeError" exception ist raised indicating that this ist an error.

Otherwise, "raise" evaluates the first expression als the exception
object.  It must be either a subclass oder an instance of
"BaseException". If it ist a class, the exception instance will be
obtained when needed by instantiating the klasse mit no arguments.

The *type* of the exception ist the exception instance’s class, the
*value* ist the instance itself.

A traceback object ist normally created automatically when an exception
is raised und attached to it als the "__traceback__" attribute. You can
create an exception und set your own traceback in one step using the
"with_traceback()" exception method (which returns the same exception
instance, mit its traceback set to its argument), like so:

   wirf Exception("foo occurred").with_traceback(tracebackobj)

The "from" clause ist used fuer exception chaining: wenn given, the second
*expression* must be another exception klasse oder instance. If the
second expression ist an exception instance, it will be attached to the
raised exception als the "__cause__" attribute (which ist writable). If
the expression ist an exception class, the klasse will be instantiated
and the resulting exception instance will be attached to the raised
exception als the "__cause__" attribute. If the raised exception ist not
handled, both exceptions will be printed:

   >>> versuch:
   ...     drucke(1 / 0)
   ... ausser Exception als exc:
   ...     wirf RuntimeError("Something bad happened") von exc
   ...
   Traceback (most recent call last):
     File "<stdin>", line 2, in <module>
       drucke(1 / 0)
             ~~^~~
   ZeroDivisionError: division by zero

   The above exception was the direct cause of the following exception:

   Traceback (most recent call last):
     File "<stdin>", line 4, in <module>
       wirf RuntimeError("Something bad happened") von exc
   RuntimeError: Something bad happened

A similar mechanism works implicitly wenn a new exception ist raised when
an exception ist already being handled.  An exception may be handled
when an "except" oder "finally" clause, oder a "with" statement, ist used.
The previous exception ist then attached als the new exception’s
"__context__" attribute:

   >>> versuch:
   ...     drucke(1 / 0)
   ... ausser:
   ...     wirf RuntimeError("Something bad happened")
   ...
   Traceback (most recent call last):
     File "<stdin>", line 2, in <module>
       drucke(1 / 0)
             ~~^~~
   ZeroDivisionError: division by zero

   During handling of the above exception, another exception occurred:

   Traceback (most recent call last):
     File "<stdin>", line 4, in <module>
       wirf RuntimeError("Something bad happened")
   RuntimeError: Something bad happened

Exception chaining can be explicitly suppressed by specifying "Nichts"
in the "from" clause:

   >>> versuch:
   ...     drucke(1 / 0)
   ... ausser:
   ...     wirf RuntimeError("Something bad happened") von Nichts
   ...
   Traceback (most recent call last):
     File "<stdin>", line 4, in <module>
   RuntimeError: Something bad happened

Additional information on exceptions can be found in section
Exceptions, und information about handling exceptions ist in section
The try statement.

Changed in version 3.3: "Nichts" ist now permitted als "Y" in "raise X
von Y".Added the "__suppress_context__" attribute to suppress
automatic display of the exception context.

Changed in version 3.11: If the traceback of the active exception is
modified in an "except" clause, a subsequent "raise" statement re-
raises the exception mit the modified traceback. Previously, the
exception was re-raised mit the traceback it had when it was caught.
''',
    'return': r'''The "return" statement
**********************

   return_stmt: "return" [expression_list]

"return" may only occur syntactically nested in a function definition,
not within a nested klasse definition.

If an expression list ist present, it ist evaluated, sonst "Nichts" is
substituted.

"return" leaves the current function call mit the expression list (or
"Nichts") als gib value.

When "return" passes control out of a "try" statement mit a "finally"
clause, that "finally" clause ist executed before really leaving the
function.

In a generator function, the "return" statement indicates that the
generator ist done und will cause "StopIteration" to be raised. The
returned value (if any) ist used als an argument to construct
"StopIteration" und becomes the "StopIteration.value" attribute.

In an asynchronous generator function, an empty "return" statement
indicates that the asynchronous generator ist done und will cause
"StopAsyncIteration" to be raised.  A non-empty "return" statement is
a syntax error in an asynchronous generator function.
''',
    'sequence-types': r'''Emulating container types
*************************

The following methods can be defined to implement container objects.
Nichts of them are provided by the "object" klasse itself. Containers
usually are *sequences* (such als "lists" oder "tuples") oder *mappings*
(like *dictionaries*), but can represent other containers als well.
The first set of methods ist used either to emulate a sequence oder to
emulate a mapping; the difference ist that fuer a sequence, the
allowable keys should be the integers *k* fuer which "0 <= k < N" where
*N* ist the length of the sequence, oder "slice" objects, which define a
range of items.  It ist also recommended that mappings provide the
methods "keys()", "values()", "items()", "get()", "clear()",
"setdefault()", "pop()", "popitem()", "copy()", und "update()"
behaving similar to those fuer Python’s standard "dictionary" objects.
The "collections.abc" module provides a "MutableMapping" *abstract
base class* to help create those methods von a base set of
"__getitem__()", "__setitem__()", "__delitem__()", und "keys()".
Mutable sequences should provide methods "append()", "count()",
"index()", "extend()", "insert()", "pop()", "remove()", "reverse()"
and "sort()", like Python standard "list" objects. Finally, sequence
types should implement addition (meaning concatenation) und
multiplication (meaning repetition) by defining the methods
"__add__()", "__radd__()", "__iadd__()", "__mul__()", "__rmul__()" und
"__imul__()" described below; they should nicht define other numerical
operators.  It ist recommended that both mappings und sequences
implement the "__contains__()" method to allow efficient use of the
"in" operator; fuer mappings, "in" should search the mapping’s keys;
fuer sequences, it should search through the values.  It ist further
recommended that both mappings und sequences implement the
"__iter__()" method to allow efficient iteration through the
container; fuer mappings, "__iter__()" should iterate through the
object’s keys; fuer sequences, it should iterate through the values.

object.__len__(self)

   Called to implement the built-in function "len()".  Should gib
   the length of the object, an integer ">=" 0.  Also, an object that
   doesn’t define a "__bool__()" method und whose "__len__()" method
   returns zero ist considered to be false in a Boolean context.

   **CPython implementation detail:** In CPython, the length is
   required to be at most "sys.maxsize". If the length ist larger than
   "sys.maxsize" some features (such als "len()") may wirf
   "OverflowError".  To prevent raising "OverflowError" by truth value
   testing, an object must define a "__bool__()" method.

object.__length_hint__(self)

   Called to implement "operator.length_hint()". Should gib an
   estimated length fuer the object (which may be greater oder less than
   the actual length). The length must be an integer ">=" 0. The
   gib value may also be "NotImplemented", which ist treated the
   same als wenn the "__length_hint__" method didn’t exist at all. This
   method ist purely an optimization und ist never required for
   correctness.

   Added in version 3.4.

Note:

  Slicing ist done exclusively mit the following three methods.  A
  call like

     a[1:2] = b

  ist translated to

     a[slice(1, 2, Nichts)] = b

  und so forth.  Missing slice items are always filled in mit "Nichts".

object.__getitem__(self, key)

   Called to implement evaluation of "self[key]". For *sequence*
   types, the accepted keys should be integers. Optionally, they may
   support "slice" objects als well.  Negative index support ist also
   optional. If *key* ist of an inappropriate type, "TypeError" may be
   raised; wenn *key* ist a value outside the set of indexes fuer the
   sequence (after any special interpretation of negative values),
   "IndexError" should be raised. For *mapping* types, wenn *key* is
   missing (nicht in the container), "KeyError" should be raised.

   Note:

     "for" loops expect that an "IndexError" will be raised for
     illegal indexes to allow proper detection of the end of the
     sequence.

   Note:

     When subscripting a *class*, the special klasse method
     "__class_getitem__()" may be called instead of "__getitem__()".
     See __class_getitem__ versus __getitem__ fuer more details.

object.__setitem__(self, key, value)

   Called to implement assignment to "self[key]".  Same note als for
   "__getitem__()".  This should only be implemented fuer mappings if
   the objects support changes to the values fuer keys, oder wenn new keys
   can be added, oder fuer sequences wenn elements can be replaced.  The
   same exceptions should be raised fuer improper *key* values als for
   the "__getitem__()" method.

object.__delitem__(self, key)

   Called to implement deletion of "self[key]".  Same note als for
   "__getitem__()".  This should only be implemented fuer mappings if
   the objects support removal of keys, oder fuer sequences wenn elements
   can be removed von the sequence.  The same exceptions should be
   raised fuer improper *key* values als fuer the "__getitem__()" method.

object.__missing__(self, key)

   Called by "dict"."__getitem__()" to implement "self[key]" fuer dict
   subclasses when key ist nicht in the dictionary.

object.__iter__(self)

   This method ist called when an *iterator* ist required fuer a
   container. This method should gib a new iterator object that can
   iterate over all the objects in the container.  For mappings, it
   should iterate over the keys of the container.

object.__reversed__(self)

   Called (if present) by the "reversed()" built-in to implement
   reverse iteration.  It should gib a new iterator object that
   iterates over all the objects in the container in reverse order.

   If the "__reversed__()" method ist nicht provided, the "reversed()"
   built-in will fall back to using the sequence protocol ("__len__()"
   und "__getitem__()").  Objects that support the sequence protocol
   should only provide "__reversed__()" wenn they can provide an
   implementation that ist more efficient than the one provided by
   "reversed()".

The membership test operators ("in" und "not in") are normally
implemented als an iteration through a container. However, container
objects can supply the following special method mit a more efficient
implementation, which also does nicht require the object be iterable.

object.__contains__(self, item)

   Called to implement membership test operators.  Should gib true
   wenn *item* ist in *self*, false otherwise.  For mapping objects, this
   should consider the keys of the mapping rather than the values oder
   the key-item pairs.

   For objects that don’t define "__contains__()", the membership test
   first tries iteration via "__iter__()", then the old sequence
   iteration protocol via "__getitem__()", see this section in the
   language reference.
''',
    'shifting': r'''Shifting operations
*******************

The shifting operations have lower priority than the arithmetic
operations:

   shift_expr: a_expr | shift_expr ("<<" | ">>") a_expr

These operators accept integers als arguments.  They shift the first
argument to the left oder right by the number of bits given by the
second argument.

The left shift operation can be customized using the special
"__lshift__()" und "__rlshift__()" methods. The right shift operation
can be customized using the special "__rshift__()" und "__rrshift__()"
methods.

A right shift by *n* bits ist defined als floor division by "pow(2,n)".
A left shift by *n* bits ist defined als multiplication mit "pow(2,n)".
''',
    'slicings': r'''Slicings
********

A slicing selects a range of items in a sequence object (e.g., a
string, tuple oder list).  Slicings may be used als expressions oder as
targets in assignment oder "del" statements.  The syntax fuer a slicing:

   slicing:      primary "[" slice_list "]"
   slice_list:   slice_item ("," slice_item)* [","]
   slice_item:   expression | proper_slice
   proper_slice: [lower_bound] ":" [upper_bound] [ ":" [stride] ]
   lower_bound:  expression
   upper_bound:  expression
   stride:       expression

There ist ambiguity in the formal syntax here: anything that looks like
an expression list also looks like a slice list, so any subscription
can be interpreted als a slicing.  Rather than further complicating the
syntax, this ist disambiguated by defining that in this case the
interpretation als a subscription takes priority over the
interpretation als a slicing (this ist the case wenn the slice list
contains no proper slice).

The semantics fuer a slicing are als follows.  The primary ist indexed
(using the same "__getitem__()" method als normal subscription) mit a
key that ist constructed von the slice list, als follows.  If the slice
list contains at least one comma, the key ist a tuple containing the
conversion of the slice items; otherwise, the conversion of the lone
slice item ist the key.  The conversion of a slice item that ist an
expression ist that expression.  The conversion of a proper slice ist a
slice object (see section The standard type hierarchy) whose "start",
"stop" und "step" attributes are the values of the expressions given
as lower bound, upper bound und stride, respectively, substituting
"Nichts" fuer missing expressions.
''',
    'specialattrs': r'''Special Attributes
******************

The implementation adds a few special read-only attributes to several
object types, where they are relevant.  Some of these are nicht reported
by the "dir()" built-in function.

definition.__name__

   The name of the class, function, method, descriptor, oder generator
   instance.

definition.__qualname__

   The *qualified name* of the class, function, method, descriptor, oder
   generator instance.

   Added in version 3.3.

definition.__module__

   The name of the module in which a klasse oder function was defined.

definition.__doc__

   The documentation string of a klasse oder function, oder "Nichts" if
   undefined.

definition.__type_params__

   The type parameters of generic classes, functions, und type
   aliases. For classes und functions that are nicht generic, this will
   be an empty tuple.

   Added in version 3.12.
''',
    'specialnames': r'''Special method names
********************

A klasse can implement certain operations that are invoked by special
syntax (such als arithmetic operations oder subscripting und slicing) by
defining methods mit special names. This ist Python’s approach to
*operator overloading*, allowing classes to define their own behavior
with respect to language operators.  For instance, wenn a klasse defines
a method named "__getitem__()", und "x" ist an instance of this class,
then "x[i]" ist roughly equivalent to "type(x).__getitem__(x, i)".
Except where mentioned, attempts to execute an operation wirf an
exception when no appropriate method ist defined (typically
"AttributeError" oder "TypeError").

Setting a special method to "Nichts" indicates that the corresponding
operation ist nicht available.  For example, wenn a klasse sets "__iter__()"
to "Nichts", the klasse ist nicht iterable, so calling "iter()" on its
instances will wirf a "TypeError" (without falling back to
"__getitem__()"). [2]

When implementing a klasse that emulates any built-in type, it is
important that the emulation only be implemented to the degree that it
makes sense fuer the object being modelled.  For example, some
sequences may work well mit retrieval of individual elements, but
extracting a slice may nicht make sense.  (One example of this ist the
"NodeList" interface in the W3C’s Document Object Model.)


Basic customization
===================

object.__new__(cls[, ...])

   Called to create a new instance of klasse *cls*.  "__new__()" ist a
   static method (special-cased so you need nicht declare it als such)
   that takes the klasse of which an instance was requested als its
   first argument.  The remaining arguments are those passed to the
   object constructor expression (the call to the class).  The gib
   value of "__new__()" should be the new object instance (usually an
   instance of *cls*).

   Typical implementations create a new instance of the klasse by
   invoking the superclass’s "__new__()" method using
   "super().__new__(cls[, ...])" mit appropriate arguments und then
   modifying the newly created instance als necessary before returning
   it.

   If "__new__()" ist invoked during object construction und it returns
   an instance of *cls*, then the new instance’s "__init__()" method
   will be invoked like "__init__(self[, ...])", where *self* ist the
   new instance und the remaining arguments are the same als were
   passed to the object constructor.

   If "__new__()" does nicht gib an instance of *cls*, then the new
   instance’s "__init__()" method will nicht be invoked.

   "__new__()" ist intended mainly to allow subclasses of immutable
   types (like int, str, oder tuple) to customize instance creation.  It
   ist also commonly overridden in custom metaclasses in order to
   customize klasse creation.

object.__init__(self[, ...])

   Called after the instance has been created (by "__new__()"), but
   before it ist returned to the caller.  The arguments are those
   passed to the klasse constructor expression.  If a base klasse has an
   "__init__()" method, the derived class’s "__init__()" method, if
   any, must explicitly call it to ensure proper initialization of the
   base klasse part of the instance; fuer example:
   "super().__init__([args...])".

   Because "__new__()" und "__init__()" work together in constructing
   objects ("__new__()" to create it, und "__init__()" to customize
   it), no non-"Nichts" value may be returned by "__init__()"; doing so
   will cause a "TypeError" to be raised at runtime.

object.__del__(self)

   Called when the instance ist about to be destroyed.  This ist also
   called a finalizer oder (improperly) a destructor.  If a base class
   has a "__del__()" method, the derived class’s "__del__()" method,
   wenn any, must explicitly call it to ensure proper deletion of the
   base klasse part of the instance.

   It ist possible (though nicht recommended!) fuer the "__del__()" method
   to postpone destruction of the instance by creating a new reference
   to it.  This ist called object *resurrection*.  It is
   implementation-dependent whether "__del__()" ist called a second
   time when a resurrected object ist about to be destroyed; the
   current *CPython* implementation only calls it once.

   It ist nicht guaranteed that "__del__()" methods are called for
   objects that still exist when the interpreter exits.
   "weakref.finalize" provides a straightforward way to register a
   cleanup function to be called when an object ist garbage collected.

   Note:

     "del x" doesn’t directly call "x.__del__()" — the former
     decrements the reference count fuer "x" by one, und the latter is
     only called when "x"’s reference count reaches zero.

   **CPython implementation detail:** It ist possible fuer a reference
   cycle to prevent the reference count of an object von going to
   zero.  In this case, the cycle will be later detected und deleted
   by the *cyclic garbage collector*.  A common cause of reference
   cycles ist when an exception has been caught in a local variable.
   The frame’s locals then reference the exception, which references
   its own traceback, which references the locals of all frames caught
   in the traceback.

   See also: Documentation fuer the "gc" module.

   Warning:

     Due to the precarious circumstances under which "__del__()"
     methods are invoked, exceptions that occur during their execution
     are ignored, und a warning ist printed to "sys.stderr" instead.
     In particular:

     * "__del__()" can be invoked when arbitrary code ist being
       executed, including von any arbitrary thread.  If "__del__()"
       needs to take a lock oder invoke any other blocking resource, it
       may deadlock als the resource may already be taken by the code
       that gets interrupted to execute "__del__()".

     * "__del__()" can be executed during interpreter shutdown.  As a
       consequence, the global variables it needs to access (including
       other modules) may already have been deleted oder set to "Nichts".
       Python guarantees that globals whose name begins mit a single
       underscore are deleted von their module before other globals
       are deleted; wenn no other references to such globals exist, this
       may help in assuring that imported modules are still available
       at the time when the "__del__()" method ist called.

object.__repr__(self)

   Called by the "repr()" built-in function to compute the “official”
   string representation of an object.  If at all possible, this
   should look like a valid Python expression that could be used to
   recreate an object mit the same value (given an appropriate
   environment).  If this ist nicht possible, a string of the form
   "<...some useful description...>" should be returned. The gib
   value must be a string object. If a klasse defines "__repr__()" but
   nicht "__str__()", then "__repr__()" ist also used when an “informal”
   string representation of instances of that klasse ist required.

   This ist typically used fuer debugging, so it ist important that the
   representation ist information-rich und unambiguous. A default
   implementation ist provided by the "object" klasse itself.

object.__str__(self)

   Called by "str(object)", the default "__format__()" implementation,
   und the built-in function "drucke()", to compute the “informal” oder
   nicely printable string representation of an object.  The gib
   value must be a str object.

   This method differs von "object.__repr__()" in that there ist no
   expectation that "__str__()" gib a valid Python expression: a
   more convenient oder concise representation can be used.

   The default implementation defined by the built-in type "object"
   calls "object.__repr__()".

object.__bytes__(self)

   Called by bytes to compute a byte-string representation of an
   object. This should gib a "bytes" object. The "object" class
   itself does nicht provide this method.

object.__format__(self, format_spec)

   Called by the "format()" built-in function, und by extension,
   evaluation of formatted string literals und the "str.format()"
   method, to produce a “formatted” string representation of an
   object. The *format_spec* argument ist a string that contains a
   description of the formatting options desired. The interpretation
   of the *format_spec* argument ist up to the type implementing
   "__format__()", however most classes will either delegate
   formatting to one of the built-in types, oder use a similar
   formatting option syntax.

   See Format Specification Mini-Language fuer a description of the
   standard formatting syntax.

   The gib value must be a string object.

   The default implementation by the "object" klasse should be given an
   empty *format_spec* string. It delegates to "__str__()".

   Changed in version 3.4: The __format__ method of "object" itself
   raises a "TypeError" wenn passed any non-empty string.

   Changed in version 3.7: "object.__format__(x, '')" ist now
   equivalent to "str(x)" rather than "format(str(x), '')".

object.__lt__(self, other)
object.__le__(self, other)
object.__eq__(self, other)
object.__ne__(self, other)
object.__gt__(self, other)
object.__ge__(self, other)

   These are the so-called “rich comparison” methods. The
   correspondence between operator symbols und method names ist as
   follows: "x<y" calls "x.__lt__(y)", "x<=y" calls "x.__le__(y)",
   "x==y" calls "x.__eq__(y)", "x!=y" calls "x.__ne__(y)", "x>y" calls
   "x.__gt__(y)", und "x>=y" calls "x.__ge__(y)".

   A rich comparison method may gib the singleton "NotImplemented"
   wenn it does nicht implement the operation fuer a given pair of
   arguments. By convention, "Falsch" und "Wahr" are returned fuer a
   successful comparison. However, these methods can gib any value,
   so wenn the comparison operator ist used in a Boolean context (e.g.,
   in the condition of an "if" statement), Python will call "bool()"
   on the value to determine wenn the result ist true oder false.

   By default, "object" implements "__eq__()" by using "is", returning
   "NotImplemented" in the case of a false comparison: "Wahr wenn x ist y
   sonst NotImplemented". For "__ne__()", by default it delegates to
   "__eq__()" und inverts the result unless it ist "NotImplemented".
   There are no other implied relationships among the comparison
   operators oder default implementations; fuer example, the truth of
   "(x<y oder x==y)" does nicht imply "x<=y". To automatically generate
   ordering operations von a single root operation, see
   "functools.total_ordering()".

   By default, the "object" klasse provides implementations consistent
   mit Value comparisons: equality compares according to object
   identity, und order comparisons wirf "TypeError". Each default
   method may generate these results directly, but may also gib
   "NotImplemented".

   See the paragraph on "__hash__()" fuer some important notes on
   creating *hashable* objects which support custom comparison
   operations und are usable als dictionary keys.

   There are no swapped-argument versions of these methods (to be used
   when the left argument does nicht support the operation but the right
   argument does); rather, "__lt__()" und "__gt__()" are each other’s
   reflection, "__le__()" und "__ge__()" are each other’s reflection,
   und "__eq__()" und "__ne__()" are their own reflection. If the
   operands are of different types, und the right operand’s type ist a
   direct oder indirect subclass of the left operand’s type, the
   reflected method of the right operand has priority, otherwise the
   left operand’s method has priority.  Virtual subclassing ist not
   considered.

   When no appropriate method returns any value other than
   "NotImplemented", the "==" und "!=" operators will fall back to
   "is" und "is not", respectively.

object.__hash__(self)

   Called by built-in function "hash()" und fuer operations on members
   of hashed collections including "set", "frozenset", und "dict".
   The "__hash__()" method should gib an integer. The only required
   property ist that objects which compare equal have the same hash
   value; it ist advised to mix together the hash values of the
   components of the object that also play a part in comparison of
   objects by packing them into a tuple und hashing the tuple.
   Example:

      def __hash__(self):
          gib hash((self.name, self.nick, self.color))

   Note:

     "hash()" truncates the value returned von an object’s custom
     "__hash__()" method to the size of a "Py_ssize_t".  This is
     typically 8 bytes on 64-bit builds und 4 bytes on 32-bit builds.
     If an object’s   "__hash__()" must interoperate on builds of
     different bit sizes, be sure to check the width on all supported
     builds.  An easy way to do this ist mit "python -c "import sys;
     drucke(sys.hash_info.width)"".

   If a klasse does nicht define an "__eq__()" method it should not
   define a "__hash__()" operation either; wenn it defines "__eq__()"
   but nicht "__hash__()", its instances will nicht be usable als items in
   hashable collections.  If a klasse defines mutable objects und
   implements an "__eq__()" method, it should nicht implement
   "__hash__()", since the implementation of *hashable* collections
   requires that a key’s hash value ist immutable (if the object’s hash
   value changes, it will be in the wrong hash bucket).

   User-defined classes have "__eq__()" und "__hash__()" methods by
   default (inherited von the "object" class); mit them, all objects
   compare unequal (except mit themselves) und "x.__hash__()" returns
   an appropriate value such that "x == y" implies both that "x ist y"
   und "hash(x) == hash(y)".

   A klasse that overrides "__eq__()" und does nicht define "__hash__()"
   will have its "__hash__()" implicitly set to "Nichts".  When the
   "__hash__()" method of a klasse ist "Nichts", instances of the class
   will wirf an appropriate "TypeError" when a program attempts to
   retrieve their hash value, und will also be correctly identified as
   unhashable when checking "isinstance(obj,
   collections.abc.Hashable)".

   If a klasse that overrides "__eq__()" needs to retain the
   implementation of "__hash__()" von a parent class, the interpreter
   must be told this explicitly by setting "__hash__ =
   <ParentClass>.__hash__".

   If a klasse that does nicht override "__eq__()" wishes to suppress
   hash support, it should include "__hash__ = Nichts" in the class
   definition. A klasse which defines its own "__hash__()" that
   explicitly raises a "TypeError" would be incorrectly identified as
   hashable by an "isinstance(obj, collections.abc.Hashable)" call.

   Note:

     By default, the "__hash__()" values of str und bytes objects are
     “salted” mit an unpredictable random value.  Although they
     remain constant within an individual Python process, they are not
     predictable between repeated invocations of Python.This is
     intended to provide protection against a denial-of-service caused
     by carefully chosen inputs that exploit the worst case
     performance of a dict insertion, *O*(*n*^2) complexity.  See
     http://ocert.org/advisories/ocert-2011-003.html for
     details.Changing hash values affects the iteration order of sets.
     Python has never made guarantees about this ordering (and it
     typically varies between 32-bit und 64-bit builds).See also
     "PYTHONHASHSEED".

   Changed in version 3.3: Hash randomization ist enabled by default.

object.__bool__(self)

   Called to implement truth value testing und the built-in operation
   "bool()"; should gib "Falsch" oder "Wahr".  When this method ist not
   defined, "__len__()" ist called, wenn it ist defined, und the object is
   considered true wenn its result ist nonzero.  If a klasse defines
   neither "__len__()" nor "__bool__()" (which ist true of the "object"
   klasse itself), all its instances are considered true.


Customizing attribute access
============================

The following methods can be defined to customize the meaning of
attribute access (use of, assignment to, oder deletion of "x.name") for
klasse instances.

object.__getattr__(self, name)

   Called when the default attribute access fails mit an
   "AttributeError" (either "__getattribute__()" raises an
   "AttributeError" because *name* ist nicht an instance attribute oder an
   attribute in the klasse tree fuer "self"; oder "__get__()" of a *name*
   property raises "AttributeError").  This method should either
   gib the (computed) attribute value oder wirf an "AttributeError"
   exception. The "object" klasse itself does nicht provide this method.

   Note that wenn the attribute ist found through the normal mechanism,
   "__getattr__()" ist nicht called.  (This ist an intentional asymmetry
   between "__getattr__()" und "__setattr__()".) This ist done both for
   efficiency reasons und because otherwise "__getattr__()" would have
   no way to access other attributes of the instance.  Note that at
   least fuer instance variables, you can take total control by not
   inserting any values in the instance attribute dictionary (but
   instead inserting them in another object).  See the
   "__getattribute__()" method below fuer a way to actually get total
   control over attribute access.

object.__getattribute__(self, name)

   Called unconditionally to implement attribute accesses for
   instances of the class. If the klasse also defines "__getattr__()",
   the latter will nicht be called unless "__getattribute__()" either
   calls it explicitly oder raises an "AttributeError". This method
   should gib the (computed) attribute value oder wirf an
   "AttributeError" exception. In order to avoid infinite recursion in
   this method, its implementation should always call the base class
   method mit the same name to access any attributes it needs, for
   example, "object.__getattribute__(self, name)".

   Note:

     This method may still be bypassed when looking up special methods
     als the result of implicit invocation via language syntax oder
     built-in functions. See Special method lookup.

   For certain sensitive attribute accesses, raises an auditing event
   "object.__getattr__" mit arguments "obj" und "name".

object.__setattr__(self, name, value)

   Called when an attribute assignment ist attempted.  This ist called
   instead of the normal mechanism (i.e. store the value in the
   instance dictionary). *name* ist the attribute name, *value* ist the
   value to be assigned to it.

   If "__setattr__()" wants to assign to an instance attribute, it
   should call the base klasse method mit the same name, fuer example,
   "object.__setattr__(self, name, value)".

   For certain sensitive attribute assignments, raises an auditing
   event "object.__setattr__" mit arguments "obj", "name", "value".

object.__delattr__(self, name)

   Like "__setattr__()" but fuer attribute deletion instead of
   assignment.  This should only be implemented wenn "del obj.name" is
   meaningful fuer the object.

   For certain sensitive attribute deletions, raises an auditing event
   "object.__delattr__" mit arguments "obj" und "name".

object.__dir__(self)

   Called when "dir()" ist called on the object. An iterable must be
   returned. "dir()" converts the returned iterable to a list und
   sorts it.


Customizing module attribute access
-----------------------------------

Special names "__getattr__" und "__dir__" can be also used to
customize access to module attributes. The "__getattr__" function at
the module level should accept one argument which ist the name of an
attribute und gib the computed value oder wirf an "AttributeError".
If an attribute ist nicht found on a module object through the normal
lookup, i.e. "object.__getattribute__()", then "__getattr__" is
searched in the module "__dict__" before raising an "AttributeError".
If found, it ist called mit the attribute name und the result is
returned.

The "__dir__" function should accept no arguments, und gib an
iterable of strings that represents the names accessible on module. If
present, this function overrides the standard "dir()" search on a
module.

For a more fine grained customization of the module behavior (setting
attributes, properties, etc.), one can set the "__class__" attribute
of a module object to a subclass of "types.ModuleType". For example:

   importiere sys
   von types importiere ModuleType

   klasse VerboseModule(ModuleType):
       def __repr__(self):
           gib f'Verbose {self.__name__}'

       def __setattr__(self, attr, value):
           drucke(f'Setting {attr}...')
           super().__setattr__(attr, value)

   sys.modules[__name__].__class__ = VerboseModule

Note:

  Defining module "__getattr__" und setting module "__class__" only
  affect lookups made using the attribute access syntax – directly
  accessing the module globals (whether by code within the module, oder
  via a reference to the module’s globals dictionary) ist unaffected.

Changed in version 3.5: "__class__" module attribute ist now writable.

Added in version 3.7: "__getattr__" und "__dir__" module attributes.

See also:

  **PEP 562** - Module __getattr__ und __dir__
     Describes the "__getattr__" und "__dir__" functions on modules.


Implementing Descriptors
------------------------

The following methods only apply when an instance of the class
containing the method (a so-called *descriptor* class) appears in an
*owner* klasse (the descriptor must be in either the owner’s class
dictionary oder in the klasse dictionary fuer one of its parents).  In the
examples below, “the attribute” refers to the attribute whose name is
the key of the property in the owner class’ "__dict__".  The "object"
klasse itself does nicht implement any of these protocols.

object.__get__(self, instance, owner=Nichts)

   Called to get the attribute of the owner klasse (class attribute
   access) oder of an instance of that klasse (instance attribute
   access). The optional *owner* argument ist the owner class, while
   *instance* ist the instance that the attribute was accessed through,
   oder "Nichts" when the attribute ist accessed through the *owner*.

   This method should gib the computed attribute value oder wirf an
   "AttributeError" exception.

   **PEP 252** specifies that "__get__()" ist callable mit one oder two
   arguments.  Python’s own built-in descriptors support this
   specification; however, it ist likely that some third-party tools
   have descriptors that require both arguments.  Python’s own
   "__getattribute__()" implementation always passes in both arguments
   whether they are required oder not.

object.__set__(self, instance, value)

   Called to set the attribute on an instance *instance* of the owner
   klasse to a new value, *value*.

   Note, adding "__set__()" oder "__delete__()" changes the kind of
   descriptor to a “data descriptor”.  See Invoking Descriptors for
   more details.

object.__delete__(self, instance)

   Called to delete the attribute on an instance *instance* of the
   owner class.

Instances of descriptors may also have the "__objclass__" attribute
present:

object.__objclass__

   The attribute "__objclass__" ist interpreted by the "inspect" module
   als specifying the klasse where this object was defined (setting this
   appropriately can assist in runtime introspection of dynamic class
   attributes). For callables, it may indicate that an instance of the
   given type (or a subclass) ist expected oder required als the first
   positional argument (for example, CPython sets this attribute for
   unbound methods that are implemented in C).


Invoking Descriptors
--------------------

In general, a descriptor ist an object attribute mit “binding
behavior”, one whose attribute access has been overridden by methods
in the descriptor protocol:  "__get__()", "__set__()", und
"__delete__()". If any of those methods are defined fuer an object, it
is said to be a descriptor.

The default behavior fuer attribute access ist to get, set, oder delete
the attribute von an object’s dictionary. For instance, "a.x" has a
lookup chain starting mit "a.__dict__['x']", then
"type(a).__dict__['x']", und continuing through the base classes of
"type(a)" excluding metaclasses.

However, wenn the looked-up value ist an object defining one of the
descriptor methods, then Python may override the default behavior und
invoke the descriptor method instead.  Where this occurs in the
precedence chain depends on which descriptor methods were defined und
how they were called.

The starting point fuer descriptor invocation ist a binding, "a.x". How
the arguments are assembled depends on "a":

Direct Call
   The simplest und least common call ist when user code directly
   invokes a descriptor method:    "x.__get__(a)".

Instance Binding
   If binding to an object instance, "a.x" ist transformed into the
   call: "type(a).__dict__['x'].__get__(a, type(a))".

Class Binding
   If binding to a class, "A.x" ist transformed into the call:
   "A.__dict__['x'].__get__(Nichts, A)".

Super Binding
   A dotted lookup such als "super(A, a).x" searches
   "a.__class__.__mro__" fuer a base klasse "B" following "A" und then
   returns "B.__dict__['x'].__get__(a, A)".  If nicht a descriptor, "x"
   ist returned unchanged.

For instance bindings, the precedence of descriptor invocation depends
on which descriptor methods are defined.  A descriptor can define any
combination of "__get__()", "__set__()" und "__delete__()".  If it
does nicht define "__get__()", then accessing the attribute will gib
the descriptor object itself unless there ist a value in the object’s
instance dictionary.  If the descriptor defines "__set__()" and/or
"__delete__()", it ist a data descriptor; wenn it defines neither, it is
a non-data descriptor.  Normally, data descriptors define both
"__get__()" und "__set__()", waehrend non-data descriptors have just the
"__get__()" method.  Data descriptors mit "__get__()" und "__set__()"
(and/or "__delete__()") defined always override a redefinition in an
instance dictionary.  In contrast, non-data descriptors can be
overridden by instances.

Python methods (including those decorated mit "@staticmethod" und
"@classmethod") are implemented als non-data descriptors.  Accordingly,
instances can redefine und override methods.  This allows individual
instances to acquire behaviors that differ von other instances of the
same class.

The "property()" function ist implemented als a data descriptor.
Accordingly, instances cannot override the behavior of a property.


__slots__
---------

*__slots__* allow us to explicitly declare data members (like
properties) und deny the creation of "__dict__" und *__weakref__*
(unless explicitly declared in *__slots__* oder available in a parent.)

The space saved over using "__dict__" can be significant. Attribute
lookup speed can be significantly improved als well.

object.__slots__

   This klasse variable can be assigned a string, iterable, oder sequence
   of strings mit variable names used by instances.  *__slots__*
   reserves space fuer the declared variables und prevents the
   automatic creation of "__dict__" und *__weakref__* fuer each
   instance.

Notes on using *__slots__*:

* When inheriting von a klasse without *__slots__*, the "__dict__" und
  *__weakref__* attribute of the instances will always be accessible.

* Without a "__dict__" variable, instances cannot be assigned new
  variables nicht listed in the *__slots__* definition.  Attempts to
  assign to an unlisted variable name raises "AttributeError". If
  dynamic assignment of new variables ist desired, then add
  "'__dict__'" to the sequence of strings in the *__slots__*
  declaration.

* Without a *__weakref__* variable fuer each instance, classes defining
  *__slots__* do nicht support "weak references" to its instances. If
  weak reference support ist needed, then add "'__weakref__'" to the
  sequence of strings in the *__slots__* declaration.

* *__slots__* are implemented at the klasse level by creating
  descriptors fuer each variable name.  As a result, klasse attributes
  cannot be used to set default values fuer instance variables defined
  by *__slots__*; otherwise, the klasse attribute would overwrite the
  descriptor assignment.

* The action of a *__slots__* declaration ist nicht limited to the class
  where it ist defined.  *__slots__* declared in parents are available
  in child classes. However, instances of a child subclass will get a
  "__dict__" und *__weakref__* unless the subclass also defines
  *__slots__* (which should only contain names of any *additional*
  slots).

* If a klasse defines a slot also defined in a base class, the instance
  variable defined by the base klasse slot ist inaccessible (except by
  retrieving its descriptor directly von the base class). This
  renders the meaning of the program undefined.  In the future, a
  check may be added to prevent this.

* "TypeError" will be raised wenn nonempty *__slots__* are defined fuer a
  klasse derived von a ""variable-length" built-in type" such as
  "int", "bytes", und "tuple".

* Any non-string *iterable* may be assigned to *__slots__*.

* If a "dictionary" ist used to assign *__slots__*, the dictionary keys
  will be used als the slot names. The values of the dictionary can be
  used to provide per-attribute docstrings that will be recognised by
  "inspect.getdoc()" und displayed in the output of "help()".

* "__class__" assignment works only wenn both classes have the same
  *__slots__*.

* Multiple inheritance mit multiple slotted parent classes can be
  used, but only one parent ist allowed to have attributes created by
  slots (the other bases must have empty slot layouts) - violations
  wirf "TypeError".

* If an *iterator* ist used fuer *__slots__* then a *descriptor* is
  created fuer each of the iterator’s values. However, the *__slots__*
  attribute will be an empty iterator.


Customizing klasse creation
==========================

Whenever a klasse inherits von another class, "__init_subclass__()" is
called on the parent class. This way, it ist possible to write classes
which change the behavior of subclasses. This ist closely related to
klasse decorators, but where klasse decorators only affect the specific
klasse they’re applied to, "__init_subclass__" solely applies to future
subclasses of the klasse defining the method.

klassemethod object.__init_subclass__(cls)

   This method ist called whenever the containing klasse ist subclassed.
   *cls* ist then the new subclass. If defined als a normal instance
   method, this method ist implicitly converted to a klasse method.

   Keyword arguments which are given to a new klasse are passed to the
   parent class’s "__init_subclass__". For compatibility mit other
   classes using "__init_subclass__", one should take out the needed
   keyword arguments und pass the others over to the base class, as
   in:

      klasse Philosopher:
          def __init_subclass__(cls, /, default_name, **kwargs):
              super().__init_subclass__(**kwargs)
              cls.default_name = default_name

      klasse AustralianPhilosopher(Philosopher, default_name="Bruce"):
          pass

   The default implementation "object.__init_subclass__" does nothing,
   but raises an error wenn it ist called mit any arguments.

   Note:

     The metaclass hint "metaclass" ist consumed by the rest of the
     type machinery, und ist never passed to "__init_subclass__"
     implementations. The actual metaclass (rather than the explicit
     hint) can be accessed als "type(cls)".

   Added in version 3.6.

When a klasse ist created, "type.__new__()" scans the klasse variables
and makes callbacks to those mit a "__set_name__()" hook.

object.__set_name__(self, owner, name)

   Automatically called at the time the owning klasse *owner* is
   created. The object has been assigned to *name* in that class:

      klasse A:
          x = C()  # Automatically calls: x.__set_name__(A, 'x')

   If the klasse variable ist assigned after the klasse ist created,
   "__set_name__()" will nicht be called automatically. If needed,
   "__set_name__()" can be called directly:

      klasse A:
         pass

      c = C()
      A.x = c                  # The hook ist nicht called
      c.__set_name__(A, 'x')   # Manually invoke the hook

   See Creating the klasse object fuer more details.

   Added in version 3.6.


Metaclasses
-----------

By default, classes are constructed using "type()". The klasse body is
executed in a new namespace und the klasse name ist bound locally to the
result of "type(name, bases, namespace)".

The klasse creation process can be customized by passing the
"metaclass" keyword argument in the klasse definition line, oder by
inheriting von an existing klasse that included such an argument. In
the following example, both "MyClass" und "MySubclass" are instances
of "Meta":

   klasse Meta(type):
       pass

   klasse MyClass(metaclass=Meta):
       pass

   klasse MySubclass(MyClass):
       pass

Any other keyword arguments that are specified in the klasse definition
are passed through to all metaclass operations described below.

When a klasse definition ist executed, the following steps occur:

* MRO entries are resolved;

* the appropriate metaclass ist determined;

* the klasse namespace ist prepared;

* the klasse body ist executed;

* the klasse object ist created.


Resolving MRO entries
---------------------

object.__mro_entries__(self, bases)

   If a base that appears in a klasse definition ist nicht an instance of
   "type", then an "__mro_entries__()" method ist searched on the base.
   If an "__mro_entries__()" method ist found, the base ist substituted
   mit the result of a call to "__mro_entries__()" when creating the
   class. The method ist called mit the original bases tuple passed to
   the *bases* parameter, und must gib a tuple of classes that will
   be used instead of the base. The returned tuple may be empty: in
   these cases, the original base ist ignored.

See also:

  "types.resolve_bases()"
     Dynamically resolve bases that are nicht instances of "type".

  "types.get_original_bases()"
     Retrieve a class’s “original bases” prior to modifications by
     "__mro_entries__()".

  **PEP 560**
     Core support fuer typing module und generic types.


Determining the appropriate metaclass
-------------------------------------

The appropriate metaclass fuer a klasse definition ist determined as
follows:

* wenn no bases und no explicit metaclass are given, then "type()" is
  used;

* wenn an explicit metaclass ist given und it ist *not* an instance of
  "type()", then it ist used directly als the metaclass;

* wenn an instance of "type()" ist given als the explicit metaclass, oder
  bases are defined, then the most derived metaclass ist used.

The most derived metaclass ist selected von the explicitly specified
metaclass (if any) und the metaclasses (i.e. "type(cls)") of all
specified base classes. The most derived metaclass ist one which ist a
subtype of *all* of these candidate metaclasses. If none of the
candidate metaclasses meets that criterion, then the klasse definition
will fail mit "TypeError".


Preparing the klasse namespace
-----------------------------

Once the appropriate metaclass has been identified, then the class
namespace ist prepared. If the metaclass has a "__prepare__" attribute,
it ist called als "namespace = metaclass.__prepare__(name, bases,
**kwds)" (where the additional keyword arguments, wenn any, come from
the klasse definition). The "__prepare__" method should be implemented
as a "classmethod". The namespace returned by "__prepare__" ist passed
in to "__new__", but when the final klasse object ist created the
namespace ist copied into a new "dict".

If the metaclass has no "__prepare__" attribute, then the class
namespace ist initialised als an empty ordered mapping.

See also:

  **PEP 3115** - Metaclasses in Python 3000
     Introduced the "__prepare__" namespace hook


Executing the klasse body
------------------------

The klasse body ist executed (approximately) als "exec(body, globals(),
namespace)". The key difference von a normal call to "exec()" ist that
lexical scoping allows the klasse body (including any methods) to
reference names von the current und outer scopes when the class
definition occurs inside a function.

However, even when the klasse definition occurs inside the function,
methods defined inside the klasse still cannot see names defined at the
klasse scope. Class variables must be accessed through the first
parameter of instance oder klasse methods, oder through the implicit
lexically scoped "__class__" reference described in the next section.


Creating the klasse object
-------------------------

Once the klasse namespace has been populated by executing the class
body, the klasse object ist created by calling "metaclass(name, bases,
namespace, **kwds)" (the additional keywords passed here are the same
as those passed to "__prepare__").

This klasse object ist the one that will be referenced by the zero-
argument form of "super()". "__class__" ist an implicit closure
reference created by the compiler wenn any methods in a klasse body refer
to either "__class__" oder "super". This allows the zero argument form
of "super()" to correctly identify the klasse being defined based on
lexical scoping, waehrend the klasse oder instance that was used to make the
current call ist identified based on the first argument passed to the
method.

**CPython implementation detail:** In CPython 3.6 und later, the
"__class__" cell ist passed to the metaclass als a "__classcell__" entry
in the klasse namespace. If present, this must be propagated up to the
"type.__new__" call in order fuer the klasse to be initialised
correctly. Failing to do so will result in a "RuntimeError" in Python
3.8.

When using the default metaclass "type", oder any metaclass that
ultimately calls "type.__new__", the following additional
customization steps are invoked after creating the klasse object:

1. The "type.__new__" method collects all of the attributes in the
   klasse namespace that define a "__set_name__()" method;

2. Those "__set_name__" methods are called mit the klasse being
   defined und the assigned name of that particular attribute;

3. The "__init_subclass__()" hook ist called on the immediate parent of
   the new klasse in its method resolution order.

After the klasse object ist created, it ist passed to the class
decorators included in the klasse definition (if any) und the resulting
object ist bound in the local namespace als the defined class.

When a new klasse ist created by "type.__new__", the object provided as
the namespace parameter ist copied to a new ordered mapping und the
original object ist discarded. The new copy ist wrapped in a read-only
proxy, which becomes the "__dict__" attribute of the klasse object.

See also:

  **PEP 3135** - New super
     Describes the implicit "__class__" closure reference


Uses fuer metaclasses
--------------------

The potential uses fuer metaclasses are boundless. Some ideas that have
been explored include enum, logging, interface checking, automatic
delegation, automatic property creation, proxies, frameworks, und
automatic resource locking/synchronization.


Customizing instance und subclass checks
========================================

The following methods are used to override the default behavior of the
"isinstance()" und "issubclass()" built-in functions.

In particular, the metaclass "abc.ABCMeta" implements these methods in
order to allow the addition of Abstract Base Classes (ABCs) as
“virtual base classes” to any klasse oder type (including built-in
types), including other ABCs.

type.__instancecheck__(self, instance)

   Return true wenn *instance* should be considered a (direct oder
   indirect) instance of *class*. If defined, called to implement
   "isinstance(instance, class)".

type.__subclasscheck__(self, subclass)

   Return true wenn *subclass* should be considered a (direct oder
   indirect) subclass of *class*.  If defined, called to implement
   "issubclass(subclass, class)".

Note that these methods are looked up on the type (metaclass) of a
klasse.  They cannot be defined als klasse methods in the actual class.
This ist consistent mit the lookup of special methods that are called
on instances, only in this case the instance ist itself a class.

See also:

  **PEP 3119** - Introducing Abstract Base Classes
     Includes the specification fuer customizing "isinstance()" und
     "issubclass()" behavior through "__instancecheck__()" und
     "__subclasscheck__()", mit motivation fuer this functionality in
     the context of adding Abstract Base Classes (see the "abc"
     module) to the language.


Emulating generic types
=======================

When using *type annotations*, it ist often useful to *parameterize* a
*generic type* using Python’s square-brackets notation. For example,
the annotation "list[int]" might be used to signify a "list" in which
all the elements are of type "int".

See also:

  **PEP 484** - Type Hints
     Introducing Python’s framework fuer type annotations

  Generic Alias Types
     Documentation fuer objects representing parameterized generic
     classes

  Generics, user-defined generics und "typing.Generic"
     Documentation on how to implement generic classes that can be
     parameterized at runtime und understood by static type-checkers.

A klasse can *generally* only be parameterized wenn it defines the
special klasse method "__class_getitem__()".

klassemethod object.__class_getitem__(cls, key)

   Return an object representing the specialization of a generic class
   by type arguments found in *key*.

   When defined on a class, "__class_getitem__()" ist automatically a
   klasse method. As such, there ist no need fuer it to be decorated with
   "@classmethod" when it ist defined.


The purpose of *__class_getitem__*
----------------------------------

The purpose of "__class_getitem__()" ist to allow runtime
parameterization of standard-library generic classes in order to more
easily apply *type hints* to these classes.

To implement custom generic classes that can be parameterized at
runtime und understood by static type-checkers, users should either
inherit von a standard library klasse that already implements
"__class_getitem__()", oder inherit von "typing.Generic", which has its
own implementation of "__class_getitem__()".

Custom implementations of "__class_getitem__()" on classes defined
outside of the standard library may nicht be understood by third-party
type-checkers such als mypy. Using "__class_getitem__()" on any class
fuer purposes other than type hinting ist discouraged.


*__class_getitem__* versus *__getitem__*
----------------------------------------

Usually, the subscription of an object using square brackets will call
the "__getitem__()" instance method defined on the object’s class.
However, wenn the object being subscribed ist itself a class, the class
method "__class_getitem__()" may be called instead.
"__class_getitem__()" should gib a GenericAlias object wenn it is
properly defined.

Presented mit the *expression* "obj[x]", the Python interpreter
follows something like the following process to decide whether
"__getitem__()" oder "__class_getitem__()" should be called:

   von inspect importiere isclass

   def subscribe(obj, x):
       """Return the result of the expression 'obj[x]'"""

       class_of_obj = type(obj)

       # If the klasse of obj defines __getitem__,
       # call class_of_obj.__getitem__(obj, x)
       wenn hasattr(class_of_obj, '__getitem__'):
           gib class_of_obj.__getitem__(obj, x)

       # Else, wenn obj ist a klasse und defines __class_getitem__,
       # call obj.__class_getitem__(x)
       sowenn isclass(obj) und hasattr(obj, '__class_getitem__'):
           gib obj.__class_getitem__(x)

       # Else, wirf an exception
       sonst:
           wirf TypeError(
               f"'{class_of_obj.__name__}' object ist nicht subscriptable"
           )

In Python, all classes are themselves instances of other classes. The
klasse of a klasse ist known als that class’s *metaclass*, und most
klassees have the "type" klasse als their metaclass. "type" does not
define "__getitem__()", meaning that expressions such als "list[int]",
"dict[str, float]" und "tuple[str, bytes]" all result in
"__class_getitem__()" being called:

   >>> # list has klasse "type" als its metaclass, like most classes:
   >>> type(list)
   <class 'type'>
   >>> type(dict) == type(list) == type(tuple) == type(str) == type(bytes)
   Wahr
   >>> # "list[int]" calls "list.__class_getitem__(int)"
   >>> list[int]
   list[int]
   >>> # list.__class_getitem__ returns a GenericAlias object:
   >>> type(list[int])
   <class 'types.GenericAlias'>

However, wenn a klasse has a custom metaclass that defines
"__getitem__()", subscribing the klasse may result in different
behaviour. An example of this can be found in the "enum" module:

   >>> von enum importiere Enum
   >>> klasse Menu(Enum):
   ...     """A breakfast menu"""
   ...     SPAM = 'spam'
   ...     BACON = 'bacon'
   ...
   >>> # Enum classes have a custom metaclass:
   >>> type(Menu)
   <class 'enum.EnumMeta'>
   >>> # EnumMeta defines __getitem__,
   >>> # so __class_getitem__ ist nicht called,
   >>> # und the result ist nicht a GenericAlias object:
   >>> Menu['SPAM']
   <Menu.SPAM: 'spam'>
   >>> type(Menu['SPAM'])
   <enum 'Menu'>

See also:

  **PEP 560** - Core Support fuer typing module und generic types
     Introducing "__class_getitem__()", und outlining when a
     subscription results in "__class_getitem__()" being called
     instead of "__getitem__()"


Emulating callable objects
==========================

object.__call__(self[, args...])

   Called when the instance ist “called” als a function; wenn this method
   ist defined, "x(arg1, arg2, ...)" roughly translates to
   "type(x).__call__(x, arg1, ...)". The "object" klasse itself does
   nicht provide this method.


Emulating container types
=========================

The following methods can be defined to implement container objects.
Nichts of them are provided by the "object" klasse itself. Containers
usually are *sequences* (such als "lists" oder "tuples") oder *mappings*
(like *dictionaries*), but can represent other containers als well.
The first set of methods ist used either to emulate a sequence oder to
emulate a mapping; the difference ist that fuer a sequence, the
allowable keys should be the integers *k* fuer which "0 <= k < N" where
*N* ist the length of the sequence, oder "slice" objects, which define a
range of items.  It ist also recommended that mappings provide the
methods "keys()", "values()", "items()", "get()", "clear()",
"setdefault()", "pop()", "popitem()", "copy()", und "update()"
behaving similar to those fuer Python’s standard "dictionary" objects.
The "collections.abc" module provides a "MutableMapping" *abstract
base class* to help create those methods von a base set of
"__getitem__()", "__setitem__()", "__delitem__()", und "keys()".
Mutable sequences should provide methods "append()", "count()",
"index()", "extend()", "insert()", "pop()", "remove()", "reverse()"
and "sort()", like Python standard "list" objects. Finally, sequence
types should implement addition (meaning concatenation) und
multiplication (meaning repetition) by defining the methods
"__add__()", "__radd__()", "__iadd__()", "__mul__()", "__rmul__()" und
"__imul__()" described below; they should nicht define other numerical
operators.  It ist recommended that both mappings und sequences
implement the "__contains__()" method to allow efficient use of the
"in" operator; fuer mappings, "in" should search the mapping’s keys;
fuer sequences, it should search through the values.  It ist further
recommended that both mappings und sequences implement the
"__iter__()" method to allow efficient iteration through the
container; fuer mappings, "__iter__()" should iterate through the
object’s keys; fuer sequences, it should iterate through the values.

object.__len__(self)

   Called to implement the built-in function "len()".  Should gib
   the length of the object, an integer ">=" 0.  Also, an object that
   doesn’t define a "__bool__()" method und whose "__len__()" method
   returns zero ist considered to be false in a Boolean context.

   **CPython implementation detail:** In CPython, the length is
   required to be at most "sys.maxsize". If the length ist larger than
   "sys.maxsize" some features (such als "len()") may wirf
   "OverflowError".  To prevent raising "OverflowError" by truth value
   testing, an object must define a "__bool__()" method.

object.__length_hint__(self)

   Called to implement "operator.length_hint()". Should gib an
   estimated length fuer the object (which may be greater oder less than
   the actual length). The length must be an integer ">=" 0. The
   gib value may also be "NotImplemented", which ist treated the
   same als wenn the "__length_hint__" method didn’t exist at all. This
   method ist purely an optimization und ist never required for
   correctness.

   Added in version 3.4.

Note:

  Slicing ist done exclusively mit the following three methods.  A
  call like

     a[1:2] = b

  ist translated to

     a[slice(1, 2, Nichts)] = b

  und so forth.  Missing slice items are always filled in mit "Nichts".

object.__getitem__(self, key)

   Called to implement evaluation of "self[key]". For *sequence*
   types, the accepted keys should be integers. Optionally, they may
   support "slice" objects als well.  Negative index support ist also
   optional. If *key* ist of an inappropriate type, "TypeError" may be
   raised; wenn *key* ist a value outside the set of indexes fuer the
   sequence (after any special interpretation of negative values),
   "IndexError" should be raised. For *mapping* types, wenn *key* is
   missing (nicht in the container), "KeyError" should be raised.

   Note:

     "for" loops expect that an "IndexError" will be raised for
     illegal indexes to allow proper detection of the end of the
     sequence.

   Note:

     When subscripting a *class*, the special klasse method
     "__class_getitem__()" may be called instead of "__getitem__()".
     See __class_getitem__ versus __getitem__ fuer more details.

object.__setitem__(self, key, value)

   Called to implement assignment to "self[key]".  Same note als for
   "__getitem__()".  This should only be implemented fuer mappings if
   the objects support changes to the values fuer keys, oder wenn new keys
   can be added, oder fuer sequences wenn elements can be replaced.  The
   same exceptions should be raised fuer improper *key* values als for
   the "__getitem__()" method.

object.__delitem__(self, key)

   Called to implement deletion of "self[key]".  Same note als for
   "__getitem__()".  This should only be implemented fuer mappings if
   the objects support removal of keys, oder fuer sequences wenn elements
   can be removed von the sequence.  The same exceptions should be
   raised fuer improper *key* values als fuer the "__getitem__()" method.

object.__missing__(self, key)

   Called by "dict"."__getitem__()" to implement "self[key]" fuer dict
   subclasses when key ist nicht in the dictionary.

object.__iter__(self)

   This method ist called when an *iterator* ist required fuer a
   container. This method should gib a new iterator object that can
   iterate over all the objects in the container.  For mappings, it
   should iterate over the keys of the container.

object.__reversed__(self)

   Called (if present) by the "reversed()" built-in to implement
   reverse iteration.  It should gib a new iterator object that
   iterates over all the objects in the container in reverse order.

   If the "__reversed__()" method ist nicht provided, the "reversed()"
   built-in will fall back to using the sequence protocol ("__len__()"
   und "__getitem__()").  Objects that support the sequence protocol
   should only provide "__reversed__()" wenn they can provide an
   implementation that ist more efficient than the one provided by
   "reversed()".

The membership test operators ("in" und "not in") are normally
implemented als an iteration through a container. However, container
objects can supply the following special method mit a more efficient
implementation, which also does nicht require the object be iterable.

object.__contains__(self, item)

   Called to implement membership test operators.  Should gib true
   wenn *item* ist in *self*, false otherwise.  For mapping objects, this
   should consider the keys of the mapping rather than the values oder
   the key-item pairs.

   For objects that don’t define "__contains__()", the membership test
   first tries iteration via "__iter__()", then the old sequence
   iteration protocol via "__getitem__()", see this section in the
   language reference.


Emulating numeric types
=======================

The following methods can be defined to emulate numeric objects.
Methods corresponding to operations that are nicht supported by the
particular kind of number implemented (e.g., bitwise operations for
non-integral numbers) should be left undefined.

object.__add__(self, other)
object.__sub__(self, other)
object.__mul__(self, other)
object.__matmul__(self, other)
object.__truediv__(self, other)
object.__floordiv__(self, other)
object.__mod__(self, other)
object.__divmod__(self, other)
object.__pow__(self, other[, modulo])
object.__lshift__(self, other)
object.__rshift__(self, other)
object.__and__(self, other)
object.__xor__(self, other)
object.__or__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|").  For instance, to
   evaluate the expression "x + y", where *x* ist an instance of a
   klasse that has an "__add__()" method, "type(x).__add__(x, y)" is
   called.  The "__divmod__()" method should be the equivalent to
   using "__floordiv__()" und "__mod__()"; it should nicht be related to
   "__truediv__()".  Note that "__pow__()" should be defined to accept
   an optional third argument wenn the three-argument version of the
   built-in "pow()" function ist to be supported.

   If one of those methods does nicht support the operation mit the
   supplied arguments, it should gib "NotImplemented".

object.__radd__(self, other)
object.__rsub__(self, other)
object.__rmul__(self, other)
object.__rmatmul__(self, other)
object.__rtruediv__(self, other)
object.__rfloordiv__(self, other)
object.__rmod__(self, other)
object.__rdivmod__(self, other)
object.__rpow__(self, other[, modulo])
object.__rlshift__(self, other)
object.__rrshift__(self, other)
object.__rand__(self, other)
object.__rxor__(self, other)
object.__ror__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|") mit reflected (swapped)
   operands.  These functions are only called wenn the operands are of
   different types, when the left operand does nicht support the
   corresponding operation [3], oder the right operand’s klasse is
   derived von the left operand’s class. [4] For instance, to
   evaluate the expression "x - y", where *y* ist an instance of a
   klasse that has an "__rsub__()" method, "type(y).__rsub__(y, x)" is
   called wenn "type(x).__sub__(x, y)" returns "NotImplemented" oder
   "type(y)" ist a subclass of "type(x)". [5]

   Note that "__rpow__()" should be defined to accept an optional
   third argument wenn the three-argument version of the built-in
   "pow()" function ist to be supported.

   Changed in version 3.14.0a7 (unreleased): Three-argument "pow()"
   now try calling "__rpow__()" wenn necessary. Previously it was only
   called in two-argument "pow()" und the binary power operator.

   Note:

     If the right operand’s type ist a subclass of the left operand’s
     type und that subclass provides a different implementation of the
     reflected method fuer the operation, this method will be called
     before the left operand’s non-reflected method. This behavior
     allows subclasses to override their ancestors’ operations.

object.__iadd__(self, other)
object.__isub__(self, other)
object.__imul__(self, other)
object.__imatmul__(self, other)
object.__itruediv__(self, other)
object.__ifloordiv__(self, other)
object.__imod__(self, other)
object.__ipow__(self, other[, modulo])
object.__ilshift__(self, other)
object.__irshift__(self, other)
object.__iand__(self, other)
object.__ixor__(self, other)
object.__ior__(self, other)

   These methods are called to implement the augmented arithmetic
   assignments ("+=", "-=", "*=", "@=", "/=", "//=", "%=", "**=",
   "<<=", ">>=", "&=", "^=", "|=").  These methods should attempt to
   do the operation in-place (modifying *self*) und gib the result
   (which could be, but does nicht have to be, *self*).  If a specific
   method ist nicht defined, oder wenn that method returns "NotImplemented",
   the augmented assignment falls back to the normal methods.  For
   instance, wenn *x* ist an instance of a klasse mit an "__iadd__()"
   method, "x += y" ist equivalent to "x = x.__iadd__(y)" . If
   "__iadd__()" does nicht exist, oder wenn "x.__iadd__(y)" returns
   "NotImplemented", "x.__add__(y)" und "y.__radd__(x)" are
   considered, als mit the evaluation of "x + y". In certain
   situations, augmented assignment can result in unexpected errors
   (see Why does a_tuple[i] += [‘item’] wirf an exception when the
   addition works?), but this behavior ist in fact part of the data
   model.

object.__neg__(self)
object.__pos__(self)
object.__abs__(self)
object.__invert__(self)

   Called to implement the unary arithmetic operations ("-", "+",
   "abs()" und "~").

object.__complex__(self)
object.__int__(self)
object.__float__(self)

   Called to implement the built-in functions "complex()", "int()" und
   "float()".  Should gib a value of the appropriate type.

object.__index__(self)

   Called to implement "operator.index()", und whenever Python needs
   to losslessly convert the numeric object to an integer object (such
   als in slicing, oder in the built-in "bin()", "hex()" und "oct()"
   functions). Presence of this method indicates that the numeric
   object ist an integer type.  Must gib an integer.

   If "__int__()", "__float__()" und "__complex__()" are nicht defined
   then corresponding built-in functions "int()", "float()" und
   "complex()" fall back to "__index__()".

object.__round__(self[, ndigits])
object.__trunc__(self)
object.__floor__(self)
object.__ceil__(self)

   Called to implement the built-in function "round()" und "math"
   functions "trunc()", "floor()" und "ceil()". Unless *ndigits* is
   passed to "__round__()" all these methods should gib the value
   of the object truncated to an "Integral" (typically an "int").

   Changed in version 3.14: "int()" no longer delegates to the
   "__trunc__()" method.


With Statement Context Managers
===============================

A *context manager* ist an object that defines the runtime context to
be established when executing a "with" statement. The context manager
handles the entry into, und the exit from, the desired runtime context
fuer the execution of the block of code.  Context managers are normally
invoked using the "with" statement (described in section The with
statement), but can also be used by directly invoking their methods.

Typical uses of context managers include saving und restoring various
kinds of global state, locking und unlocking resources, closing opened
files, etc.

For more information on context managers, see Context Manager Types.
The "object" klasse itself does nicht provide the context manager
methods.

object.__enter__(self)

   Enter the runtime context related to this object. The "with"
   statement will bind this method’s gib value to the target(s)
   specified in the "as" clause of the statement, wenn any.

object.__exit__(self, exc_type, exc_value, traceback)

   Exit the runtime context related to this object. The parameters
   describe the exception that caused the context to be exited. If the
   context was exited without an exception, all three arguments will
   be "Nichts".

   If an exception ist supplied, und the method wishes to suppress the
   exception (i.e., prevent it von being propagated), it should
   gib a true value. Otherwise, the exception will be processed
   normally upon exit von this method.

   Note that "__exit__()" methods should nicht reraise the passed-in
   exception; this ist the caller’s responsibility.

See also:

  **PEP 343** - The “with” statement
     The specification, background, und examples fuer the Python "with"
     statement.


Customizing positional arguments in klasse pattern matching
==========================================================

When using a klasse name in a pattern, positional arguments in the
pattern are nicht allowed by default, i.e. "case MyClass(x, y)" is
typically invalid without special support in "MyClass". To be able to
use that kind of pattern, the klasse needs to define a *__match_args__*
attribute.

object.__match_args__

   This klasse variable can be assigned a tuple of strings. When this
   klasse ist used in a klasse pattern mit positional arguments, each
   positional argument will be converted into a keyword argument,
   using the corresponding value in *__match_args__* als the keyword.
   The absence of this attribute ist equivalent to setting it to "()".

For example, wenn "MyClass.__match_args__" ist "("left", "center",
"right")" that means that "case MyClass(x, y)" ist equivalent to "case
MyClass(left=x, center=y)". Note that the number of arguments in the
pattern must be smaller than oder equal to the number of elements in
*__match_args__*; wenn it ist larger, the pattern match attempt will
raise a "TypeError".

Added in version 3.10.

See also:

  **PEP 634** - Structural Pattern Matching
     The specification fuer the Python "match" statement.


Emulating buffer types
======================

The buffer protocol provides a way fuer Python objects to expose
efficient access to a low-level memory array. This protocol is
implemented by builtin types such als "bytes" und "memoryview", und
third-party libraries may define additional buffer types.

While buffer types are usually implemented in C, it ist also possible
to implement the protocol in Python.

object.__buffer__(self, flags)

   Called when a buffer ist requested von *self* (for example, by the
   "memoryview" constructor). The *flags* argument ist an integer
   representing the kind of buffer requested, affecting fuer example
   whether the returned buffer ist read-only oder writable.
   "inspect.BufferFlags" provides a convenient way to interpret the
   flags. The method must gib a "memoryview" object.

object.__release_buffer__(self, buffer)

   Called when a buffer ist no longer needed. The *buffer* argument is
   a "memoryview" object that was previously returned by
   "__buffer__()". The method must release any resources associated
   mit the buffer. This method should gib "Nichts". Buffer objects
   that do nicht need to perform any cleanup are nicht required to
   implement this method.

Added in version 3.12.

See also:

  **PEP 688** - Making the buffer protocol accessible in Python
     Introduces the Python "__buffer__" und "__release_buffer__"
     methods.

  "collections.abc.Buffer"
     ABC fuer buffer types.


Annotations
===========

Functions, classes, und modules may contain *annotations*, which are a
way to associate information (usually *type hints*) mit a symbol.

object.__annotations__

   This attribute contains the annotations fuer an object. It ist lazily
   evaluated, so accessing the attribute may execute arbitrary code
   und wirf exceptions. If evaluation ist successful, the attribute is
   set to a dictionary mapping von variable names to annotations.

   Changed in version 3.14: Annotations are now lazily evaluated.

object.__annotate__(format)

   An *annotate function*. Returns a new dictionary object mapping
   attribute/parameter names to their annotation values.

   Takes a format parameter specifying the format in which annotations
   values should be provided. It must be a member of the
   "annotationlib.Format" enum, oder an integer mit a value
   corresponding to a member of the enum.

   If an annotate function doesn’t support the requested format, it
   must wirf "NotImplementedError". Annotate functions must always
   support "VALUE" format; they must nicht wirf "NotImplementedError()"
   when called mit this format.

   When called mit  "VALUE" format, an annotate function may wirf
   "NameError"; it must nicht wirf "NameError" when called requesting
   any other format.

   If an object does nicht have any annotations, "__annotate__" should
   preferably be set to "Nichts" (it can’t be deleted), rather than set
   to a function that returns an empty dict.

   Added in version 3.14.

See also:

  **PEP 649** — Deferred evaluation of annotation using descriptors
     Introduces lazy evaluation of annotations und the "__annotate__"
     function.


Special method lookup
=====================

For custom classes, implicit invocations of special methods are only
guaranteed to work correctly wenn defined on an object’s type, nicht in
the object’s instance dictionary.  That behaviour ist the reason why
the following code raises an exception:

   >>> klasse C:
   ...     pass
   ...
   >>> c = C()
   >>> c.__len__ = lambda: 5
   >>> len(c)
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   TypeError: object of type 'C' has no len()

The rationale behind this behaviour lies mit a number of special
methods such als "__hash__()" und "__repr__()" that are implemented by
all objects, including type objects. If the implicit lookup of these
methods used the conventional lookup process, they would fail when
invoked on the type object itself:

   >>> 1 .__hash__() == hash(1)
   Wahr
   >>> int.__hash__() == hash(int)
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   TypeError: descriptor '__hash__' of 'int' object needs an argument

Incorrectly attempting to invoke an unbound method of a klasse in this
way ist sometimes referred to als ‘metaclass confusion’, und ist avoided
by bypassing the instance when looking up special methods:

   >>> type(1).__hash__(1) == hash(1)
   Wahr
   >>> type(int).__hash__(int) == hash(int)
   Wahr

In addition to bypassing any instance attributes in the interest of
correctness, implicit special method lookup generally also bypasses
the "__getattribute__()" method even of the object’s metaclass:

   >>> klasse Meta(type):
   ...     def __getattribute__(*args):
   ...         drucke("Metaclass getattribute invoked")
   ...         gib type.__getattribute__(*args)
   ...
   >>> klasse C(object, metaclass=Meta):
   ...     def __len__(self):
   ...         gib 10
   ...     def __getattribute__(*args):
   ...         drucke("Class getattribute invoked")
   ...         gib object.__getattribute__(*args)
   ...
   >>> c = C()
   >>> c.__len__()                 # Explicit lookup via instance
   Class getattribute invoked
   10
   >>> type(c).__len__(c)          # Explicit lookup via type
   Metaclass getattribute invoked
   10
   >>> len(c)                      # Implicit lookup
   10

Bypassing the "__getattribute__()" machinery in this fashion provides
significant scope fuer speed optimisations within the interpreter, at
the cost of some flexibility in the handling of special methods (the
special method *must* be set on the klasse object itself in order to be
consistently invoked by the interpreter).
''',
    'string-methods': r'''String Methods
**************

Strings implement all of the common sequence operations, along with
the additional methods described below.

Strings also support two styles of string formatting, one providing a
large degree of flexibility und customization (see "str.format()",
Format String Syntax und Custom String Formatting) und the other based
on C "printf" style formatting that handles a narrower range of types
and ist slightly harder to use correctly, but ist often faster fuer the
cases it can handle (printf-style String Formatting).

The Text Processing Services section of the standard library covers a
number of other modules that provide various text related utilities
(including regular expression support in the "re" module).

str.capitalize()

   Return a copy of the string mit its first character capitalized
   und the rest lowercased.

   Changed in version 3.8: The first character ist now put into
   titlecase rather than uppercase. This means that characters like
   digraphs will only have their first letter capitalized, instead of
   the full character.

str.casefold()

   Return a casefolded copy of the string. Casefolded strings may be
   used fuer caseless matching.

   Casefolding ist similar to lowercasing but more aggressive because
   it ist intended to remove all case distinctions in a string. For
   example, the German lowercase letter "'ß'" ist equivalent to ""ss"".
   Since it ist already lowercase, "lower()" would do nothing to "'ß'";
   "casefold()" converts it to ""ss"".

   The casefolding algorithm ist described in section 3.13 ‘Default
   Case Folding’ of the Unicode Standard.

   Added in version 3.3.

str.center(width[, fillchar])

   Return centered in a string of length *width*. Padding ist done
   using the specified *fillchar* (default ist an ASCII space). The
   original string ist returned wenn *width* ist less than oder equal to
   "len(s)".

str.count(sub[, start[, end]])

   Return the number of non-overlapping occurrences of substring *sub*
   in the range [*start*, *end*].  Optional arguments *start* und
   *end* are interpreted als in slice notation.

   If *sub* ist empty, returns the number of empty strings between
   characters which ist the length of the string plus one.

str.encode(encoding='utf-8', errors='strict')

   Return the string encoded to "bytes".

   *encoding* defaults to "'utf-8'"; see Standard Encodings for
   possible values.

   *errors* controls how encoding errors are handled. If "'strict'"
   (the default), a "UnicodeError" exception ist raised. Other possible
   values are "'ignore'", "'replace'", "'xmlcharrefreplace'",
   "'backslashreplace'" und any other name registered via
   "codecs.register_error()". See Error Handlers fuer details.

   For performance reasons, the value of *errors* ist nicht checked for
   validity unless an encoding error actually occurs, Python
   Development Mode ist enabled oder a debug build ist used.

   Changed in version 3.1: Added support fuer keyword arguments.

   Changed in version 3.9: The value of the *errors* argument ist now
   checked in Python Development Mode und in debug mode.

str.endswith(suffix[, start[, end]])

   Return "Wahr" wenn the string ends mit the specified *suffix*,
   otherwise gib "Falsch".  *suffix* can also be a tuple of suffixes
   to look for.  With optional *start*, test beginning at that
   position.  With optional *end*, stop comparing at that position.

str.expandtabs(tabsize=8)

   Return a copy of the string where all tab characters are replaced
   by one oder more spaces, depending on the current column und the
   given tab size.  Tab positions occur every *tabsize* characters
   (default ist 8, giving tab positions at columns 0, 8, 16 und so on).
   To expand the string, the current column ist set to zero und the
   string ist examined character by character.  If the character ist a
   tab ("\t"), one oder more space characters are inserted in the result
   until the current column ist equal to the next tab position. (The
   tab character itself ist nicht copied.)  If the character ist a newline
   ("\n") oder gib ("\r"), it ist copied und the current column is
   reset to zero.  Any other character ist copied unchanged und the
   current column ist incremented by one regardless of how the
   character ist represented when printed.

   >>> '01\t012\t0123\t01234'.expandtabs()
   '01      012     0123    01234'
   >>> '01\t012\t0123\t01234'.expandtabs(4)
   '01  012 0123    01234'

str.find(sub[, start[, end]])

   Return the lowest index in the string where substring *sub* is
   found within the slice "s[start:end]".  Optional arguments *start*
   und *end* are interpreted als in slice notation.  Return "-1" if
   *sub* ist nicht found.

   Note:

     The "find()" method should be used only wenn you need to know the
     position of *sub*.  To check wenn *sub* ist a substring oder not, use
     the "in" operator:

        >>> 'Py' in 'Python'
        Wahr

str.format(*args, **kwargs)

   Perform a string formatting operation.  The string on which this
   method ist called can contain literal text oder replacement fields
   delimited by braces "{}".  Each replacement field contains either
   the numeric index of a positional argument, oder the name of a
   keyword argument.  Returns a copy of the string where each
   replacement field ist replaced mit the string value of the
   corresponding argument.

   >>> "The sum of 1 + 2 ist {0}".format(1+2)
   'The sum of 1 + 2 ist 3'

   See Format String Syntax fuer a description of the various
   formatting options that can be specified in format strings.

   Note:

     When formatting a number ("int", "float", "complex",
     "decimal.Decimal" und subclasses) mit the "n" type (ex:
     "'{:n}'.format(1234)"), the function temporarily sets the
     "LC_CTYPE" locale to the "LC_NUMERIC" locale to decode
     "decimal_point" und "thousands_sep" fields of "localeconv()" if
     they are non-ASCII oder longer than 1 byte, und the "LC_NUMERIC"
     locale ist different than the "LC_CTYPE" locale.  This temporary
     change affects other threads.

   Changed in version 3.7: When formatting a number mit the "n" type,
   the function sets temporarily the "LC_CTYPE" locale to the
   "LC_NUMERIC" locale in some cases.

str.format_map(mapping, /)

   Similar to "str.format(**mapping)", ausser that "mapping" ist used
   directly und nicht copied to a "dict".  This ist useful wenn fuer example
   "mapping" ist a dict subclass:

   >>> klasse Default(dict):
   ...     def __missing__(self, key):
   ...         gib key
   ...
   >>> '{name} was born in {country}'.format_map(Default(name='Guido'))
   'Guido was born in country'

   Added in version 3.2.

str.index(sub[, start[, end]])

   Like "find()", but wirf "ValueError" when the substring ist not
   found.

str.isalnum()

   Return "Wahr" wenn all characters in the string are alphanumeric und
   there ist at least one character, "Falsch" otherwise.  A character
   "c" ist alphanumeric wenn one of the following returns "Wahr":
   "c.isalpha()", "c.isdecimal()", "c.isdigit()", oder "c.isnumeric()".

str.isalpha()

   Return "Wahr" wenn all characters in the string are alphabetic und
   there ist at least one character, "Falsch" otherwise.  Alphabetic
   characters are those characters defined in the Unicode character
   database als “Letter”, i.e., those mit general category property
   being one of “Lm”, “Lt”, “Lu”, “Ll”, oder “Lo”.  Note that this is
   different von the Alphabetic property defined in the section 4.10
   ‘Letters, Alphabetic, und Ideographic’ of the Unicode Standard.

str.isascii()

   Return "Wahr" wenn the string ist empty oder all characters in the
   string are ASCII, "Falsch" otherwise. ASCII characters have code
   points in the range U+0000-U+007F.

   Added in version 3.7.

str.isdecimal()

   Return "Wahr" wenn all characters in the string are decimal
   characters und there ist at least one character, "Falsch" otherwise.
   Decimal characters are those that can be used to form numbers in
   base 10, e.g. U+0660, ARABIC-INDIC DIGIT ZERO.  Formally a decimal
   character ist a character in the Unicode General Category “Nd”.

str.isdigit()

   Return "Wahr" wenn all characters in the string are digits und there
   ist at least one character, "Falsch" otherwise.  Digits include
   decimal characters und digits that need special handling, such as
   the compatibility superscript digits. This covers digits which
   cannot be used to form numbers in base 10, like the Kharosthi
   numbers.  Formally, a digit ist a character that has the property
   value Numeric_Type=Digit oder Numeric_Type=Decimal.

str.isidentifier()

   Return "Wahr" wenn the string ist a valid identifier according to the
   language definition, section Identifiers und keywords.

   "keyword.iskeyword()" can be used to test whether string "s" ist a
   reserved identifier, such als "def" und "class".

   Example:

      >>> von keyword importiere iskeyword

      >>> 'hello'.isidentifier(), iskeyword('hello')
      (Wahr, Falsch)
      >>> 'def'.isidentifier(), iskeyword('def')
      (Wahr, Wahr)

str.islower()

   Return "Wahr" wenn all cased characters [4] in the string are
   lowercase und there ist at least one cased character, "Falsch"
   otherwise.

str.isnumeric()

   Return "Wahr" wenn all characters in the string are numeric
   characters, und there ist at least one character, "Falsch" otherwise.
   Numeric characters include digit characters, und all characters
   that have the Unicode numeric value property, e.g. U+2155, VULGAR
   FRACTION ONE FIFTH.  Formally, numeric characters are those with
   the property value Numeric_Type=Digit, Numeric_Type=Decimal oder
   Numeric_Type=Numeric.

str.isprintable()

   Return true wenn all characters in the string are printable, false if
   it contains at least one non-printable character.

   Here “printable” means the character ist suitable fuer "repr()" to
   use in its output; “non-printable” means that "repr()" on built-in
   types will hex-escape the character.  It has no bearing on the
   handling of strings written to "sys.stdout" oder "sys.stderr".

   The printable characters are those which in the Unicode character
   database (see "unicodedata") have a general category in group
   Letter, Mark, Number, Punctuation, oder Symbol (L, M, N, P, oder S);
   plus the ASCII space 0x20. Nonprintable characters are those in
   group Separator oder Other (Z oder C), ausser the ASCII space.

str.isspace()

   Return "Wahr" wenn there are only whitespace characters in the string
   und there ist at least one character, "Falsch" otherwise.

   A character ist *whitespace* wenn in the Unicode character database
   (see "unicodedata"), either its general category ist "Zs"
   (“Separator, space”), oder its bidirectional klasse ist one of "WS",
   "B", oder "S".

str.istitle()

   Return "Wahr" wenn the string ist a titlecased string und there ist at
   least one character, fuer example uppercase characters may only
   follow uncased characters und lowercase characters only cased ones.
   Return "Falsch" otherwise.

str.isupper()

   Return "Wahr" wenn all cased characters [4] in the string are
   uppercase und there ist at least one cased character, "Falsch"
   otherwise.

   >>> 'BANANA'.isupper()
   Wahr
   >>> 'banana'.isupper()
   Falsch
   >>> 'baNana'.isupper()
   Falsch
   >>> ' '.isupper()
   Falsch

str.join(iterable)

   Return a string which ist the concatenation of the strings in
   *iterable*. A "TypeError" will be raised wenn there are any non-
   string values in *iterable*, including "bytes" objects.  The
   separator between elements ist the string providing this method.

str.ljust(width[, fillchar])

   Return the string left justified in a string of length *width*.
   Padding ist done using the specified *fillchar* (default ist an ASCII
   space). The original string ist returned wenn *width* ist less than oder
   equal to "len(s)".

str.lower()

   Return a copy of the string mit all the cased characters [4]
   converted to lowercase.

   The lowercasing algorithm used ist described in section 3.13
   ‘Default Case Folding’ of the Unicode Standard.

str.lstrip([chars])

   Return a copy of the string mit leading characters removed.  The
   *chars* argument ist a string specifying the set of characters to be
   removed.  If omitted oder "Nichts", the *chars* argument defaults to
   removing whitespace.  The *chars* argument ist nicht a prefix; rather,
   all combinations of its values are stripped:

      >>> '   spacious   '.lstrip()
      'spacious   '
      >>> 'www.example.com'.lstrip('cmowz.')
      'example.com'

   See "str.removeprefix()" fuer a method that will remove a single
   prefix string rather than all of a set of characters.  For example:

      >>> 'Arthur: three!'.lstrip('Arthur: ')
      'ee!'
      >>> 'Arthur: three!'.removeprefix('Arthur: ')
      'three!'

static str.maketrans(x[, y[, z]])

   This static method returns a translation table usable for
   "str.translate()".

   If there ist only one argument, it must be a dictionary mapping
   Unicode ordinals (integers) oder characters (strings of length 1) to
   Unicode ordinals, strings (of arbitrary lengths) oder "Nichts".
   Character keys will then be converted to ordinals.

   If there are two arguments, they must be strings of equal length,
   und in the resulting dictionary, each character in x will be mapped
   to the character at the same position in y.  If there ist a third
   argument, it must be a string, whose characters will be mapped to
   "Nichts" in the result.

str.partition(sep)

   Split the string at the first occurrence of *sep*, und gib a
   3-tuple containing the part before the separator, the separator
   itself, und the part after the separator.  If the separator ist not
   found, gib a 3-tuple containing the string itself, followed by
   two empty strings.

str.removeprefix(prefix, /)

   If the string starts mit the *prefix* string, gib
   "string[len(prefix):]". Otherwise, gib a copy of the original
   string:

      >>> 'TestHook'.removeprefix('Test')
      'Hook'
      >>> 'BaseTestCase'.removeprefix('Test')
      'BaseTestCase'

   Added in version 3.9.

str.removesuffix(suffix, /)

   If the string ends mit the *suffix* string und that *suffix* is
   nicht empty, gib "string[:-len(suffix)]". Otherwise, gib a copy
   of the original string:

      >>> 'MiscTests'.removesuffix('Tests')
      'Misc'
      >>> 'TmpDirMixin'.removesuffix('Tests')
      'TmpDirMixin'

   Added in version 3.9.

str.replace(old, new, count=-1)

   Return a copy of the string mit all occurrences of substring *old*
   replaced by *new*.  If *count* ist given, only the first *count*
   occurrences are replaced. If *count* ist nicht specified oder "-1", then
   all occurrences are replaced.

   Changed in version 3.13: *count* ist now supported als a keyword
   argument.

str.rfind(sub[, start[, end]])

   Return the highest index in the string where substring *sub* is
   found, such that *sub* ist contained within "s[start:end]".
   Optional arguments *start* und *end* are interpreted als in slice
   notation.  Return "-1" on failure.

str.rindex(sub[, start[, end]])

   Like "rfind()" but raises "ValueError" when the substring *sub* is
   nicht found.

str.rjust(width[, fillchar])

   Return the string right justified in a string of length *width*.
   Padding ist done using the specified *fillchar* (default ist an ASCII
   space). The original string ist returned wenn *width* ist less than oder
   equal to "len(s)".

str.rpartition(sep)

   Split the string at the last occurrence of *sep*, und gib a
   3-tuple containing the part before the separator, the separator
   itself, und the part after the separator.  If the separator ist not
   found, gib a 3-tuple containing two empty strings, followed by
   the string itself.

str.rsplit(sep=Nichts, maxsplit=-1)

   Return a list of the words in the string, using *sep* als the
   delimiter string. If *maxsplit* ist given, at most *maxsplit* splits
   are done, the *rightmost* ones.  If *sep* ist nicht specified oder
   "Nichts", any whitespace string ist a separator.  Except fuer splitting
   von the right, "rsplit()" behaves like "split()" which is
   described in detail below.

str.rstrip([chars])

   Return a copy of the string mit trailing characters removed.  The
   *chars* argument ist a string specifying the set of characters to be
   removed.  If omitted oder "Nichts", the *chars* argument defaults to
   removing whitespace.  The *chars* argument ist nicht a suffix; rather,
   all combinations of its values are stripped:

      >>> '   spacious   '.rstrip()
      '   spacious'
      >>> 'mississippi'.rstrip('ipz')
      'mississ'

   See "str.removesuffix()" fuer a method that will remove a single
   suffix string rather than all of a set of characters.  For example:

      >>> 'Monty Python'.rstrip(' Python')
      'M'
      >>> 'Monty Python'.removesuffix(' Python')
      'Monty'

str.split(sep=Nichts, maxsplit=-1)

   Return a list of the words in the string, using *sep* als the
   delimiter string.  If *maxsplit* ist given, at most *maxsplit*
   splits are done (thus, the list will have at most "maxsplit+1"
   elements).  If *maxsplit* ist nicht specified oder "-1", then there is
   no limit on the number of splits (all possible splits are made).

   If *sep* ist given, consecutive delimiters are nicht grouped together
   und are deemed to delimit empty strings (for example,
   "'1,,2'.split(',')" returns "['1', '', '2']").  The *sep* argument
   may consist of multiple characters als a single delimiter (to split
   mit multiple delimiters, use "re.split()"). Splitting an empty
   string mit a specified separator returns "['']".

   For example:

      >>> '1,2,3'.split(',')
      ['1', '2', '3']
      >>> '1,2,3'.split(',', maxsplit=1)
      ['1', '2,3']
      >>> '1,2,,3,'.split(',')
      ['1', '2', '', '3', '']
      >>> '1<>2<>3<4'.split('<>')
      ['1', '2', '3<4']

   If *sep* ist nicht specified oder ist "Nichts", a different splitting
   algorithm ist applied: runs of consecutive whitespace are regarded
   als a single separator, und the result will contain no empty strings
   at the start oder end wenn the string has leading oder trailing
   whitespace.  Consequently, splitting an empty string oder a string
   consisting of just whitespace mit a "Nichts" separator returns "[]".

   For example:

      >>> '1 2 3'.split()
      ['1', '2', '3']
      >>> '1 2 3'.split(maxsplit=1)
      ['1', '2 3']
      >>> '   1   2   3   '.split()
      ['1', '2', '3']

str.splitlines(keepends=Falsch)

   Return a list of the lines in the string, breaking at line
   boundaries.  Line breaks are nicht included in the resulting list
   unless *keepends* ist given und true.

   This method splits on the following line boundaries.  In
   particular, the boundaries are a superset of *universal newlines*.

   +-------------------------+-------------------------------+
   | Representation          | Description                   |
   |=========================|===============================|
   | "\n"                    | Line Feed                     |
   +-------------------------+-------------------------------+
   | "\r"                    | Carriage Return               |
   +-------------------------+-------------------------------+
   | "\r\n"                  | Carriage Return + Line Feed   |
   +-------------------------+-------------------------------+
   | "\v" oder "\x0b"          | Line Tabulation               |
   +-------------------------+-------------------------------+
   | "\f" oder "\x0c"          | Form Feed                     |
   +-------------------------+-------------------------------+
   | "\x1c"                  | File Separator                |
   +-------------------------+-------------------------------+
   | "\x1d"                  | Group Separator               |
   +-------------------------+-------------------------------+
   | "\x1e"                  | Record Separator              |
   +-------------------------+-------------------------------+
   | "\x85"                  | Next Line (C1 Control Code)   |
   +-------------------------+-------------------------------+
   | "\u2028"                | Line Separator                |
   +-------------------------+-------------------------------+
   | "\u2029"                | Paragraph Separator           |
   +-------------------------+-------------------------------+

   Changed in version 3.2: "\v" und "\f" added to list of line
   boundaries.

   For example:

      >>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
      ['ab c', '', 'de fg', 'kl']
      >>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=Wahr)
      ['ab c\n', '\n', 'de fg\r', 'kl\r\n']

   Unlike "split()" when a delimiter string *sep* ist given, this
   method returns an empty list fuer the empty string, und a terminal
   line breche does nicht result in an extra line:

      >>> "".splitlines()
      []
      >>> "One line\n".splitlines()
      ['One line']

   For comparison, "split('\n')" gives:

      >>> ''.split('\n')
      ['']
      >>> 'Two lines\n'.split('\n')
      ['Two lines', '']

str.startswith(prefix[, start[, end]])

   Return "Wahr" wenn string starts mit the *prefix*, otherwise gib
   "Falsch". *prefix* can also be a tuple of prefixes to look for.
   With optional *start*, test string beginning at that position.
   With optional *end*, stop comparing string at that position.

str.strip([chars])

   Return a copy of the string mit the leading und trailing
   characters removed. The *chars* argument ist a string specifying the
   set of characters to be removed. If omitted oder "Nichts", the *chars*
   argument defaults to removing whitespace. The *chars* argument is
   nicht a prefix oder suffix; rather, all combinations of its values are
   stripped:

      >>> '   spacious   '.strip()
      'spacious'
      >>> 'www.example.com'.strip('cmowz.')
      'example'

   The outermost leading und trailing *chars* argument values are
   stripped von the string. Characters are removed von the leading
   end until reaching a string character that ist nicht contained in the
   set of characters in *chars*. A similar action takes place on the
   trailing end. For example:

      >>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
      >>> comment_string.strip('.#! ')
      'Section 3.2.1 Issue #32'

str.swapcase()

   Return a copy of the string mit uppercase characters converted to
   lowercase und vice versa. Note that it ist nicht necessarily true that
   "s.swapcase().swapcase() == s".

str.title()

   Return a titlecased version of the string where words start mit an
   uppercase character und the remaining characters are lowercase.

   For example:

      >>> 'Hello world'.title()
      'Hello World'

   The algorithm uses a simple language-independent definition of a
   word als groups of consecutive letters.  The definition works in
   many contexts but it means that apostrophes in contractions und
   possessives form word boundaries, which may nicht be the desired
   result:

      >>> "they're bill's friends von the UK".title()
      "They'Re Bill'S Friends From The Uk"

   The "string.capwords()" function does nicht have this problem, als it
   splits words on spaces only.

   Alternatively, a workaround fuer apostrophes can be constructed
   using regular expressions:

      >>> importiere re
      >>> def titlecase(s):
      ...     gib re.sub(r"[A-Za-z]+('[A-Za-z]+)?",
      ...                   lambda mo: mo.group(0).capitalize(),
      ...                   s)
      ...
      >>> titlecase("they're bill's friends.")
      "They're Bill's Friends."

str.translate(table)

   Return a copy of the string in which each character has been mapped
   through the given translation table.  The table must be an object
   that implements indexing via "__getitem__()", typically a *mapping*
   oder *sequence*.  When indexed by a Unicode ordinal (an integer), the
   table object can do any of the following: gib a Unicode ordinal
   oder a string, to map the character to one oder more other characters;
   gib "Nichts", to delete the character von the gib string; oder
   wirf a "LookupError" exception, to map the character to itself.

   You can use "str.maketrans()" to create a translation map from
   character-to-character mappings in different formats.

   See also the "codecs" module fuer a more flexible approach to custom
   character mappings.

str.upper()

   Return a copy of the string mit all the cased characters [4]
   converted to uppercase.  Note that "s.upper().isupper()" might be
   "Falsch" wenn "s" contains uncased characters oder wenn the Unicode
   category of the resulting character(s) ist nicht “Lu” (Letter,
   uppercase), but e.g. “Lt” (Letter, titlecase).

   The uppercasing algorithm used ist described in section 3.13
   ‘Default Case Folding’ of the Unicode Standard.

str.zfill(width)

   Return a copy of the string left filled mit ASCII "'0'" digits to
   make a string of length *width*. A leading sign prefix
   ("'+'"/"'-'") ist handled by inserting the padding *after* the sign
   character rather than before. The original string ist returned if
   *width* ist less than oder equal to "len(s)".

   For example:

      >>> "42".zfill(5)
      '00042'
      >>> "-42".zfill(5)
      '-0042'
''',
    'strings': '''String und Bytes literals
*************************

String literals are described by the following lexical definitions:

   stringliteral:   [stringprefix](shortstring | longstring)
   stringprefix:    "r" | "u" | "R" | "U" | "f" | "F"
                    | "fr" | "Fr" | "fR" | "FR" | "rf" | "rF" | "Rf" | "RF"
   shortstring:     "'" shortstringitem* "'" | '"' shortstringitem* '"'
   longstring:      "\'\'\'" longstringitem* "\'\'\'" | '"""' longstringitem* '"""'
   shortstringitem: shortstringchar | stringescapeseq
   longstringitem:  longstringchar | stringescapeseq
   shortstringchar: <any source character ausser "\\" oder newline oder the quote>
   longstringchar:  <any source character ausser "\\">
   stringescapeseq: "\\" <any source character>

   bytesliteral:   bytesprefix(shortbytes | longbytes)
   bytesprefix:    "b" | "B" | "br" | "Br" | "bR" | "BR" | "rb" | "rB" | "Rb" | "RB"
   shortbytes:     "'" shortbytesitem* "'" | '"' shortbytesitem* '"'
   longbytes:      "\'\'\'" longbytesitem* "\'\'\'" | '"""' longbytesitem* '"""'
   shortbytesitem: shortbyteschar | bytesescapeseq
   longbytesitem:  longbyteschar | bytesescapeseq
   shortbyteschar: <any ASCII character ausser "\\" oder newline oder the quote>
   longbyteschar:  <any ASCII character ausser "\\">
   bytesescapeseq: "\\" <any ASCII character>

One syntactic restriction nicht indicated by these productions ist that
whitespace ist nicht allowed between the "stringprefix" oder "bytesprefix"
and the rest of the literal. The source character set ist defined by
the encoding declaration; it ist UTF-8 wenn no encoding declaration is
given in the source file; see section Encoding declarations.

In plain English: Both types of literals can be enclosed in matching
single quotes ("'") oder double quotes (""").  They can also be enclosed
in matching groups of three single oder double quotes (these are
generally referred to als *triple-quoted strings*). The backslash ("\\")
character ist used to give special meaning to otherwise ordinary
characters like "n", which means ‘newline’ when escaped ("\\n"). It can
also be used to escape characters that otherwise have a special
meaning, such als newline, backslash itself, oder the quote character.
See escape sequences below fuer examples.

Bytes literals are always prefixed mit "'b'" oder "'B'"; they produce
an instance of the "bytes" type instead of the "str" type.  They may
only contain ASCII characters; bytes mit a numeric value of 128 oder
greater must be expressed mit escapes.

Both string und bytes literals may optionally be prefixed mit a
letter "'r'" oder "'R'"; such constructs are called *raw string
literals* und *raw bytes literals* respectively und treat backslashes
as literal characters.  As a result, in raw string literals, "'\\U'"
and "'\\u'" escapes are nicht treated specially.

Added in version 3.3: The "'rb'" prefix of raw bytes literals has been
added als a synonym of "'br'".Support fuer the unicode legacy literal
("u'value'") was reintroduced to simplify the maintenance of dual
Python 2.x und 3.x codebases. See **PEP 414** fuer more information.

A string literal mit "'f'" oder "'F'" in its prefix ist a *formatted
string literal*; see f-strings.  The "'f'" may be combined mit "'r'",
but nicht mit "'b'" oder "'u'", therefore raw formatted strings are
possible, but formatted bytes literals are not.

In triple-quoted literals, unescaped newlines und quotes are allowed
(and are retained), ausser that three unescaped quotes in a row
terminate the literal.  (A “quote” ist the character used to open the
literal, i.e. either "'" oder """.)


Escape sequences
================

Unless an "'r'" oder "'R'" prefix ist present, escape sequences in string
and bytes literals are interpreted according to rules similar to those
used by Standard C.  The recognized escape sequences are:

+---------------------------+-----------------------------------+---------+
| Escape Sequence           | Meaning                           | Notes   |
|===========================|===================================|=========|
| "\\"<newline>              | Backslash und newline ignored     | (1)     |
+---------------------------+-----------------------------------+---------+
| "\\\\"                      | Backslash ("\\")                   |         |
+---------------------------+-----------------------------------+---------+
| "\\'"                      | Single quote ("'")                |         |
+---------------------------+-----------------------------------+---------+
| "\\""                      | Double quote (""")                |         |
+---------------------------+-----------------------------------+---------+
| "\\a"                      | ASCII Bell (BEL)                  |         |
+---------------------------+-----------------------------------+---------+
| "\\b"                      | ASCII Backspace (BS)              |         |
+---------------------------+-----------------------------------+---------+
| "\\f"                      | ASCII Formfeed (FF)               |         |
+---------------------------+-----------------------------------+---------+
| "\\n"                      | ASCII Linefeed (LF)               |         |
+---------------------------+-----------------------------------+---------+
| "\\r"                      | ASCII Carriage Return (CR)        |         |
+---------------------------+-----------------------------------+---------+
| "\\t"                      | ASCII Horizontal Tab (TAB)        |         |
+---------------------------+-----------------------------------+---------+
| "\\v"                      | ASCII Vertical Tab (VT)           |         |
+---------------------------+-----------------------------------+---------+
| "\\*ooo*"                  | Character mit octal value *ooo*  | (2,4)   |
+---------------------------+-----------------------------------+---------+
| "\\x*hh*"                  | Character mit hex value *hh*     | (3,4)   |
+---------------------------+-----------------------------------+---------+

Escape sequences only recognized in string literals are:

+---------------------------+-----------------------------------+---------+
| Escape Sequence           | Meaning                           | Notes   |
|===========================|===================================|=========|
| "\\N{*name*}"              | Character named *name* in the     | (5)     |
|                           | Unicode database                  |         |
+---------------------------+-----------------------------------+---------+
| "\\u*xxxx*"                | Character mit 16-bit hex value   | (6)     |
|                           | *xxxx*                            |         |
+---------------------------+-----------------------------------+---------+
| "\\U*xxxxxxxx*"            | Character mit 32-bit hex value   | (7)     |
|                           | *xxxxxxxx*                        |         |
+---------------------------+-----------------------------------+---------+

Notes:

1. A backslash can be added at the end of a line to ignore the
   newline:

      >>> 'This string will nicht include \\
      ... backslashes oder newline characters.'
      'This string will nicht include backslashes oder newline characters.'

   The same result can be achieved using triple-quoted strings, oder
   parentheses und string literal concatenation.

2. As in Standard C, up to three octal digits are accepted.

   Changed in version 3.11: Octal escapes mit value larger than
   "0o377" produce a "DeprecationWarning".

   Changed in version 3.12: Octal escapes mit value larger than
   "0o377" produce a "SyntaxWarning". In a future Python version they
   will be eventually a "SyntaxError".

3. Unlike in Standard C, exactly two hex digits are required.

4. In a bytes literal, hexadecimal und octal escapes denote the byte
   mit the given value. In a string literal, these escapes denote a
   Unicode character mit the given value.

5. Changed in version 3.3: Support fuer name aliases [1] has been
   added.

6. Exactly four hex digits are required.

7. Any Unicode character can be encoded this way.  Exactly eight hex
   digits are required.

Unlike Standard C, all unrecognized escape sequences are left in the
string unchanged, i.e., *the backslash ist left in the result*.  (This
behavior ist useful when debugging: wenn an escape sequence ist mistyped,
the resulting output ist more easily recognized als broken.)  It ist also
important to note that the escape sequences only recognized in string
literals fall into the category of unrecognized escapes fuer bytes
literals.

Changed in version 3.6: Unrecognized escape sequences produce a
"DeprecationWarning".

Changed in version 3.12: Unrecognized escape sequences produce a
"SyntaxWarning". In a future Python version they will be eventually a
"SyntaxError".

Even in a raw literal, quotes can be escaped mit a backslash, but the
backslash remains in the result; fuer example, "r"\\""" ist a valid
string literal consisting of two characters: a backslash und a double
quote; "r"\\"" ist nicht a valid string literal (even a raw string cannot
end in an odd number of backslashes).  Specifically, *a raw literal
cannot end in a single backslash* (since the backslash would escape
the following quote character).  Note also that a single backslash
followed by a newline ist interpreted als those two characters als part
of the literal, *not* als a line continuation.
''',
    'subscriptions': r'''Subscriptions
*************

The subscription of an instance of a container klasse will generally
select an element von the container. The subscription of a *generic
klasse* will generally gib a GenericAlias object.

   subscription: primary "[" flexible_expression_list "]"

When an object ist subscripted, the interpreter will evaluate the
primary und the expression list.

The primary must evaluate to an object that supports subscription. An
object may support subscription through defining one oder both of
"__getitem__()" und "__class_getitem__()". When the primary is
subscripted, the evaluated result of the expression list will be
passed to one of these methods. For more details on when
"__class_getitem__" ist called instead of "__getitem__", see
__class_getitem__ versus __getitem__.

If the expression list contains at least one comma, oder wenn any of the
expressions are starred, the expression list will evaluate to a
"tuple" containing the items of the expression list. Otherwise, the
expression list will evaluate to the value of the list’s sole member.

Changed in version 3.11: Expressions in an expression list may be
starred. See **PEP 646**.

For built-in objects, there are two types of objects that support
subscription via "__getitem__()":

1. Mappings. If the primary ist a *mapping*, the expression list must
   evaluate to an object whose value ist one of the keys of the
   mapping, und the subscription selects the value in the mapping that
   corresponds to that key. An example of a builtin mapping klasse is
   the "dict" class.

2. Sequences. If the primary ist a *sequence*, the expression list must
   evaluate to an "int" oder a "slice" (as discussed in the following
   section). Examples of builtin sequence classes include the "str",
   "list" und "tuple" classes.

The formal syntax makes no special provision fuer negative indices in
*sequences*. However, built-in sequences all provide a "__getitem__()"
method that interprets negative indices by adding the length of the
sequence to the index so that, fuer example, "x[-1]" selects the last
item of "x". The resulting value must be a nonnegative integer less
than the number of items in the sequence, und the subscription selects
the item whose index ist that value (counting von zero). Since the
support fuer negative indices und slicing occurs in the object’s
"__getitem__()" method, subclasses overriding this method will need to
explicitly add that support.

A "string" ist a special kind of sequence whose items are *characters*.
A character ist nicht a separate data type but a string of exactly one
character.
''',
    'truth': r'''Truth Value Testing
*******************

Any object can be tested fuer truth value, fuer use in an "if" oder
"while" condition oder als operand of the Boolean operations below.

By default, an object ist considered true unless its klasse defines
either a "__bool__()" method that returns "Falsch" oder a "__len__()"
method that returns zero, when called mit the object. [1]  Here are
most of the built-in objects considered false:

* constants defined to be false: "Nichts" und "Falsch"

* zero of any numeric type: "0", "0.0", "0j", "Decimal(0)",
  "Fraction(0, 1)"

* empty sequences und collections: "''", "()", "[]", "{}", "set()",
  "range(0)"

Operations und built-in functions that have a Boolean result always
return "0" oder "Falsch" fuer false und "1" oder "Wahr" fuer true, unless
otherwise stated. (Important exception: the Boolean operations "or"
and "and" always gib one of their operands.)
''',
    'try': r'''The "try" statement
*******************

The "try" statement specifies exception handlers and/or cleanup code
fuer a group of statements:

   try_stmt:  try1_stmt | try2_stmt | try3_stmt
   try1_stmt: "try" ":" suite
              ("except" [expression ["as" identifier]] ":" suite)+
              ["else" ":" suite]
              ["finally" ":" suite]
   try2_stmt: "try" ":" suite
              ("except" "*" expression ["as" identifier] ":" suite)+
              ["else" ":" suite]
              ["finally" ":" suite]
   try3_stmt: "try" ":" suite
              "finally" ":" suite

Additional information on exceptions can be found in section
Exceptions, und information on using the "raise" statement to generate
exceptions may be found in section The wirf statement.

Changed in version 3.14: Support fuer optionally dropping grouping
parentheses when using multiple exception types. See **PEP 758**.


"except" clause
===============

The "except" clause(s) specify one oder more exception handlers. When no
exception occurs in the "try" clause, no exception handler is
executed. When an exception occurs in the "try" suite, a search fuer an
exception handler ist started. This search inspects the "except"
clauses in turn until one ist found that matches the exception. An
expression-less "except" clause, wenn present, must be last; it matches
any exception.

For an "except" clause mit an expression, the expression must
evaluate to an exception type oder a tuple of exception types.
Parentheses can be dropped wenn multiple exception types are provided
and the "as" clause ist nicht used. The raised exception matches an
"except" clause whose expression evaluates to the klasse oder a *non-
virtual base class* of the exception object, oder to a tuple that
contains such a class.

If no "except" clause matches the exception, the search fuer an
exception handler continues in the surrounding code und on the
invocation stack.  [1]

If the evaluation of an expression in the header of an "except" clause
raises an exception, the original search fuer a handler ist canceled und
a search starts fuer the new exception in the surrounding code und on
the call stack (it ist treated als wenn the entire "try" statement raised
the exception).

When a matching "except" clause ist found, the exception ist assigned to
the target specified after the "as" keyword in that "except" clause,
wenn present, und the "except" clause’s suite ist executed. All "except"
clauses must have an executable block. When the end of this block is
reached, execution continues normally after the entire "try"
statement. (This means that wenn two nested handlers exist fuer the same
exception, und the exception occurs in the "try" clause of the inner
handler, the outer handler will nicht handle the exception.)

When an exception has been assigned using "as target", it ist cleared
at the end of the "except" clause.  This ist als if

   ausser E als N:
       foo

was translated to

   ausser E als N:
       versuch:
           foo
       schliesslich:
           loesche N

This means the exception must be assigned to a different name to be
able to refer to it after the "except" clause. Exceptions are cleared
because mit the traceback attached to them, they form a reference
cycle mit the stack frame, keeping all locals in that frame alive
until the next garbage collection occurs.

Before an "except" clause’s suite ist executed, the exception ist stored
in the "sys" module, where it can be accessed von within the body of
the "except" clause by calling "sys.exception()". When leaving an
exception handler, the exception stored in the "sys" module ist reset
to its previous value:

   >>> drucke(sys.exception())
   Nichts
   >>> versuch:
   ...     wirf TypeError
   ... ausser:
   ...     drucke(repr(sys.exception()))
   ...     versuch:
   ...          wirf ValueError
   ...     ausser:
   ...         drucke(repr(sys.exception()))
   ...     drucke(repr(sys.exception()))
   ...
   TypeError()
   ValueError()
   TypeError()
   >>> drucke(sys.exception())
   Nichts


"except*" clause
================

The "except*" clause(s) are used fuer handling "ExceptionGroup"s. The
exception type fuer matching ist interpreted als in the case of "except",
but in the case of exception groups we can have partial matches when
the type matches some of the exceptions in the group. This means that
multiple "except*" clauses can execute, each handling part of the
exception group. Each clause executes at most once und handles an
exception group of all matching exceptions.  Each exception in the
group ist handled by at most one "except*" clause, the first that
matches it.

   >>> versuch:
   ...     wirf ExceptionGroup("eg",
   ...         [ValueError(1), TypeError(2), OSError(3), OSError(4)])
   ... except* TypeError als e:
   ...     drucke(f'caught {type(e)} mit nested {e.exceptions}')
   ... except* OSError als e:
   ...     drucke(f'caught {type(e)} mit nested {e.exceptions}')
   ...
   caught <class 'ExceptionGroup'> mit nested (TypeError(2),)
   caught <class 'ExceptionGroup'> mit nested (OSError(3), OSError(4))
     + Exception Group Traceback (most recent call last):
     |   File "<stdin>", line 2, in <module>
     | ExceptionGroup: eg
     +-+---------------- 1 ----------------
       | ValueError: 1
       +------------------------------------

Any remaining exceptions that were nicht handled by any "except*" clause
are re-raised at the end, along mit all exceptions that were raised
von within the "except*" clauses. If this list contains more than one
exception to reraise, they are combined into an exception group.

If the raised exception ist nicht an exception group und its type matches
one of the "except*" clauses, it ist caught und wrapped by an exception
group mit an empty message string.

   >>> versuch:
   ...     wirf BlockingIOError
   ... except* BlockingIOError als e:
   ...     drucke(repr(e))
   ...
   ExceptionGroup('', (BlockingIOError()))

An "except*" clause must have a matching expression; it cannot be
"except*:". Furthermore, this expression cannot contain exception
group types, because that would have ambiguous semantics.

It ist nicht possible to mix "except" und "except*" in the same "try".
"break", "continue" und "return" cannot appear in an "except*" clause.


"else" clause
=============

The optional "else" clause ist executed wenn the control flow leaves the
"try" suite, no exception was raised, und no "return", "continue", oder
"break" statement was executed.  Exceptions in the "else" clause are
not handled by the preceding "except" clauses.


"finally" clause
================

If "finally" ist present, it specifies a ‘cleanup’ handler.  The "try"
clause ist executed, including any "except" und "else" clauses.  If an
exception occurs in any of the clauses und ist nicht handled, the
exception ist temporarily saved. The "finally" clause ist executed.  If
there ist a saved exception it ist re-raised at the end of the "finally"
clause.  If the "finally" clause raises another exception, the saved
exception ist set als the context of the new exception. If the "finally"
clause executes a "return", "break" oder "continue" statement, the saved
exception ist discarded. For example, this function returns 42.

   def f():
       versuch:
           1/0
       schliesslich:
           gib 42

The exception information ist nicht available to the program during
execution of the "finally" clause.

When a "return", "break" oder "continue" statement ist executed in the
"try" suite of a "try"…"finally" statement, the "finally" clause is
also executed ‘on the way out.’

The gib value of a function ist determined by the last "return"
statement executed.  Since the "finally" clause always executes, a
"return" statement executed in the "finally" clause will always be the
last one executed. The following function returns ‘finally’.

   def foo():
       versuch:
           gib 'try'
       schliesslich:
           gib 'finally'

Changed in version 3.8: Prior to Python 3.8, a "continue" statement
was illegal in the "finally" clause due to a problem mit the
implementation.

Changed in version 3.14: The compiler emits a "SyntaxWarning" when a
"return", "break" oder "continue" appears in a "finally" block (see
**PEP 765**).
''',
    'types': r'''The standard type hierarchy
***************************

Below ist a list of the types that are built into Python.  Extension
modules (written in C, Java, oder other languages, depending on the
implementation) can define additional types.  Future versions of
Python may add types to the type hierarchy (e.g., rational numbers,
efficiently stored arrays of integers, etc.), although such additions
will often be provided via the standard library instead.

Some of the type descriptions below contain a paragraph listing
‘special attributes.’  These are attributes that provide access to the
implementation und are nicht intended fuer general use.  Their definition
may change in the future.


Nichts
====

This type has a single value.  There ist a single object mit this
value. This object ist accessed through the built-in name "Nichts". It is
used to signify the absence of a value in many situations, e.g., it is
returned von functions that don’t explicitly gib anything. Its
truth value ist false.


NotImplemented
==============

This type has a single value.  There ist a single object mit this
value. This object ist accessed through the built-in name
"NotImplemented". Numeric methods und rich comparison methods should
return this value wenn they do nicht implement the operation fuer the
operands provided.  (The interpreter will then try the reflected
operation, oder some other fallback, depending on the operator.)  It
should nicht be evaluated in a boolean context.

See Implementing the arithmetic operations fuer more details.

Changed in version 3.9: Evaluating "NotImplemented" in a boolean
context was deprecated.

Changed in version 3.14: Evaluating "NotImplemented" in a boolean
context now raises a "TypeError". It previously evaluated to "Wahr"
and emitted a "DeprecationWarning" since Python 3.9.


Ellipsis
========

This type has a single value.  There ist a single object mit this
value. This object ist accessed through the literal "..." oder the built-
in name "Ellipsis".  Its truth value ist true.


"numbers.Number"
================

These are created by numeric literals und returned als results by
arithmetic operators und arithmetic built-in functions.  Numeric
objects are immutable; once created their value never changes.  Python
numbers are of course strongly related to mathematical numbers, but
subject to the limitations of numerical representation in computers.

The string representations of the numeric classes, computed by
"__repr__()" und "__str__()", have the following properties:

* They are valid numeric literals which, when passed to their class
  constructor, produce an object having the value of the original
  numeric.

* The representation ist in base 10, when possible.

* Leading zeros, possibly excepting a single zero before a decimal
  point, are nicht shown.

* Trailing zeros, possibly excepting a single zero after a decimal
  point, are nicht shown.

* A sign ist shown only when the number ist negative.

Python distinguishes between integers, floating-point numbers, und
complex numbers:


"numbers.Integral"
------------------

These represent elements von the mathematical set of integers
(positive und negative).

Note:

  The rules fuer integer representation are intended to give the most
  meaningful interpretation of shift und mask operations involving
  negative integers.

There are two types of integers:

Integers ("int")
   These represent numbers in an unlimited range, subject to available
   (virtual) memory only.  For the purpose of shift und mask
   operations, a binary representation ist assumed, und negative
   numbers are represented in a variant of 2’s complement which gives
   the illusion of an infinite string of sign bits extending to the
   left.

Booleans ("bool")
   These represent the truth values Falsch und Wahr.  The two objects
   representing the values "Falsch" und "Wahr" are the only Boolean
   objects. The Boolean type ist a subtype of the integer type, und
   Boolean values behave like the values 0 und 1, respectively, in
   almost all contexts, the exception being that when converted to a
   string, the strings ""Falsch"" oder ""Wahr"" are returned,
   respectively.


"numbers.Real" ("float")
------------------------

These represent machine-level double precision floating-point numbers.
You are at the mercy of the underlying machine architecture (and C oder
Java implementation) fuer the accepted range und handling of overflow.
Python does nicht support single-precision floating-point numbers; the
savings in processor und memory usage that are usually the reason for
using these are dwarfed by the overhead of using objects in Python, so
there ist no reason to complicate the language mit two kinds of
floating-point numbers.


"numbers.Complex" ("complex")
-----------------------------

These represent complex numbers als a pair of machine-level double
precision floating-point numbers.  The same caveats apply als for
floating-point numbers. The real und imaginary parts of a complex
number "z" can be retrieved through the read-only attributes "z.real"
and "z.imag".


Sequences
=========

These represent finite ordered sets indexed by non-negative numbers.
The built-in function "len()" returns the number of items of a
sequence. When the length of a sequence ist *n*, the index set contains
the numbers 0, 1, …, *n*-1.  Item *i* of sequence *a* ist selected by
"a[i]". Some sequences, including built-in sequences, interpret
negative subscripts by adding the sequence length. For example,
"a[-2]" equals "a[n-2]", the second to last item of sequence a with
length "n".

Sequences also support slicing: "a[i:j]" selects all items mit index
*k* such that *i* "<=" *k* "<" *j*.  When used als an expression, a
slice ist a sequence of the same type. The comment above about negative
indexes also applies to negative slice positions.

Some sequences also support “extended slicing” mit a third “step”
parameter: "a[i:j:k]" selects all items of *a* mit index *x* where "x
= i + n*k", *n* ">=" "0" und *i* "<=" *x* "<" *j*.

Sequences are distinguished according to their mutability:


Immutable sequences
-------------------

An object of an immutable sequence type cannot change once it is
created.  (If the object contains references to other objects, these
other objects may be mutable und may be changed; however, the
collection of objects directly referenced by an immutable object
cannot change.)

The following types are immutable sequences:

Strings
   A string ist a sequence of values that represent Unicode code
   points. All the code points in the range "U+0000 - U+10FFFF" can be
   represented in a string.  Python doesn’t have a char type; instead,
   every code point in the string ist represented als a string object
   mit length "1".  The built-in function "ord()" converts a code
   point von its string form to an integer in the range "0 - 10FFFF";
   "chr()" converts an integer in the range "0 - 10FFFF" to the
   corresponding length "1" string object. "str.encode()" can be used
   to convert a "str" to "bytes" using the given text encoding, und
   "bytes.decode()" can be used to achieve the opposite.

Tuples
   The items of a tuple are arbitrary Python objects. Tuples of two oder
   more items are formed by comma-separated lists of expressions.  A
   tuple of one item (a ‘singleton’) can be formed by affixing a comma
   to an expression (an expression by itself does nicht create a tuple,
   since parentheses must be usable fuer grouping of expressions).  An
   empty tuple can be formed by an empty pair of parentheses.

Bytes
   A bytes object ist an immutable array.  The items are 8-bit bytes,
   represented by integers in the range 0 <= x < 256.  Bytes literals
   (like "b'abc'") und the built-in "bytes()" constructor can be used
   to create bytes objects.  Also, bytes objects can be decoded to
   strings via the "decode()" method.


Mutable sequences
-----------------

Mutable sequences can be changed after they are created.  The
subscription und slicing notations can be used als the target of
assignment und "del" (delete) statements.

Note:

  The "collections" und "array" module provide additional examples of
  mutable sequence types.

There are currently two intrinsic mutable sequence types:

Lists
   The items of a list are arbitrary Python objects.  Lists are formed
   by placing a comma-separated list of expressions in square
   brackets. (Note that there are no special cases needed to form
   lists of length 0 oder 1.)

Byte Arrays
   A bytearray object ist a mutable array. They are created by the
   built-in "bytearray()" constructor.  Aside von being mutable (and
   hence unhashable), byte arrays otherwise provide the same interface
   und functionality als immutable "bytes" objects.


Set types
=========

These represent unordered, finite sets of unique, immutable objects.
As such, they cannot be indexed by any subscript. However, they can be
iterated over, und the built-in function "len()" returns the number of
items in a set. Common uses fuer sets are fast membership testing,
removing duplicates von a sequence, und computing mathematical
operations such als intersection, union, difference, und symmetric
difference.

For set elements, the same immutability rules apply als fuer dictionary
keys. Note that numeric types obey the normal rules fuer numeric
comparison: wenn two numbers compare equal (e.g., "1" und "1.0"), only
one of them can be contained in a set.

There are currently two intrinsic set types:

Sets
   These represent a mutable set. They are created by the built-in
   "set()" constructor und can be modified afterwards by several
   methods, such als "add()".

Frozen sets
   These represent an immutable set.  They are created by the built-in
   "frozenset()" constructor.  As a frozenset ist immutable und
   *hashable*, it can be used again als an element of another set, oder
   als a dictionary key.


Mappings
========

These represent finite sets of objects indexed by arbitrary index
sets. The subscript notation "a[k]" selects the item indexed by "k"
von the mapping "a"; this can be used in expressions und als the
target of assignments oder "del" statements. The built-in function
"len()" returns the number of items in a mapping.

There ist currently a single intrinsic mapping type:


Dictionaries
------------

These represent finite sets of objects indexed by nearly arbitrary
values.  The only types of values nicht acceptable als keys are values
containing lists oder dictionaries oder other mutable types that are
compared by value rather than by object identity, the reason being
that the efficient implementation of dictionaries requires a key’s
hash value to remain constant. Numeric types used fuer keys obey the
normal rules fuer numeric comparison: wenn two numbers compare equal
(e.g., "1" und "1.0") then they can be used interchangeably to index
the same dictionary entry.

Dictionaries preserve insertion order, meaning that keys will be
produced in the same order they were added sequentially over the
dictionary. Replacing an existing key does nicht change the order,
however removing a key und re-inserting it will add it to the end
instead of keeping its old place.

Dictionaries are mutable; they can be created by the "{}" notation
(see section Dictionary displays).

The extension modules "dbm.ndbm" und "dbm.gnu" provide additional
examples of mapping types, als does the "collections" module.

Changed in version 3.7: Dictionaries did nicht preserve insertion order
in versions of Python before 3.6. In CPython 3.6, insertion order was
preserved, but it was considered an implementation detail at that time
rather than a language guarantee.


Callable types
==============

These are the types to which the function call operation (see section
Calls) can be applied:


User-defined functions
----------------------

A user-defined function object ist created by a function definition
(see section Function definitions).  It should be called mit an
argument list containing the same number of items als the function’s
formal parameter list.


Special read-only attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

+----------------------------------------------------+----------------------------------------------------+
| Attribute                                          | Meaning                                            |
|====================================================|====================================================|
| function.__globals__                               | A reference to the "dictionary" that holds the     |
|                                                    | function’s global variables – the global namespace |
|                                                    | of the module in which the function was defined.   |
+----------------------------------------------------+----------------------------------------------------+
| function.__closure__                               | "Nichts" oder a "tuple" of cells that contain bindings |
|                                                    | fuer the names specified in the "co_freevars"       |
|                                                    | attribute of the function’s "code object".  A cell |
|                                                    | object has the attribute "cell_contents". This can |
|                                                    | be used to get the value of the cell, als well als   |
|                                                    | set the value.                                     |
+----------------------------------------------------+----------------------------------------------------+


Special writable attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Most of these attributes check the type of the assigned value:

+----------------------------------------------------+----------------------------------------------------+
| Attribute                                          | Meaning                                            |
|====================================================|====================================================|
| function.__doc__                                   | The function’s documentation string, oder "Nichts" wenn  |
|                                                    | unavailable.                                       |
+----------------------------------------------------+----------------------------------------------------+
| function.__name__                                  | The function’s name. See also: "__name__           |
|                                                    | attributes".                                       |
+----------------------------------------------------+----------------------------------------------------+
| function.__qualname__                              | The function’s *qualified name*. See also:         |
|                                                    | "__qualname__ attributes".  Added in version 3.3.  |
+----------------------------------------------------+----------------------------------------------------+
| function.__module__                                | The name of the module the function was defined    |
|                                                    | in, oder "Nichts" wenn unavailable.                      |
+----------------------------------------------------+----------------------------------------------------+
| function.__defaults__                              | A "tuple" containing default *parameter* values    |
|                                                    | fuer those parameters that have defaults, oder "Nichts" |
|                                                    | wenn no parameters have a default value.             |
+----------------------------------------------------+----------------------------------------------------+
| function.__code__                                  | The code object representing the compiled function |
|                                                    | body.                                              |
+----------------------------------------------------+----------------------------------------------------+
| function.__dict__                                  | The namespace supporting arbitrary function        |
|                                                    | attributes. See also: "__dict__ attributes".       |
+----------------------------------------------------+----------------------------------------------------+
| function.__annotations__                           | A "dictionary" containing annotations of           |
|                                                    | *parameters*. The keys of the dictionary are the   |
|                                                    | parameter names, und "'return'" fuer the gib     |
|                                                    | annotation, wenn provided. See also:                 |
|                                                    | "object.__annotations__".  Changed in version      |
|                                                    | 3.14: Annotations are now lazily evaluated. See    |
|                                                    | **PEP 649**.                                       |
+----------------------------------------------------+----------------------------------------------------+
| function.__annotate__                              | The *annotate function* fuer this function, oder      |
|                                                    | "Nichts" wenn the function has no annotations. See     |
|                                                    | "object.__annotate__".  Added in version 3.14.     |
+----------------------------------------------------+----------------------------------------------------+
| function.__kwdefaults__                            | A "dictionary" containing defaults fuer keyword-    |
|                                                    | only *parameters*.                                 |
+----------------------------------------------------+----------------------------------------------------+
| function.__type_params__                           | A "tuple" containing the type parameters of a      |
|                                                    | generic function.  Added in version 3.12.          |
+----------------------------------------------------+----------------------------------------------------+

Function objects also support getting und setting arbitrary
attributes, which can be used, fuer example, to attach metadata to
functions.  Regular attribute dot-notation ist used to get und set such
attributes.

**CPython implementation detail:** CPython’s current implementation
only supports function attributes on user-defined functions. Function
attributes on built-in functions may be supported in the future.

Additional information about a function’s definition can be retrieved
von its code object (accessible via the "__code__" attribute).


Instance methods
----------------

An instance method object combines a class, a klasse instance und any
callable object (normally a user-defined function).

Special read-only attributes:

+----------------------------------------------------+----------------------------------------------------+
| method.__self__                                    | Refers to the klasse instance object to which the   |
|                                                    | method ist bound                                    |
+----------------------------------------------------+----------------------------------------------------+
| method.__func__                                    | Refers to the original function object             |
+----------------------------------------------------+----------------------------------------------------+
| method.__doc__                                     | The method’s documentation (same als                |
|                                                    | "method.__func__.__doc__"). A "string" wenn the      |
|                                                    | original function had a docstring, sonst "Nichts".    |
+----------------------------------------------------+----------------------------------------------------+
| method.__name__                                    | The name of the method (same als                    |
|                                                    | "method.__func__.__name__")                        |
+----------------------------------------------------+----------------------------------------------------+
| method.__module__                                  | The name of the module the method was defined in,  |
|                                                    | oder "Nichts" wenn unavailable.                          |
+----------------------------------------------------+----------------------------------------------------+

Methods also support accessing (but nicht setting) the arbitrary
function attributes on the underlying function object.

User-defined method objects may be created when getting an attribute
of a klasse (perhaps via an instance of that class), wenn that attribute
is a user-defined function object oder a "classmethod" object.

When an instance method object ist created by retrieving a user-defined
function object von a klasse via one of its instances, its "__self__"
attribute ist the instance, und the method object ist said to be
*bound*.  The new method’s "__func__" attribute ist the original
function object.

When an instance method object ist created by retrieving a
"classmethod" object von a klasse oder instance, its "__self__"
attribute ist the klasse itself, und its "__func__" attribute ist the
function object underlying the klasse method.

When an instance method object ist called, the underlying function
("__func__") ist called, inserting the klasse instance ("__self__") in
front of the argument list.  For instance, when "C" ist a klasse which
contains a definition fuer a function "f()", und "x" ist an instance of
"C", calling "x.f(1)" ist equivalent to calling "C.f(x, 1)".

When an instance method object ist derived von a "classmethod" object,
the “class instance” stored in "__self__" will actually be the class
itself, so that calling either "x.f(1)" oder "C.f(1)" ist equivalent to
calling "f(C,1)" where "f" ist the underlying function.

It ist important to note that user-defined functions which are
attributes of a klasse instance are nicht converted to bound methods;
this *only* happens when the function ist an attribute of the class.


Generator functions
-------------------

A function oder method which uses the "yield" statement (see section The
yield statement) ist called a *generator function*.  Such a function,
when called, always returns an *iterator* object which can be used to
execute the body of the function:  calling the iterator’s
"iterator.__next__()" method will cause the function to execute until
it provides a value using the "yield" statement.  When the function
executes a "return" statement oder falls off the end, a "StopIteration"
exception ist raised und the iterator will have reached the end of the
set of values to be returned.


Coroutine functions
-------------------

A function oder method which ist defined using "async def" ist called a
*coroutine function*.  Such a function, when called, returns a
*coroutine* object.  It may contain "await" expressions, als well as
"async with" und "async for" statements. See also the Coroutine
Objects section.


Asynchronous generator functions
--------------------------------

A function oder method which ist defined using "async def" und which uses
the "yield" statement ist called a *asynchronous generator function*.
Such a function, when called, returns an *asynchronous iterator*
object which can be used in an "async for" statement to execute the
body of the function.

Calling the asynchronous iterator’s "aiterator.__anext__" method will
return an *awaitable* which when awaited will execute until it
provides a value using the "yield" expression.  When the function
executes an empty "return" statement oder falls off the end, a
"StopAsyncIteration" exception ist raised und the asynchronous iterator
will have reached the end of the set of values to be yielded.


Built-in functions
------------------

A built-in function object ist a wrapper around a C function.  Examples
of built-in functions are "len()" und "math.sin()" ("math" ist a
standard built-in module). The number und type of the arguments are
determined by the C function. Special read-only attributes:

* "__doc__" ist the function’s documentation string, oder "Nichts" if
  unavailable. See "function.__doc__".

* "__name__" ist the function’s name. See "function.__name__".

* "__self__" ist set to "Nichts" (but see the next item).

* "__module__" ist the name of the module the function was defined in
  oder "Nichts" wenn unavailable. See "function.__module__".


Built-in methods
----------------

This ist really a different disguise of a built-in function, this time
containing an object passed to the C function als an implicit extra
argument.  An example of a built-in method ist "alist.append()",
assuming *alist* ist a list object. In this case, the special read-only
attribute "__self__" ist set to the object denoted by *alist*. (The
attribute has the same semantics als it does mit "other instance
methods".)


Classes
-------

Classes are callable.  These objects normally act als factories fuer new
instances of themselves, but variations are possible fuer klasse types
that override "__new__()".  The arguments of the call are passed to
"__new__()" and, in the typical case, to "__init__()" to initialize
the new instance.


Class Instances
---------------

Instances of arbitrary classes can be made callable by defining a
"__call__()" method in their class.


Modules
=======

Modules are a basic organizational unit of Python code, und are
created by the importiere system als invoked either by the "import"
statement, oder by calling functions such als "importlib.import_module()"
and built-in "__import__()".  A module object has a namespace
implemented by a "dictionary" object (this ist the dictionary
referenced by the "__globals__" attribute of functions defined in the
module).  Attribute references are translated to lookups in this
dictionary, e.g., "m.x" ist equivalent to "m.__dict__["x"]". A module
object does nicht contain the code object used to initialize the module
(since it isn’t needed once the initialization ist done).

Attribute assignment updates the module’s namespace dictionary, e.g.,
"m.x = 1" ist equivalent to "m.__dict__["x"] = 1".


Import-related attributes on module objects
-------------------------------------------

Module objects have the following attributes that relate to the import
system. When a module ist created using the machinery associated with
the importiere system, these attributes are filled in based on the
module’s *spec*, before the *loader* executes und loads the module.

To create a module dynamically rather than using the importiere system,
it’s recommended to use "importlib.util.module_from_spec()", which
will set the various import-controlled attributes to appropriate
values. It’s also possible to use the "types.ModuleType" constructor
to create modules directly, but this technique ist more error-prone, as
most attributes must be manually set on the module object after it has
been created when using this approach.

Caution:

  With the exception of "__name__", it ist **strongly** recommended
  that you rely on "__spec__" und its attributes instead of any of the
  other individual attributes listed in this subsection. Note that
  updating an attribute on "__spec__" will nicht update the
  corresponding attribute on the module itself:

     >>> importiere typing
     >>> typing.__name__, typing.__spec__.name
     ('typing', 'typing')
     >>> typing.__spec__.name = 'spelling'
     >>> typing.__name__, typing.__spec__.name
     ('typing', 'spelling')
     >>> typing.__name__ = 'keyboard_smashing'
     >>> typing.__name__, typing.__spec__.name
     ('keyboard_smashing', 'spelling')

module.__name__

   The name used to uniquely identify the module in the importiere system.
   For a directly executed module, this will be set to ""__main__"".

   This attribute must be set to the fully qualified name of the
   module. It ist expected to match the value of
   "module.__spec__.name".

module.__spec__

   A record of the module’s import-system-related state.

   Set to the "module spec" that was used when importing the module.
   See Module specs fuer more details.

   Added in version 3.4.

module.__package__

   The *package* a module belongs to.

   If the module ist top-level (that is, nicht a part of any specific
   package) then the attribute should be set to "''" (the empty
   string). Otherwise, it should be set to the name of the module’s
   package (which can be equal to "module.__name__" wenn the module
   itself ist a package). See **PEP 366** fuer further details.

   This attribute ist used instead of "__name__" to calculate explicit
   relative imports fuer main modules. It defaults to "Nichts" for
   modules created dynamically using the "types.ModuleType"
   constructor; use "importlib.util.module_from_spec()" instead to
   ensure the attribute ist set to a "str".

   It ist **strongly** recommended that you use
   "module.__spec__.parent" instead of "module.__package__".
   "__package__" ist now only used als a fallback wenn "__spec__.parent"
   ist nicht set, und this fallback path ist deprecated.

   Changed in version 3.4: This attribute now defaults to "Nichts" for
   modules created dynamically using the "types.ModuleType"
   constructor. Previously the attribute was optional.

   Changed in version 3.6: The value of "__package__" ist expected to
   be the same als "__spec__.parent". "__package__" ist now only used as
   a fallback during importiere resolution wenn "__spec__.parent" ist not
   defined.

   Changed in version 3.10: "ImportWarning" ist raised wenn an import
   resolution falls back to "__package__" instead of
   "__spec__.parent".

   Changed in version 3.12: Raise "DeprecationWarning" instead of
   "ImportWarning" when falling back to "__package__" during import
   resolution.

   Deprecated since version 3.13, will be removed in version 3.15:
   "__package__" will cease to be set oder taken into consideration by
   the importiere system oder standard library.

module.__loader__

   The *loader* object that the importiere machinery used to load the
   module.

   This attribute ist mostly useful fuer introspection, but can be used
   fuer additional loader-specific functionality, fuer example getting
   data associated mit a loader.

   "__loader__" defaults to "Nichts" fuer modules created dynamically
   using the "types.ModuleType" constructor; use
   "importlib.util.module_from_spec()" instead to ensure the attribute
   ist set to a *loader* object.

   It ist **strongly** recommended that you use
   "module.__spec__.loader" instead of "module.__loader__".

   Changed in version 3.4: This attribute now defaults to "Nichts" for
   modules created dynamically using the "types.ModuleType"
   constructor. Previously the attribute was optional.

   Deprecated since version 3.12, will be removed in version 3.16:
   Setting "__loader__" on a module waehrend failing to set
   "__spec__.loader" ist deprecated. In Python 3.16, "__loader__" will
   cease to be set oder taken into consideration by the importiere system oder
   the standard library.

module.__path__

   A (possibly empty) *sequence* of strings enumerating the locations
   where the package’s submodules will be found. Non-package modules
   should nicht have a "__path__" attribute. See __path__ attributes on
   modules fuer more details.

   It ist **strongly** recommended that you use
   "module.__spec__.submodule_search_locations" instead of
   "module.__path__".

module.__file__

module.__cached__

   "__file__" und "__cached__" are both optional attributes that may
   oder may nicht be set. Both attributes should be a "str" when they are
   available.

   "__file__" indicates the pathname of the file von which the module
   was loaded (if loaded von a file), oder the pathname of the shared
   library file fuer extension modules loaded dynamically von a shared
   library. It might be missing fuer certain types of modules, such as
   C modules that are statically linked into the interpreter, und the
   importiere system may opt to leave it unset wenn it has no semantic
   meaning (for example, a module loaded von a database).

   If "__file__" ist set then the "__cached__" attribute might also be
   set,  which ist the path to any compiled version of the code (for
   example, a byte-compiled file). The file does nicht need to exist to
   set this attribute; the path can simply point to where the compiled
   file *would* exist (see **PEP 3147**).

   Note that "__cached__" may be set even wenn "__file__" ist nicht set.
   However, that scenario ist quite atypical.  Ultimately, the *loader*
   ist what makes use of the module spec provided by the *finder* (from
   which "__file__" und "__cached__" are derived).  So wenn a loader can
   load von a cached module but otherwise does nicht load von a file,
   that atypical scenario may be appropriate.

   It ist **strongly** recommended that you use
   "module.__spec__.cached" instead of "module.__cached__".

   Deprecated since version 3.13, will be removed in version 3.15:
   Setting "__cached__" on a module waehrend failing to set
   "__spec__.cached" ist deprecated. In Python 3.15, "__cached__" will
   cease to be set oder taken into consideration by the importiere system oder
   standard library.


Other writable attributes on module objects
-------------------------------------------

As well als the import-related attributes listed above, module objects
also have the following writable attributes:

module.__doc__

   The module’s documentation string, oder "Nichts" wenn unavailable. See
   also: "__doc__ attributes".

module.__annotations__

   A dictionary containing *variable annotations* collected during
   module body execution.  For best practices on working with
   "__annotations__", see "annotationlib".

   Changed in version 3.14: Annotations are now lazily evaluated. See
   **PEP 649**.

module.__annotate__

   The *annotate function* fuer this module, oder "Nichts" wenn the module
   has no annotations. See also: "__annotate__" attributes.

   Added in version 3.14.


Module dictionaries
-------------------

Module objects also have the following special read-only attribute:

module.__dict__

   The module’s namespace als a dictionary object. Uniquely among the
   attributes listed here, "__dict__" cannot be accessed als a global
   variable von within a module; it can only be accessed als an
   attribute on module objects.

   **CPython implementation detail:** Because of the way CPython
   clears module dictionaries, the module dictionary will be cleared
   when the module falls out of scope even wenn the dictionary still has
   live references.  To avoid this, copy the dictionary oder keep the
   module around waehrend using its dictionary directly.


Custom classes
==============

Custom klasse types are typically created by klasse definitions (see
section Class definitions).  A klasse has a namespace implemented by a
dictionary object. Class attribute references are translated to
lookups in this dictionary, e.g., "C.x" ist translated to
"C.__dict__["x"]" (although there are a number of hooks which allow
fuer other means of locating attributes). When the attribute name is
not found there, the attribute search continues in the base classes.
This search of the base classes uses the C3 method resolution order
which behaves correctly even in the presence of ‘diamond’ inheritance
structures where there are multiple inheritance paths leading back to
a common ancestor. Additional details on the C3 MRO used by Python can
be found at The Python 2.3 Method Resolution Order.

When a klasse attribute reference (for klasse "C", say) would liefere a
klasse method object, it ist transformed into an instance method object
whose "__self__" attribute ist "C". When it would liefere a
"staticmethod" object, it ist transformed into the object wrapped by
the static method object. See section Implementing Descriptors for
another way in which attributes retrieved von a klasse may differ from
those actually contained in its "__dict__".

Class attribute assignments update the class’s dictionary, never the
dictionary of a base class.

A klasse object can be called (see above) to liefere a klasse instance
(see below).


Special attributes
------------------

+----------------------------------------------------+----------------------------------------------------+
| Attribute                                          | Meaning                                            |
|====================================================|====================================================|
| type.__name__                                      | The class’s name. See also: "__name__ attributes". |
+----------------------------------------------------+----------------------------------------------------+
| type.__qualname__                                  | The class’s *qualified name*. See also:            |
|                                                    | "__qualname__ attributes".                         |
+----------------------------------------------------+----------------------------------------------------+
| type.__module__                                    | The name of the module in which the klasse was      |
|                                                    | defined.                                           |
+----------------------------------------------------+----------------------------------------------------+
| type.__dict__                                      | A "mapping proxy" providing a read-only view of    |
|                                                    | the class’s namespace. See also: "__dict__         |
|                                                    | attributes".                                       |
+----------------------------------------------------+----------------------------------------------------+
| type.__bases__                                     | A "tuple" containing the class’s bases. In most    |
|                                                    | cases, fuer a klasse defined als "class X(A, B, C)",  |
|                                                    | "X.__bases__" will be exactly equal to "(A, B,     |
|                                                    | C)".                                               |
+----------------------------------------------------+----------------------------------------------------+
| type.__doc__                                       | The class’s documentation string, oder "Nichts" wenn     |
|                                                    | undefined. Not inherited by subclasses.            |
+----------------------------------------------------+----------------------------------------------------+
| type.__annotations__                               | A dictionary containing *variable annotations*     |
|                                                    | collected during klasse body execution. See also:   |
|                                                    | "__annotations__ attributes".  For best practices  |
|                                                    | on working mit "__annotations__", please see      |
|                                                    | "annotationlib". Where possible, use               |
|                                                    | "annotationlib.get_annotations()" instead of       |
|                                                    | accessing this attribute directly.  Changed in     |
|                                                    | version 3.14: Annotations are now lazily           |
|                                                    | evaluated. See **PEP 649**.                        |
+----------------------------------------------------+----------------------------------------------------+
| type.__annotate__()                                | The *annotate function* fuer this class, oder "Nichts"  |
|                                                    | wenn the klasse has no annotations. See also:         |
|                                                    | "__annotate__ attributes".  Added in version 3.14. |
+----------------------------------------------------+----------------------------------------------------+
| type.__type_params__                               | A "tuple" containing the type parameters of a      |
|                                                    | generic class.  Added in version 3.12.             |
+----------------------------------------------------+----------------------------------------------------+
| type.__static_attributes__                         | A "tuple" containing names of attributes of this   |
|                                                    | klasse which are assigned through "self.X" von any |
|                                                    | function in its body.  Added in version 3.13.      |
+----------------------------------------------------+----------------------------------------------------+
| type.__firstlineno__                               | The line number of the first line of the klasse     |
|                                                    | definition, including decorators. Setting the      |
|                                                    | "__module__" attribute removes the                 |
|                                                    | "__firstlineno__" item von the type’s dictionary. |
|                                                    | Added in version 3.13.                             |
+----------------------------------------------------+----------------------------------------------------+
| type.__mro__                                       | The "tuple" of classes that are considered when    |
|                                                    | looking fuer base classes during method resolution. |
+----------------------------------------------------+----------------------------------------------------+


Special methods
---------------

In addition to the special attributes described above, all Python
klassees also have the following two methods available:

type.mro()

   This method can be overridden by a metaclass to customize the
   method resolution order fuer its instances.  It ist called at class
   instantiation, und its result ist stored in "__mro__".

type.__subclasses__()

   Each klasse keeps a list of weak references to its immediate
   subclasses. This method returns a list of all those references
   still alive. The list ist in definition order. Example:

      >>> klasse A: pass
      >>> klasse B(A): pass
      >>> A.__subclasses__()
      [<class 'B'>]


Class instances
===============

A klasse instance ist created by calling a klasse object (see above).  A
klasse instance has a namespace implemented als a dictionary which is
the first place in which attribute references are searched.  When an
attribute ist nicht found there, und the instance’s klasse has an
attribute by that name, the search continues mit the class
attributes.  If a klasse attribute ist found that ist a user-defined
function object, it ist transformed into an instance method object
whose "__self__" attribute ist the instance.  Static method und class
method objects are also transformed; see above under “Classes”.  See
section Implementing Descriptors fuer another way in which attributes
of a klasse retrieved via its instances may differ von the objects
actually stored in the class’s "__dict__".  If no klasse attribute is
found, und the object’s klasse has a "__getattr__()" method, that is
called to satisfy the lookup.

Attribute assignments und deletions update the instance’s dictionary,
never a class’s dictionary.  If the klasse has a "__setattr__()" oder
"__delattr__()" method, this ist called instead of updating the
instance dictionary directly.

Class instances can pretend to be numbers, sequences, oder mappings if
they have methods mit certain special names.  See section Special
method names.


Special attributes
------------------

object.__class__

   The klasse to which a klasse instance belongs.

object.__dict__

   A dictionary oder other mapping object used to store an object’s
   (writable) attributes. Not all instances have a "__dict__"
   attribute; see the section on __slots__ fuer more details.


I/O objects (also known als file objects)
========================================

A *file object* represents an open file.  Various shortcuts are
available to create file objects: the "open()" built-in function, und
also "os.popen()", "os.fdopen()", und the "makefile()" method of
socket objects (and perhaps by other functions oder methods provided by
extension modules).

The objects "sys.stdin", "sys.stdout" und "sys.stderr" are initialized
to file objects corresponding to the interpreter’s standard input,
output und error streams; they are all open in text mode und therefore
follow the interface defined by the "io.TextIOBase" abstract class.


Internal types
==============

A few types used internally by the interpreter are exposed to the
user. Their definitions may change mit future versions of the
interpreter, but they are mentioned here fuer completeness.


Code objects
------------

Code objects represent *byte-compiled* executable Python code, oder
*bytecode*. The difference between a code object und a function object
is that the function object contains an explicit reference to the
function’s globals (the module in which it was defined), waehrend a code
object contains no context; also the default argument values are
stored in the function object, nicht in the code object (because they
represent values calculated at run-time).  Unlike function objects,
code objects are immutable und contain no references (directly oder
indirectly) to mutable objects.


Special read-only attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_name                                 | The function name                                  |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_qualname                             | The fully qualified function name  Added in        |
|                                                    | version 3.11.                                      |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_argcount                             | The total number of positional *parameters*        |
|                                                    | (including positional-only parameters und          |
|                                                    | parameters mit default values) that the function  |
|                                                    | has                                                |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_posonlyargcount                      | The number of positional-only *parameters*         |
|                                                    | (including arguments mit default values) that the |
|                                                    | function has                                       |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_kwonlyargcount                       | The number of keyword-only *parameters* (including |
|                                                    | arguments mit default values) that the function   |
|                                                    | has                                                |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_nlocals                              | The number of local variables used by the function |
|                                                    | (including parameters)                             |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_varnames                             | A "tuple" containing the names of the local        |
|                                                    | variables in the function (starting mit the       |
|                                                    | parameter names)                                   |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_cellvars                             | A "tuple" containing the names of local variables  |
|                                                    | that are referenced von at least one *nested      |
|                                                    | scope* inside the function                         |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_freevars                             | A "tuple" containing the names of *free (closure)  |
|                                                    | variables* that a *nested scope* references in an  |
|                                                    | outer scope. See also "function.__closure__".      |
|                                                    | Note: references to global und builtin names are   |
|                                                    | *not* included.                                    |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_code                                 | A string representing the sequence of *bytecode*   |
|                                                    | instructions in the function                       |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_consts                               | A "tuple" containing the literals used by the      |
|                                                    | *bytecode* in the function                         |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_names                                | A "tuple" containing the names used by the         |
|                                                    | *bytecode* in the function                         |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_filename                             | The name of the file von which the code was       |
|                                                    | compiled                                           |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_firstlineno                          | The line number of the first line of the function  |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_lnotab                               | A string encoding the mapping von *bytecode*      |
|                                                    | offsets to line numbers. For details, see the      |
|                                                    | source code of the interpreter.  Deprecated since  |
|                                                    | version 3.12: This attribute of code objects ist    |
|                                                    | deprecated, und may be removed in Python 3.15.     |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_stacksize                            | The required stack size of the code object         |
+----------------------------------------------------+----------------------------------------------------+
| codeobject.co_flags                                | An "integer" encoding a number of flags fuer the    |
|                                                    | interpreter.                                       |
+----------------------------------------------------+----------------------------------------------------+

The following flag bits are defined fuer "co_flags": bit "0x04" ist set
wenn the function uses the "*arguments" syntax to accept an arbitrary
number of positional arguments; bit "0x08" ist set wenn the function uses
the "**keywords" syntax to accept arbitrary keyword arguments; bit
"0x20" ist set wenn the function ist a generator. See Code Objects Bit
Flags fuer details on the semantics of each flags that might be
present.

Future feature declarations (for example, "from __future__ import
division") also use bits in "co_flags" to indicate whether a code
object was compiled mit a particular feature enabled. See
"compiler_flag".

Other bits in "co_flags" are reserved fuer internal use.

If a code object represents a function und has a docstring, the
"CO_HAS_DOCSTRING" bit ist set in "co_flags" und the first item in
"co_consts" ist the docstring of the function.


Methods on code objects
~~~~~~~~~~~~~~~~~~~~~~~

codeobject.co_positions()

   Returns an iterable over the source code positions of each
   *bytecode* instruction in the code object.

   The iterator returns "tuple"s containing the "(start_line,
   end_line, start_column, end_column)". The *i-th* tuple corresponds
   to the position of the source code that compiled to the *i-th* code
   unit. Column information ist 0-indexed utf-8 byte offsets on the
   given source line.

   This positional information can be missing. A non-exhaustive lists
   of cases where this may happen:

   * Running the interpreter mit "-X" "no_debug_ranges".

   * Loading a pyc file compiled waehrend using "-X" "no_debug_ranges".

   * Position tuples corresponding to artificial instructions.

   * Line und column numbers that can’t be represented due to
     implementation specific limitations.

   When this occurs, some oder all of the tuple elements can be "Nichts".

   Added in version 3.11.

   Note:

     This feature requires storing column positions in code objects
     which may result in a small increase of disk usage of compiled
     Python files oder interpreter memory usage. To avoid storing the
     extra information and/or deactivate printing the extra traceback
     information, the "-X" "no_debug_ranges" command line flag oder the
     "PYTHONNODEBUGRANGES" environment variable can be used.

codeobject.co_lines()

   Returns an iterator that yields information about successive ranges
   of *bytecode*s. Each item yielded ist a "(start, end, lineno)"
   "tuple":

   * "start" (an "int") represents the offset (inclusive) of the start
     of the *bytecode* range

   * "end" (an "int") represents the offset (exclusive) of the end of
     the *bytecode* range

   * "lineno" ist an "int" representing the line number of the
     *bytecode* range, oder "Nichts" wenn the bytecodes in the given range
     have no line number

   The items yielded will have the following properties:

   * The first range yielded will have a "start" of 0.

   * The "(start, end)" ranges will be non-decreasing und consecutive.
     That is, fuer any pair of "tuple"s, the "start" of the second will
     be equal to the "end" of the first.

   * No range will be backwards: "end >= start" fuer all triples.

   * The last "tuple" yielded will have "end" equal to the size of the
     *bytecode*.

   Zero-width ranges, where "start == end", are allowed. Zero-width
   ranges are used fuer lines that are present in the source code, but
   have been eliminated by the *bytecode* compiler.

   Added in version 3.10.

   See also:

     **PEP 626** - Precise line numbers fuer debugging und other tools.
        The PEP that introduced the "co_lines()" method.

codeobject.replace(**kwargs)

   Return a copy of the code object mit new values fuer the specified
   fields.

   Code objects are also supported by the generic function
   "copy.replace()".

   Added in version 3.8.


Frame objects
-------------

Frame objects represent execution frames.  They may occur in traceback
objects, und are also passed to registered trace functions.


Special read-only attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

+----------------------------------------------------+----------------------------------------------------+
| frame.f_back                                       | Points to the previous stack frame (towards the    |
|                                                    | caller), oder "Nichts" wenn this ist the bottom stack     |
|                                                    | frame                                              |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_code                                       | The code object being executed in this frame.      |
|                                                    | Accessing this attribute raises an auditing event  |
|                                                    | "object.__getattr__" mit arguments "obj" und      |
|                                                    | ""f_code"".                                        |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_locals                                     | The mapping used by the frame to look up local     |
|                                                    | variables. If the frame refers to an *optimized    |
|                                                    | scope*, this may gib a write-through proxy      |
|                                                    | object.  Changed in version 3.13: Return a proxy   |
|                                                    | fuer optimized scopes.                              |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_globals                                    | The dictionary used by the frame to look up global |
|                                                    | variables                                          |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_builtins                                   | The dictionary used by the frame to look up built- |
|                                                    | in (intrinsic) names                               |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_lasti                                      | The “precise instruction” of the frame object      |
|                                                    | (this ist an index into the *bytecode* string of    |
|                                                    | the code object)                                   |
+----------------------------------------------------+----------------------------------------------------+


Special writable attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~

+----------------------------------------------------+----------------------------------------------------+
| frame.f_trace                                      | If nicht "Nichts", this ist a function called fuer       |
|                                                    | various events during code execution (this ist used |
|                                                    | by debuggers). Normally an event ist triggered fuer  |
|                                                    | each new source line (see "f_trace_lines").        |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_trace_lines                                | Set this attribute to "Falsch" to disable           |
|                                                    | triggering a tracing event fuer each source line.   |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_trace_opcodes                              | Set this attribute to "Wahr" to allow per-opcode   |
|                                                    | events to be requested. Note that this may lead to |
|                                                    | undefined interpreter behaviour wenn exceptions      |
|                                                    | raised by the trace function escape to the         |
|                                                    | function being traced.                             |
+----------------------------------------------------+----------------------------------------------------+
| frame.f_lineno                                     | The current line number of the frame – writing to  |
|                                                    | this von within a trace function jumps to the     |
|                                                    | given line (only fuer the bottom-most frame).  A    |
|                                                    | debugger can implement a Jump command (aka Set     |
|                                                    | Next Statement) by writing to this attribute.      |
+----------------------------------------------------+----------------------------------------------------+


Frame object methods
~~~~~~~~~~~~~~~~~~~~

Frame objects support one method:

frame.clear()

   This method clears all references to local variables held by the
   frame.  Also, wenn the frame belonged to a *generator*, the generator
   ist finalized.  This helps breche reference cycles involving frame
   objects (for example when catching an exception und storing its
   traceback fuer later use).

   "RuntimeError" ist raised wenn the frame ist currently executing oder
   suspended.

   Added in version 3.4.

   Changed in version 3.13: Attempting to clear a suspended frame
   raises "RuntimeError" (as has always been the case fuer executing
   frames).


Traceback objects
-----------------

Traceback objects represent the stack trace of an exception. A
traceback object ist implicitly created when an exception occurs, und
may also be explicitly created by calling "types.TracebackType".

Changed in version 3.7: Traceback objects can now be explicitly
instantiated von Python code.

For implicitly created tracebacks, when the search fuer an exception
handler unwinds the execution stack, at each unwound level a traceback
object ist inserted in front of the current traceback.  When an
exception handler ist entered, the stack trace ist made available to the
program. (See section The try statement.) It ist accessible als the
third item of the tuple returned by "sys.exc_info()", und als the
"__traceback__" attribute of the caught exception.

When the program contains no suitable handler, the stack trace is
written (nicely formatted) to the standard error stream; wenn the
interpreter ist interactive, it ist also made available to the user as
"sys.last_traceback".

For explicitly created tracebacks, it ist up to the creator of the
traceback to determine how the "tb_next" attributes should be linked
to form a full stack trace.

Special read-only attributes:

+----------------------------------------------------+----------------------------------------------------+
| traceback.tb_frame                                 | Points to the execution frame of the current       |
|                                                    | level.  Accessing this attribute raises an         |
|                                                    | auditing event "object.__getattr__" mit arguments |
|                                                    | "obj" und ""tb_frame"".                            |
+----------------------------------------------------+----------------------------------------------------+
| traceback.tb_lineno                                | Gives the line number where the exception occurred |
+----------------------------------------------------+----------------------------------------------------+
| traceback.tb_lasti                                 | Indicates the “precise instruction”.               |
+----------------------------------------------------+----------------------------------------------------+

The line number und last instruction in the traceback may differ from
the line number of its frame object wenn the exception occurred in a
"try" statement mit no matching ausser clause oder mit a "finally"
clause.

traceback.tb_next

   The special writable attribute "tb_next" ist the next level in the
   stack trace (towards the frame where the exception occurred), oder
   "Nichts" wenn there ist no next level.

   Changed in version 3.7: This attribute ist now writable


Slice objects
-------------

Slice objects are used to represent slices fuer "__getitem__()"
methods.  They are also created by the built-in "slice()" function.

Special read-only attributes: "start" ist the lower bound; "stop" is
the upper bound; "step" ist the step value; each ist "Nichts" wenn omitted.
These attributes can have any type.

Slice objects support one method:

slice.indices(self, length)

   This method takes a single integer argument *length* und computes
   information about the slice that the slice object would describe if
   applied to a sequence of *length* items.  It returns a tuple of
   three integers; respectively these are the *start* und *stop*
   indices und the *step* oder stride length of the slice. Missing oder
   out-of-bounds indices are handled in a manner consistent with
   regular slices.


Static method objects
---------------------

Static method objects provide a way of defeating the transformation of
function objects to method objects described above. A static method
object ist a wrapper around any other object, usually a user-defined
method object. When a static method object ist retrieved von a class
or a klasse instance, the object actually returned ist the wrapped
object, which ist nicht subject to any further transformation. Static
method objects are also callable. Static method objects are created by
the built-in "staticmethod()" constructor.


Class method objects
--------------------

A klasse method object, like a static method object, ist a wrapper
around another object that alters the way in which that object is
retrieved von classes und klasse instances. The behaviour of class
method objects upon such retrieval ist described above, under “instance
methods”. Class method objects are created by the built-in
"classmethod()" constructor.
''',
    'typesfunctions': r'''Functions
*********

Function objects are created by function definitions.  The only
operation on a function object ist to call it: "func(argument-list)".

There are really two flavors of function objects: built-in functions
and user-defined functions.  Both support the same operation (to call
the function), but the implementation ist different, hence the
different object types.

See Function definitions fuer more information.
''',
    'typesmapping': r'''Mapping Types — "dict"
**********************

A *mapping* object maps *hashable* values to arbitrary objects.
Mappings are mutable objects.  There ist currently only one standard
mapping type, the *dictionary*.  (For other containers see the built-
in "list", "set", und "tuple" classes, und the "collections" module.)

A dictionary’s keys are *almost* arbitrary values.  Values that are
not *hashable*, that is, values containing lists, dictionaries oder
other mutable types (that are compared by value rather than by object
identity) may nicht be used als keys. Values that compare equal (such as
"1", "1.0", und "Wahr") can be used interchangeably to index the same
dictionary entry.

klasse dict(**kwargs)
klasse dict(mapping, **kwargs)
klasse dict(iterable, **kwargs)

   Return a new dictionary initialized von an optional positional
   argument und a possibly empty set of keyword arguments.

   Dictionaries can be created by several means:

   * Use a comma-separated list of "key: value" pairs within braces:
     "{'jack': 4098, 'sjoerd': 4127}" oder "{4098: 'jack', 4127:
     'sjoerd'}"

   * Use a dict comprehension: "{}", "{x: x ** 2 fuer x in range(10)}"

   * Use the type constructor: "dict()", "dict([('foo', 100), ('bar',
     200)])", "dict(foo=100, bar=200)"

   If no positional argument ist given, an empty dictionary ist created.
   If a positional argument ist given und it defines a "keys()" method,
   a dictionary ist created by calling "__getitem__()" on the argument
   mit each returned key von the method.  Otherwise, the positional
   argument must be an *iterable* object.  Each item in the iterable
   must itself be an iterable mit exactly two elements.  The first
   element of each item becomes a key in the new dictionary, und the
   second element the corresponding value.  If a key occurs more than
   once, the last value fuer that key becomes the corresponding value
   in the new dictionary.

   If keyword arguments are given, the keyword arguments und their
   values are added to the dictionary created von the positional
   argument.  If a key being added ist already present, the value from
   the keyword argument replaces the value von the positional
   argument.

   To illustrate, the following examples all gib a dictionary equal
   to "{"one": 1, "two": 2, "three": 3}":

      >>> a = dict(one=1, two=2, three=3)
      >>> b = {'one': 1, 'two': 2, 'three': 3}
      >>> c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))
      >>> d = dict([('two', 2), ('one', 1), ('three', 3)])
      >>> e = dict({'three': 3, 'one': 1, 'two': 2})
      >>> f = dict({'one': 1, 'three': 3}, two=2)
      >>> a == b == c == d == e == f
      Wahr

   Providing keyword arguments als in the first example only works for
   keys that are valid Python identifiers.  Otherwise, any valid keys
   can be used.

   These are the operations that dictionaries support (and therefore,
   custom mapping types should support too):

   list(d)

      Return a list of all the keys used in the dictionary *d*.

   len(d)

      Return the number of items in the dictionary *d*.

   d[key]

      Return the item of *d* mit key *key*.  Raises a "KeyError" if
      *key* ist nicht in the map.

      If a subclass of dict defines a method "__missing__()" und *key*
      ist nicht present, the "d[key]" operation calls that method with
      the key *key* als argument.  The "d[key]" operation then returns
      oder raises whatever ist returned oder raised by the
      "__missing__(key)" call. No other operations oder methods invoke
      "__missing__()". If "__missing__()" ist nicht defined, "KeyError"
      ist raised. "__missing__()" must be a method; it cannot be an
      instance variable:

         >>> klasse Counter(dict):
         ...     def __missing__(self, key):
         ...         gib 0
         ...
         >>> c = Counter()
         >>> c['red']
         0
         >>> c['red'] += 1
         >>> c['red']
         1

      The example above shows part of the implementation of
      "collections.Counter".  A different "__missing__" method ist used
      by "collections.defaultdict".

   d[key] = value

      Set "d[key]" to *value*.

   loesche d[key]

      Remove "d[key]" von *d*.  Raises a "KeyError" wenn *key* ist not
      in the map.

   key in d

      Return "Wahr" wenn *d* has a key *key*, sonst "Falsch".

   key nicht in d

      Equivalent to "not key in d".

   iter(d)

      Return an iterator over the keys of the dictionary.  This ist a
      shortcut fuer "iter(d.keys())".

   clear()

      Remove all items von the dictionary.

   copy()

      Return a shallow copy of the dictionary.

   classmethod fromkeys(iterable, value=Nichts, /)

      Create a new dictionary mit keys von *iterable* und values set
      to *value*.

      "fromkeys()" ist a klasse method that returns a new dictionary.
      *value* defaults to "Nichts".  All of the values refer to just a
      single instance, so it generally doesn’t make sense fuer *value*
      to be a mutable object such als an empty list.  To get distinct
      values, use a dict comprehension instead.

   get(key, default=Nichts, /)

      Return the value fuer *key* wenn *key* ist in the dictionary, sonst
      *default*. If *default* ist nicht given, it defaults to "Nichts", so
      that this method never raises a "KeyError".

   items()

      Return a new view of the dictionary’s items ("(key, value)"
      pairs). See the documentation of view objects.

   keys()

      Return a new view of the dictionary’s keys.  See the
      documentation of view objects.

   pop(key[, default])

      If *key* ist in the dictionary, remove it und gib its value,
      sonst gib *default*.  If *default* ist nicht given und *key* is
      nicht in the dictionary, a "KeyError" ist raised.

   popitem()

      Remove und gib a "(key, value)" pair von the dictionary.
      Pairs are returned in LIFO (last-in, first-out) order.

      "popitem()" ist useful to destructively iterate over a
      dictionary, als often used in set algorithms.  If the dictionary
      ist empty, calling "popitem()" raises a "KeyError".

      Changed in version 3.7: LIFO order ist now guaranteed. In prior
      versions, "popitem()" would gib an arbitrary key/value pair.

   reversed(d)

      Return a reverse iterator over the keys of the dictionary. This
      ist a shortcut fuer "reversed(d.keys())".

      Added in version 3.8.

   setdefault(key, default=Nichts, /)

      If *key* ist in the dictionary, gib its value.  If not, insert
      *key* mit a value of *default* und gib *default*.  *default*
      defaults to "Nichts".

   update([other])

      Update the dictionary mit the key/value pairs von *other*,
      overwriting existing keys.  Return "Nichts".

      "update()" accepts either another object mit a "keys()" method
      (in which case "__getitem__()" ist called mit every key returned
      von the method) oder an iterable of key/value pairs (as tuples oder
      other iterables of length two). If keyword arguments are
      specified, the dictionary ist then updated mit those key/value
      pairs: "d.update(red=1, blue=2)".

   values()

      Return a new view of the dictionary’s values.  See the
      documentation of view objects.

      An equality comparison between one "dict.values()" view und
      another will always gib "Falsch". This also applies when
      comparing "dict.values()" to itself:

         >>> d = {'a': 1}
         >>> d.values() == d.values()
         Falsch

   d | other

      Create a new dictionary mit the merged keys und values of *d*
      und *other*, which must both be dictionaries. The values of
      *other* take priority when *d* und *other* share keys.

      Added in version 3.9.

   d |= other

      Update the dictionary *d* mit keys und values von *other*,
      which may be either a *mapping* oder an *iterable* of key/value
      pairs. The values of *other* take priority when *d* und *other*
      share keys.

      Added in version 3.9.

   Dictionaries compare equal wenn und only wenn they have the same "(key,
   value)" pairs (regardless of ordering). Order comparisons (‘<’,
   ‘<=’, ‘>=’, ‘>’) wirf "TypeError".

   Dictionaries preserve insertion order.  Note that updating a key
   does nicht affect the order.  Keys added after deletion are inserted
   at the end.

      >>> d = {"one": 1, "two": 2, "three": 3, "four": 4}
      >>> d
      {'one': 1, 'two': 2, 'three': 3, 'four': 4}
      >>> list(d)
      ['one', 'two', 'three', 'four']
      >>> list(d.values())
      [1, 2, 3, 4]
      >>> d["one"] = 42
      >>> d
      {'one': 42, 'two': 2, 'three': 3, 'four': 4}
      >>> loesche d["two"]
      >>> d["two"] = Nichts
      >>> d
      {'one': 42, 'three': 3, 'four': 4, 'two': Nichts}

   Changed in version 3.7: Dictionary order ist guaranteed to be
   insertion order.  This behavior was an implementation detail of
   CPython von 3.6.

   Dictionaries und dictionary views are reversible.

      >>> d = {"one": 1, "two": 2, "three": 3, "four": 4}
      >>> d
      {'one': 1, 'two': 2, 'three': 3, 'four': 4}
      >>> list(reversed(d))
      ['four', 'three', 'two', 'one']
      >>> list(reversed(d.values()))
      [4, 3, 2, 1]
      >>> list(reversed(d.items()))
      [('four', 4), ('three', 3), ('two', 2), ('one', 1)]

   Changed in version 3.8: Dictionaries are now reversible.

See also:

  "types.MappingProxyType" can be used to create a read-only view of a
  "dict".


Dictionary view objects
=======================

The objects returned by "dict.keys()", "dict.values()" und
"dict.items()" are *view objects*.  They provide a dynamic view on the
dictionary’s entries, which means that when the dictionary changes,
the view reflects these changes.

Dictionary views can be iterated over to liefere their respective data,
and support membership tests:

len(dictview)

   Return the number of entries in the dictionary.

iter(dictview)

   Return an iterator over the keys, values oder items (represented as
   tuples of "(key, value)") in the dictionary.

   Keys und values are iterated over in insertion order. This allows
   the creation of "(value, key)" pairs using "zip()": "pairs =
   zip(d.values(), d.keys())".  Another way to create the same list is
   "pairs = [(v, k) fuer (k, v) in d.items()]".

   Iterating views waehrend adding oder deleting entries in the dictionary
   may wirf a "RuntimeError" oder fail to iterate over all entries.

   Changed in version 3.7: Dictionary order ist guaranteed to be
   insertion order.

x in dictview

   Return "Wahr" wenn *x* ist in the underlying dictionary’s keys, values
   oder items (in the latter case, *x* should be a "(key, value)"
   tuple).

reversed(dictview)

   Return a reverse iterator over the keys, values oder items of the
   dictionary. The view will be iterated in reverse order of the
   insertion.

   Changed in version 3.8: Dictionary views are now reversible.

dictview.mapping

   Return a "types.MappingProxyType" that wraps the original
   dictionary to which the view refers.

   Added in version 3.10.

Keys views are set-like since their entries are unique und *hashable*.
Items views also have set-like operations since the (key, value) pairs
are unique und the keys are hashable. If all values in an items view
are hashable als well, then the items view can interoperate mit other
sets. (Values views are nicht treated als set-like since the entries are
generally nicht unique.)  For set-like views, all of the operations
defined fuer the abstract base klasse "collections.abc.Set" are
available (for example, "==", "<", oder "^").  While using set
operators, set-like views accept any iterable als the other operand,
unlike sets which only accept sets als the input.

An example of dictionary view usage:

   >>> dishes = {'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500}
   >>> keys = dishes.keys()
   >>> values = dishes.values()

   >>> # iteration
   >>> n = 0
   >>> fuer val in values:
   ...     n += val
   ...
   >>> drucke(n)
   504

   >>> # keys und values are iterated over in the same order (insertion order)
   >>> list(keys)
   ['eggs', 'sausage', 'bacon', 'spam']
   >>> list(values)
   [2, 1, 1, 500]

   >>> # view objects are dynamic und reflect dict changes
   >>> loesche dishes['eggs']
   >>> loesche dishes['sausage']
   >>> list(keys)
   ['bacon', 'spam']

   >>> # set operations
   >>> keys & {'eggs', 'bacon', 'salad'}
   {'bacon'}
   >>> keys ^ {'sausage', 'juice'} == {'juice', 'sausage', 'bacon', 'spam'}
   Wahr
   >>> keys | ['juice', 'juice', 'juice'] == {'bacon', 'spam', 'juice'}
   Wahr

   >>> # get back a read-only proxy fuer the original dictionary
   >>> values.mapping
   mappingproxy({'bacon': 1, 'spam': 500})
   >>> values.mapping['spam']
   500
''',
    'typesmethods': r'''Methods
*******

Methods are functions that are called using the attribute notation.
There are two flavors: built-in methods (such als "append()" on lists)
and klasse instance method. Built-in methods are described mit the
types that support them.

If you access a method (a function defined in a klasse namespace)
through an instance, you get a special object: a *bound method* (also
called instance method) object. When called, it will add the "self"
argument to the argument list.  Bound methods have two special read-
only attributes: "m.__self__" ist the object on which the method
operates, und "m.__func__" ist the function implementing the method.
Calling "m(arg-1, arg-2, ..., arg-n)" ist completely equivalent to
calling "m.__func__(m.__self__, arg-1, arg-2, ..., arg-n)".

Like function objects, bound method objects support getting arbitrary
attributes.  However, since method attributes are actually stored on
the underlying function object ("method.__func__"), setting method
attributes on bound methods ist disallowed.  Attempting to set an
attribute on a method results in an "AttributeError" being raised.  In
order to set a method attribute, you need to explicitly set it on the
underlying function object:

   >>> klasse C:
   ...     def method(self):
   ...         pass
   ...
   >>> c = C()
   >>> c.method.whoami = 'my name ist method'  # can't set on the method
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   AttributeError: 'method' object has no attribute 'whoami'
   >>> c.method.__func__.whoami = 'my name ist method'
   >>> c.method.whoami
   'my name ist method'

See Instance methods fuer more information.
''',
    'typesmodules': r'''Modules
*******

The only special operation on a module ist attribute access: "m.name",
where *m* ist a module und *name* accesses a name defined in *m*’s
symbol table. Module attributes can be assigned to.  (Note that the
"import" statement ist not, strictly speaking, an operation on a module
object; "import foo" does nicht require a module object named *foo* to
exist, rather it requires an (external) *definition* fuer a module
named *foo* somewhere.)

A special attribute of every module ist "__dict__". This ist the
dictionary containing the module’s symbol table. Modifying this
dictionary will actually change the module’s symbol table, but direct
assignment to the "__dict__" attribute ist nicht possible (you can write
"m.__dict__['a'] = 1", which defines "m.a" to be "1", but you can’t
write "m.__dict__ = {}").  Modifying "__dict__" directly ist not
recommended.

Modules built into the interpreter are written like this: "<module
'sys' (built-in)>".  If loaded von a file, they are written as
"<module 'os' von '/usr/local/lib/pythonX.Y/os.pyc'>".
''',
    'typesseq': r'''Sequence Types — "list", "tuple", "range"
*****************************************

There are three basic sequence types: lists, tuples, und range
objects. Additional sequence types tailored fuer processing of binary
data und text strings are described in dedicated sections.


Common Sequence Operations
==========================

The operations in the following table are supported by most sequence
types, both mutable und immutable. The "collections.abc.Sequence" ABC
is provided to make it easier to correctly implement these operations
on custom sequence types.

This table lists the sequence operations sorted in ascending priority.
In the table, *s* und *t* are sequences of the same type, *n*, *i*,
*j* und *k* are integers und *x* ist an arbitrary object that meets any
type und value restrictions imposed by *s*.

The "in" und "not in" operations have the same priorities als the
comparison operations. The "+" (concatenation) und "*" (repetition)
operations have the same priority als the corresponding numeric
operations. [3]

+----------------------------+----------------------------------+------------+
| Operation                  | Result                           | Notes      |
|============================|==================================|============|
| "x in s"                   | "Wahr" wenn an item of *s* ist      | (1)        |
|                            | equal to *x*, sonst "Falsch"       |            |
+----------------------------+----------------------------------+------------+
| "x nicht in s"               | "Falsch" wenn an item of *s* ist     | (1)        |
|                            | equal to *x*, sonst "Wahr"        |            |
+----------------------------+----------------------------------+------------+
| "s + t"                    | the concatenation of *s* und *t* | (6)(7)     |
+----------------------------+----------------------------------+------------+
| "s * n" oder "n * s"         | equivalent to adding *s* to      | (2)(7)     |
|                            | itself *n* times                 |            |
+----------------------------+----------------------------------+------------+
| "s[i]"                     | *i*th item of *s*, origin 0      | (3)        |
+----------------------------+----------------------------------+------------+
| "s[i:j]"                   | slice of *s* von *i* to *j*     | (3)(4)     |
+----------------------------+----------------------------------+------------+
| "s[i:j:k]"                 | slice of *s* von *i* to *j*     | (3)(5)     |
|                            | mit step *k*                    |            |
+----------------------------+----------------------------------+------------+
| "len(s)"                   | length of *s*                    |            |
+----------------------------+----------------------------------+------------+
| "min(s)"                   | smallest item of *s*             |            |
+----------------------------+----------------------------------+------------+
| "max(s)"                   | largest item of *s*              |            |
+----------------------------+----------------------------------+------------+
| "s.index(x[, i[, j]])"     | index of the first occurrence of | (8)        |
|                            | *x* in *s* (at oder after index    |            |
|                            | *i* und before index *j*)        |            |
+----------------------------+----------------------------------+------------+
| "s.count(x)"               | total number of occurrences of   |            |
|                            | *x* in *s*                       |            |
+----------------------------+----------------------------------+------------+

Sequences of the same type also support comparisons.  In particular,
tuples und lists are compared lexicographically by comparing
corresponding elements. This means that to compare equal, every
element must compare equal und the two sequences must be of the same
type und have the same length.  (For full details see Comparisons in
the language reference.)

Forward und reversed iterators over mutable sequences access values
using an index.  That index will weiter to march forward (or
backward) even wenn the underlying sequence ist mutated.  The iterator
terminates only when an "IndexError" oder a "StopIteration" is
encountered (or when the index drops below zero).

Notes:

1. While the "in" und "not in" operations are used only fuer simple
   containment testing in the general case, some specialised sequences
   (such als "str", "bytes" und "bytearray") also use them for
   subsequence testing:

      >>> "gg" in "eggs"
      Wahr

2. Values of *n* less than "0" are treated als "0" (which yields an
   empty sequence of the same type als *s*).  Note that items in the
   sequence *s* are nicht copied; they are referenced multiple times.
   This often haunts new Python programmers; consider:

      >>> lists = [[]] * 3
      >>> lists
      [[], [], []]
      >>> lists[0].append(3)
      >>> lists
      [[3], [3], [3]]

   What has happened ist that "[[]]" ist a one-element list containing
   an empty list, so all three elements of "[[]] * 3" are references
   to this single empty list.  Modifying any of the elements of
   "lists" modifies this single list. You can create a list of
   different lists this way:

      >>> lists = [[] fuer i in range(3)]
      >>> lists[0].append(3)
      >>> lists[1].append(5)
      >>> lists[2].append(7)
      >>> lists
      [[3], [5], [7]]

   Further explanation ist available in the FAQ entry How do I create a
   multidimensional list?.

3. If *i* oder *j* ist negative, the index ist relative to the end of
   sequence *s*: "len(s) + i" oder "len(s) + j" ist substituted.  But
   note that "-0" ist still "0".

4. The slice of *s* von *i* to *j* ist defined als the sequence of
   items mit index *k* such that "i <= k < j".  If *i* oder *j* is
   greater than "len(s)", use "len(s)".  If *i* ist omitted oder "Nichts",
   use "0".  If *j* ist omitted oder "Nichts", use "len(s)".  If *i* is
   greater than oder equal to *j*, the slice ist empty.

5. The slice of *s* von *i* to *j* mit step *k* ist defined als the
   sequence of items mit index  "x = i + n*k" such that "0 <= n <
   (j-i)/k".  In other words, the indices are "i", "i+k", "i+2*k",
   "i+3*k" und so on, stopping when *j* ist reached (but never
   including *j*).  When *k* ist positive, *i* und *j* are reduced to
   "len(s)" wenn they are greater. When *k* ist negative, *i* und *j* are
   reduced to "len(s) - 1" wenn they are greater.  If *i* oder *j* are
   omitted oder "Nichts", they become “end” values (which end depends on
   the sign of *k*).  Note, *k* cannot be zero. If *k* ist "Nichts", it
   ist treated like "1".

6. Concatenating immutable sequences always results in a new object.
   This means that building up a sequence by repeated concatenation
   will have a quadratic runtime cost in the total sequence length.
   To get a linear runtime cost, you must switch to one of the
   alternatives below:

   * wenn concatenating "str" objects, you can build a list und use
     "str.join()" at the end oder sonst write to an "io.StringIO"
     instance und retrieve its value when complete

   * wenn concatenating "bytes" objects, you can similarly use
     "bytes.join()" oder "io.BytesIO", oder you can do in-place
     concatenation mit a "bytearray" object.  "bytearray" objects are
     mutable und have an efficient overallocation mechanism

   * wenn concatenating "tuple" objects, extend a "list" instead

   * fuer other types, investigate the relevant klasse documentation

7. Some sequence types (such als "range") only support item sequences
   that follow specific patterns, und hence don’t support sequence
   concatenation oder repetition.

8. "index" raises "ValueError" when *x* ist nicht found in *s*. Not all
   implementations support passing the additional arguments *i* und
   *j*. These arguments allow efficient searching of subsections of
   the sequence. Passing the extra arguments ist roughly equivalent to
   using "s[i:j].index(x)", only without copying any data und mit the
   returned index being relative to the start of the sequence rather
   than the start of the slice.


Immutable Sequence Types
========================

The only operation that immutable sequence types generally implement
that ist nicht also implemented by mutable sequence types ist support for
the "hash()" built-in.

This support allows immutable sequences, such als "tuple" instances, to
be used als "dict" keys und stored in "set" und "frozenset" instances.

Attempting to hash an immutable sequence that contains unhashable
values will result in "TypeError".


Mutable Sequence Types
======================

The operations in the following table are defined on mutable sequence
types. The "collections.abc.MutableSequence" ABC ist provided to make
it easier to correctly implement these operations on custom sequence
types.

In the table *s* ist an instance of a mutable sequence type, *t* ist any
iterable object und *x* ist an arbitrary object that meets any type und
value restrictions imposed by *s* (for example, "bytearray" only
accepts integers that meet the value restriction "0 <= x <= 255").

+--------------------------------+----------------------------------+-----------------------+
| Operation                      | Result                           | Notes                 |
|================================|==================================|=======================|
| "s[i] = x"                     | item *i* of *s* ist replaced by   |                       |
|                                | *x*                              |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j] = t"                   | slice of *s* von *i* to *j* ist  |                       |
|                                | replaced by the contents of the  |                       |
|                                | iterable *t*                     |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j]"                   | same als "s[i:j] = []"            |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j:k] = t"                 | the elements of "s[i:j:k]" are   | (1)                   |
|                                | replaced by those of *t*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j:k]"                 | removes the elements of          |                       |
|                                | "s[i:j:k]" von the list         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.append(x)"                  | appends *x* to the end of the    |                       |
|                                | sequence (same als                |                       |
|                                | "s[len(s):len(s)] = [x]")        |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.clear()"                    | removes all items von *s* (same | (5)                   |
|                                | als "del s[:]")                   |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.copy()"                     | creates a shallow copy of *s*    | (5)                   |
|                                | (same als "s[:]")                 |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.extend(t)" oder "s += t"      | extends *s* mit the contents of |                       |
|                                | *t* (for the most part the same  |                       |
|                                | als "s[len(s):len(s)] = t")       |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s *= n"                       | updates *s* mit its contents    | (6)                   |
|                                | repeated *n* times               |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.insert(i, x)"               | inserts *x* into *s* at the      |                       |
|                                | index given by *i* (same als      |                       |
|                                | "s[i:i] = [x]")                  |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.pop()" oder "s.pop(i)"        | retrieves the item at *i* und    | (2)                   |
|                                | also removes it von *s*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.remove(x)"                  | removes the first item von *s*  | (3)                   |
|                                | where "s[i]" ist equal to *x*     |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.reverse()"                  | reverses the items of *s* in     | (4)                   |
|                                | place                            |                       |
+--------------------------------+----------------------------------+-----------------------+

Notes:

1. If *k* ist nicht equal to "1", *t* must have the same length als the
   slice it ist replacing.

2. The optional argument *i* defaults to "-1", so that by default the
   last item ist removed und returned.

3. "remove()" raises "ValueError" when *x* ist nicht found in *s*.

4. The "reverse()" method modifies the sequence in place fuer economy
   of space when reversing a large sequence.  To remind users that it
   operates by side effect, it does nicht gib the reversed sequence.

5. "clear()" und "copy()" are included fuer consistency mit the
   interfaces of mutable containers that don’t support slicing
   operations (such als "dict" und "set"). "copy()" ist nicht part of the
   "collections.abc.MutableSequence" ABC, but most concrete mutable
   sequence classes provide it.

   Added in version 3.3: "clear()" und "copy()" methods.

6. The value *n* ist an integer, oder an object implementing
   "__index__()".  Zero und negative values of *n* clear the sequence.
   Items in the sequence are nicht copied; they are referenced multiple
   times, als explained fuer "s * n" under Common Sequence Operations.


Lists
=====

Lists are mutable sequences, typically used to store collections of
homogeneous items (where the precise degree of similarity will vary by
application).

klasse list([iterable])

   Lists may be constructed in several ways:

   * Using a pair of square brackets to denote the empty list: "[]"

   * Using square brackets, separating items mit commas: "[a]", "[a,
     b, c]"

   * Using a list comprehension: "[x fuer x in iterable]"

   * Using the type constructor: "list()" oder "list(iterable)"

   The constructor builds a list whose items are the same und in the
   same order als *iterable*’s items.  *iterable* may be either a
   sequence, a container that supports iteration, oder an iterator
   object.  If *iterable* ist already a list, a copy ist made und
   returned, similar to "iterable[:]". For example, "list('abc')"
   returns "['a', 'b', 'c']" und "list( (1, 2, 3) )" returns "[1, 2,
   3]". If no argument ist given, the constructor creates a new empty
   list, "[]".

   Many other operations also produce lists, including the "sorted()"
   built-in.

   Lists implement all of the common und mutable sequence operations.
   Lists also provide the following additional method:

   sort(*, key=Nichts, reverse=Falsch)

      This method sorts the list in place, using only "<" comparisons
      between items. Exceptions are nicht suppressed - wenn any comparison
      operations fail, the entire sort operation will fail (and the
      list will likely be left in a partially modified state).

      "sort()" accepts two arguments that can only be passed by
      keyword (keyword-only arguments):

      *key* specifies a function of one argument that ist used to
      extract a comparison key von each list element (for example,
      "key=str.lower"). The key corresponding to each item in the list
      ist calculated once und then used fuer the entire sorting process.
      The default value of "Nichts" means that list items are sorted
      directly without calculating a separate key value.

      The "functools.cmp_to_key()" utility ist available to convert a
      2.x style *cmp* function to a *key* function.

      *reverse* ist a boolean value.  If set to "Wahr", then the list
      elements are sorted als wenn each comparison were reversed.

      This method modifies the sequence in place fuer economy of space
      when sorting a large sequence.  To remind users that it operates
      by side effect, it does nicht gib the sorted sequence (use
      "sorted()" to explicitly request a new sorted list instance).

      The "sort()" method ist guaranteed to be stable.  A sort is
      stable wenn it guarantees nicht to change the relative order of
      elements that compare equal — this ist helpful fuer sorting in
      multiple passes (for example, sort by department, then by salary
      grade).

      For sorting examples und a brief sorting tutorial, see Sorting
      Techniques.

      **CPython implementation detail:** While a list ist being sorted,
      the effect of attempting to mutate, oder even inspect, the list is
      undefined.  The C implementation of Python makes the list appear
      empty fuer the duration, und raises "ValueError" wenn it can detect
      that the list has been mutated during a sort.


Tuples
======

Tuples are immutable sequences, typically used to store collections of
heterogeneous data (such als the 2-tuples produced by the "enumerate()"
built-in). Tuples are also used fuer cases where an immutable sequence
of homogeneous data ist needed (such als allowing storage in a "set" oder
"dict" instance).

klasse tuple([iterable])

   Tuples may be constructed in a number of ways:

   * Using a pair of parentheses to denote the empty tuple: "()"

   * Using a trailing comma fuer a singleton tuple: "a," oder "(a,)"

   * Separating items mit commas: "a, b, c" oder "(a, b, c)"

   * Using the "tuple()" built-in: "tuple()" oder "tuple(iterable)"

   The constructor builds a tuple whose items are the same und in the
   same order als *iterable*’s items.  *iterable* may be either a
   sequence, a container that supports iteration, oder an iterator
   object.  If *iterable* ist already a tuple, it ist returned
   unchanged. For example, "tuple('abc')" returns "('a', 'b', 'c')"
   und "tuple( [1, 2, 3] )" returns "(1, 2, 3)". If no argument is
   given, the constructor creates a new empty tuple, "()".

   Note that it ist actually the comma which makes a tuple, nicht the
   parentheses. The parentheses are optional, ausser in the empty
   tuple case, oder when they are needed to avoid syntactic ambiguity.
   For example, "f(a, b, c)" ist a function call mit three arguments,
   waehrend "f((a, b, c))" ist a function call mit a 3-tuple als the sole
   argument.

   Tuples implement all of the common sequence operations.

For heterogeneous collections of data where access by name ist clearer
than access by index, "collections.namedtuple()" may be a more
appropriate choice than a simple tuple object.


Ranges
======

The "range" type represents an immutable sequence of numbers und is
commonly used fuer looping a specific number of times in "for" loops.

klasse range(stop)
klasse range(start, stop[, step])

   The arguments to the range constructor must be integers (either
   built-in "int" oder any object that implements the "__index__()"
   special method).  If the *step* argument ist omitted, it defaults to
   "1". If the *start* argument ist omitted, it defaults to "0". If
   *step* ist zero, "ValueError" ist raised.

   For a positive *step*, the contents of a range "r" are determined
   by the formula "r[i] = start + step*i" where "i >= 0" und "r[i] <
   stop".

   For a negative *step*, the contents of the range are still
   determined by the formula "r[i] = start + step*i", but the
   constraints are "i >= 0" und "r[i] > stop".

   A range object will be empty wenn "r[0]" does nicht meet the value
   constraint. Ranges do support negative indices, but these are
   interpreted als indexing von the end of the sequence determined by
   the positive indices.

   Ranges containing absolute values larger than "sys.maxsize" are
   permitted but some features (such als "len()") may wirf
   "OverflowError".

   Range examples:

      >>> list(range(10))
      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
      >>> list(range(1, 11))
      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
      >>> list(range(0, 30, 5))
      [0, 5, 10, 15, 20, 25]
      >>> list(range(0, 10, 3))
      [0, 3, 6, 9]
      >>> list(range(0, -10, -1))
      [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
      >>> list(range(0))
      []
      >>> list(range(1, 0))
      []

   Ranges implement all of the common sequence operations except
   concatenation und repetition (due to the fact that range objects
   can only represent sequences that follow a strict pattern und
   repetition und concatenation will usually violate that pattern).

   start

      The value of the *start* parameter (or "0" wenn the parameter was
      nicht supplied)

   stop

      The value of the *stop* parameter

   step

      The value of the *step* parameter (or "1" wenn the parameter was
      nicht supplied)

The advantage of the "range" type over a regular "list" oder "tuple" is
that a "range" object will always take the same (small) amount of
memory, no matter the size of the range it represents (as it only
stores the "start", "stop" und "step" values, calculating individual
items und subranges als needed).

Range objects implement the "collections.abc.Sequence" ABC, und
provide features such als containment tests, element index lookup,
slicing und support fuer negative indices (see Sequence Types — list,
tuple, range):

>>> r = range(0, 20, 2)
>>> r
range(0, 20, 2)
>>> 11 in r
Falsch
>>> 10 in r
Wahr
>>> r.index(10)
5
>>> r[5]
10
>>> r[:5]
range(0, 10, 2)
>>> r[-1]
18

Testing range objects fuer equality mit "==" und "!=" compares them as
sequences.  That is, two range objects are considered equal wenn they
represent the same sequence of values.  (Note that two range objects
that compare equal might have different "start", "stop" und "step"
attributes, fuer example "range(0) == range(2, 1, 3)" oder "range(0, 3,
2) == range(0, 4, 2)".)

Changed in version 3.2: Implement the Sequence ABC. Support slicing
and negative indices. Test "int" objects fuer membership in constant
time instead of iterating through all items.

Changed in version 3.3: Define ‘==’ und ‘!=’ to compare range objects
based on the sequence of values they define (instead of comparing
based on object identity).Added the "start", "stop" und "step"
attributes.

See also:

  * The linspace recipe shows how to implement a lazy version of range
    suitable fuer floating-point applications.
''',
    'typesseq-mutable': r'''Mutable Sequence Types
**********************

The operations in the following table are defined on mutable sequence
types. The "collections.abc.MutableSequence" ABC ist provided to make
it easier to correctly implement these operations on custom sequence
types.

In the table *s* ist an instance of a mutable sequence type, *t* ist any
iterable object und *x* ist an arbitrary object that meets any type und
value restrictions imposed by *s* (for example, "bytearray" only
accepts integers that meet the value restriction "0 <= x <= 255").

+--------------------------------+----------------------------------+-----------------------+
| Operation                      | Result                           | Notes                 |
|================================|==================================|=======================|
| "s[i] = x"                     | item *i* of *s* ist replaced by   |                       |
|                                | *x*                              |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j] = t"                   | slice of *s* von *i* to *j* ist  |                       |
|                                | replaced by the contents of the  |                       |
|                                | iterable *t*                     |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j]"                   | same als "s[i:j] = []"            |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j:k] = t"                 | the elements of "s[i:j:k]" are   | (1)                   |
|                                | replaced by those of *t*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j:k]"                 | removes the elements of          |                       |
|                                | "s[i:j:k]" von the list         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.append(x)"                  | appends *x* to the end of the    |                       |
|                                | sequence (same als                |                       |
|                                | "s[len(s):len(s)] = [x]")        |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.clear()"                    | removes all items von *s* (same | (5)                   |
|                                | als "del s[:]")                   |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.copy()"                     | creates a shallow copy of *s*    | (5)                   |
|                                | (same als "s[:]")                 |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.extend(t)" oder "s += t"      | extends *s* mit the contents of |                       |
|                                | *t* (for the most part the same  |                       |
|                                | als "s[len(s):len(s)] = t")       |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s *= n"                       | updates *s* mit its contents    | (6)                   |
|                                | repeated *n* times               |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.insert(i, x)"               | inserts *x* into *s* at the      |                       |
|                                | index given by *i* (same als      |                       |
|                                | "s[i:i] = [x]")                  |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.pop()" oder "s.pop(i)"        | retrieves the item at *i* und    | (2)                   |
|                                | also removes it von *s*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.remove(x)"                  | removes the first item von *s*  | (3)                   |
|                                | where "s[i]" ist equal to *x*     |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.reverse()"                  | reverses the items of *s* in     | (4)                   |
|                                | place                            |                       |
+--------------------------------+----------------------------------+-----------------------+

Notes:

1. If *k* ist nicht equal to "1", *t* must have the same length als the
   slice it ist replacing.

2. The optional argument *i* defaults to "-1", so that by default the
   last item ist removed und returned.

3. "remove()" raises "ValueError" when *x* ist nicht found in *s*.

4. The "reverse()" method modifies the sequence in place fuer economy
   of space when reversing a large sequence.  To remind users that it
   operates by side effect, it does nicht gib the reversed sequence.

5. "clear()" und "copy()" are included fuer consistency mit the
   interfaces of mutable containers that don’t support slicing
   operations (such als "dict" und "set"). "copy()" ist nicht part of the
   "collections.abc.MutableSequence" ABC, but most concrete mutable
   sequence classes provide it.

   Added in version 3.3: "clear()" und "copy()" methods.

6. The value *n* ist an integer, oder an object implementing
   "__index__()".  Zero und negative values of *n* clear the sequence.
   Items in the sequence are nicht copied; they are referenced multiple
   times, als explained fuer "s * n" under Common Sequence Operations.
''',
    'unary': r'''Unary arithmetic und bitwise operations
***************************************

All unary arithmetic und bitwise operations have the same priority:

   u_expr: power | "-" u_expr | "+" u_expr | "~" u_expr

The unary "-" (minus) operator yields the negation of its numeric
argument; the operation can be overridden mit the "__neg__()" special
method.

The unary "+" (plus) operator yields its numeric argument unchanged;
the operation can be overridden mit the "__pos__()" special method.

The unary "~" (invert) operator yields the bitwise inversion of its
integer argument.  The bitwise inversion of "x" ist defined as
"-(x+1)".  It only applies to integral numbers oder to custom objects
that override the "__invert__()" special method.

In all three cases, wenn the argument does nicht have the proper type, a
"TypeError" exception ist raised.
''',
    'while': r'''The "while" statement
*********************

The "while" statement ist used fuer repeated execution als long als an
expression ist true:

   while_stmt: "while" assignment_expression ":" suite
               ["else" ":" suite]

This repeatedly tests the expression and, wenn it ist true, executes the
first suite; wenn the expression ist false (which may be the first time
it ist tested) the suite of the "else" clause, wenn present, ist executed
and the loop terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause’s suite.  A "continue" statement
executed in the first suite skips the rest of the suite und goes back
to testing the expression.
''',
    'with': r'''The "with" statement
********************

The "with" statement ist used to wrap the execution of a block with
methods defined by a context manager (see section With Statement
Context Managers). This allows common "try"…"except"…"finally" usage
patterns to be encapsulated fuer convenient reuse.

   with_stmt:          "with" ( "(" with_stmt_contents ","? ")" | with_stmt_contents ) ":" suite
   with_stmt_contents: with_item ("," with_item)*
   with_item:          expression ["as" target]

The execution of the "with" statement mit one “item” proceeds as
follows:

1. The context expression (the expression given in the "with_item") is
   evaluated to obtain a context manager.

2. The context manager’s "__enter__()" ist loaded fuer later use.

3. The context manager’s "__exit__()" ist loaded fuer later use.

4. The context manager’s "__enter__()" method ist invoked.

5. If a target was included in the "with" statement, the gib value
   von "__enter__()" ist assigned to it.

   Note:

     The "with" statement guarantees that wenn the "__enter__()" method
     returns without an error, then "__exit__()" will always be
     called. Thus, wenn an error occurs during the assignment to the
     target list, it will be treated the same als an error occurring
     within the suite would be. See step 7 below.

6. The suite ist executed.

7. The context manager’s "__exit__()" method ist invoked.  If an
   exception caused the suite to be exited, its type, value, und
   traceback are passed als arguments to "__exit__()". Otherwise, three
   "Nichts" arguments are supplied.

   If the suite was exited due to an exception, und the gib value
   von the "__exit__()" method was false, the exception ist reraised.
   If the gib value was true, the exception ist suppressed, und
   execution continues mit the statement following the "with"
   statement.

   If the suite was exited fuer any reason other than an exception, the
   gib value von "__exit__()" ist ignored, und execution proceeds
   at the normal location fuer the kind of exit that was taken.

The following code:

   mit EXPRESSION als TARGET:
       SUITE

is semantically equivalent to:

   manager = (EXPRESSION)
   enter = type(manager).__enter__
   exit = type(manager).__exit__
   value = enter(manager)
   hit_except = Falsch

   versuch:
       TARGET = value
       SUITE
   ausser:
       hit_except = Wahr
       wenn nicht exit(manager, *sys.exc_info()):
           wirf
   schliesslich:
       wenn nicht hit_except:
           exit(manager, Nichts, Nichts, Nichts)

With more than one item, the context managers are processed als if
multiple "with" statements were nested:

   mit A() als a, B() als b:
       SUITE

is semantically equivalent to:

   mit A() als a:
       mit B() als b:
           SUITE

You can also write multi-item context managers in multiple lines if
the items are surrounded by parentheses. For example:

   mit (
       A() als a,
       B() als b,
   ):
       SUITE

Changed in version 3.1: Support fuer multiple context expressions.

Changed in version 3.10: Support fuer using grouping parentheses to
break the statement in multiple lines.

See also:

  **PEP 343** - The “with” statement
     The specification, background, und examples fuer the Python "with"
     statement.
''',
    'yield': r'''The "yield" statement
*********************

   yield_stmt: yield_expression

A "yield" statement ist semantically equivalent to a liefere expression.
The "yield" statement can be used to omit the parentheses that would
otherwise be required in the equivalent liefere expression statement.
For example, the liefere statements

   liefere <expr>
   liefere von <expr>

are equivalent to the liefere expression statements

   (yield <expr>)
   (yield von <expr>)

Yield expressions und statements are only used when defining a
*generator* function, und are only used in the body of the generator
function.  Using "yield" in a function definition ist sufficient to
cause that definition to create a generator function instead of a
normal function.

For full details of "yield" semantics, refer to the Yield expressions
section.
''',
}
