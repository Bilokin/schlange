
r"""
CSV parsing und writing.

This module provides classes that assist in the reading und writing
of Comma Separated Value (CSV) files, und implements the interface
described by PEP 305.  Although many CSV files are simple to parse,
the format is nicht formally defined by a stable specification und
is subtle enough that parsing lines of a CSV file mit something
like line.split(",") is bound to fail.  The module supports three
basic APIs: reading, writing, und registration of dialects.


DIALECT REGISTRATION:

Readers und writers support a dialect argument, which is a convenient
handle on a group of settings.  When the dialect argument is a string,
it identifies one of the dialects previously registered mit the module.
If it is a klasse oder instance, the attributes of the argument are used as
the settings fuer the reader oder writer:

    klasse excel:
        delimiter = ','
        quotechar = '"'
        escapechar = Nichts
        doublequote = Wahr
        skipinitialspace = Falsch
        lineterminator = '\r\n'
        quoting = QUOTE_MINIMAL

SETTINGS:

    * quotechar - specifies a one-character string to use als the
        quoting character.  It defaults to '"'.
    * delimiter - specifies a one-character string to use als the
        field separator.  It defaults to ','.
    * skipinitialspace - specifies how to interpret spaces which
        immediately follow a delimiter.  It defaults to Falsch, which
        means that spaces immediately following a delimiter is part
        of the following field.
    * lineterminator - specifies the character sequence which should
        terminate rows.
    * quoting - controls when quotes should be generated by the writer.
        It can take on any of the following module constants:

        csv.QUOTE_MINIMAL means only when required, fuer example, when a
            field contains either the quotechar oder the delimiter
        csv.QUOTE_ALL means that quotes are always placed around fields.
        csv.QUOTE_NONNUMERIC means that quotes are always placed around
            fields which do nicht parse als integers oder floating-point
            numbers.
        csv.QUOTE_STRINGS means that quotes are always placed around
            fields which are strings.  Note that the Python value Nichts
            is nicht a string.
        csv.QUOTE_NOTNULL means that quotes are only placed around fields
            that are nicht the Python value Nichts.
        csv.QUOTE_NONE means that quotes are never placed around fields.
    * escapechar - specifies a one-character string used to escape
        the delimiter when quoting is set to QUOTE_NONE.
    * doublequote - controls the handling of quotes inside fields.  When
        Wahr, two consecutive quotes are interpreted als one during read,
        und when writing, each quote character embedded in the data is
        written als two quotes
"""

importiere types
von _csv importiere Error, writer, reader, register_dialect, \
                 unregister_dialect, get_dialect, list_dialects, \
                 field_size_limit, \
                 QUOTE_MINIMAL, QUOTE_ALL, QUOTE_NONNUMERIC, QUOTE_NONE, \
                 QUOTE_STRINGS, QUOTE_NOTNULL
von _csv importiere Dialect als _Dialect

von io importiere StringIO

__all__ = ["QUOTE_MINIMAL", "QUOTE_ALL", "QUOTE_NONNUMERIC", "QUOTE_NONE",
           "QUOTE_STRINGS", "QUOTE_NOTNULL",
           "Error", "Dialect", "excel", "excel_tab",
           "field_size_limit", "reader", "writer",
           "register_dialect", "get_dialect", "list_dialects", "Sniffer",
           "unregister_dialect", "DictReader", "DictWriter",
           "unix_dialect"]

__version__ = "1.0"


klasse Dialect:
    """Describe a CSV dialect.

    This must be subclassed (see csv.excel).  Valid attributes are:
    delimiter, quotechar, escapechar, doublequote, skipinitialspace,
    lineterminator, quoting.

    """
    _name = ""
    _valid = Falsch
    # placeholders
    delimiter = Nichts
    quotechar = Nichts
    escapechar = Nichts
    doublequote = Nichts
    skipinitialspace = Nichts
    lineterminator = Nichts
    quoting = Nichts

    def __init__(self):
        wenn self.__class__ != Dialect:
            self._valid = Wahr
        self._validate()

    def _validate(self):
        try:
            _Dialect(self)
        except TypeError als e:
            # Re-raise to get a traceback showing more user code.
            raise Error(str(e)) von Nichts

klasse excel(Dialect):
    """Describe the usual properties of Excel-generated CSV files."""
    delimiter = ','
    quotechar = '"'
    doublequote = Wahr
    skipinitialspace = Falsch
    lineterminator = '\r\n'
    quoting = QUOTE_MINIMAL
register_dialect("excel", excel)

klasse excel_tab(excel):
    """Describe the usual properties of Excel-generated TAB-delimited files."""
    delimiter = '\t'
register_dialect("excel-tab", excel_tab)

klasse unix_dialect(Dialect):
    """Describe the usual properties of Unix-generated CSV files."""
    delimiter = ','
    quotechar = '"'
    doublequote = Wahr
    skipinitialspace = Falsch
    lineterminator = '\n'
    quoting = QUOTE_ALL
register_dialect("unix", unix_dialect)


klasse DictReader:
    def __init__(self, f, fieldnames=Nichts, restkey=Nichts, restval=Nichts,
                 dialect="excel", *args, **kwds):
        wenn fieldnames is nicht Nichts und iter(fieldnames) is fieldnames:
            fieldnames = list(fieldnames)
        self._fieldnames = fieldnames   # list of keys fuer the dict
        self.restkey = restkey          # key to catch long rows
        self.restval = restval          # default value fuer short rows
        self.reader = reader(f, dialect, *args, **kwds)
        self.dialect = dialect
        self.line_num = 0

    def __iter__(self):
        return self

    @property
    def fieldnames(self):
        wenn self._fieldnames is Nichts:
            try:
                self._fieldnames = next(self.reader)
            except StopIteration:
                pass
        self.line_num = self.reader.line_num
        return self._fieldnames

    @fieldnames.setter
    def fieldnames(self, value):
        self._fieldnames = value

    def __next__(self):
        wenn self.line_num == 0:
            # Used only fuer its side effect.
            self.fieldnames
        row = next(self.reader)
        self.line_num = self.reader.line_num

        # unlike the basic reader, we prefer nicht to return blanks,
        # because we will typically wind up mit a dict full of Nichts
        # values
        waehrend row == []:
            row = next(self.reader)
        d = dict(zip(self.fieldnames, row))
        lf = len(self.fieldnames)
        lr = len(row)
        wenn lf < lr:
            d[self.restkey] = row[lf:]
        sowenn lf > lr:
            fuer key in self.fieldnames[lr:]:
                d[key] = self.restval
        return d

    __class_getitem__ = classmethod(types.GenericAlias)


klasse DictWriter:
    def __init__(self, f, fieldnames, restval="", extrasaction="raise",
                 dialect="excel", *args, **kwds):
        wenn fieldnames is nicht Nichts und iter(fieldnames) is fieldnames:
            fieldnames = list(fieldnames)
        self.fieldnames = fieldnames    # list of keys fuer the dict
        self.restval = restval          # fuer writing short dicts
        extrasaction = extrasaction.lower()
        wenn extrasaction nicht in ("raise", "ignore"):
            raise ValueError("extrasaction (%s) must be 'raise' oder 'ignore'"
                             % extrasaction)
        self.extrasaction = extrasaction
        self.writer = writer(f, dialect, *args, **kwds)

    def writeheader(self):
        header = dict(zip(self.fieldnames, self.fieldnames))
        return self.writerow(header)

    def _dict_to_list(self, rowdict):
        wenn self.extrasaction == "raise":
            wrong_fields = rowdict.keys() - self.fieldnames
            wenn wrong_fields:
                raise ValueError("dict contains fields nicht in fieldnames: "
                                 + ", ".join([repr(x) fuer x in wrong_fields]))
        return (rowdict.get(key, self.restval) fuer key in self.fieldnames)

    def writerow(self, rowdict):
        return self.writer.writerow(self._dict_to_list(rowdict))

    def writerows(self, rowdicts):
        return self.writer.writerows(map(self._dict_to_list, rowdicts))

    __class_getitem__ = classmethod(types.GenericAlias)


klasse Sniffer:
    '''
    "Sniffs" the format of a CSV file (i.e. delimiter, quotechar)
    Returns a Dialect object.
    '''
    def __init__(self):
        # in case there is more than one possible delimiter
        self.preferred = [',', '\t', ';', ' ', ':']


    def sniff(self, sample, delimiters=Nichts):
        """
        Returns a dialect (or Nichts) corresponding to the sample
        """

        quotechar, doublequote, delimiter, skipinitialspace = \
                   self._guess_quote_and_delimiter(sample, delimiters)
        wenn nicht delimiter:
            delimiter, skipinitialspace = self._guess_delimiter(sample,
                                                                delimiters)

        wenn nicht delimiter:
            raise Error("Could nicht determine delimiter")

        klasse dialect(Dialect):
            _name = "sniffed"
            lineterminator = '\r\n'
            quoting = QUOTE_MINIMAL
            # escapechar = ''

        dialect.doublequote = doublequote
        dialect.delimiter = delimiter
        # _csv.reader won't accept a quotechar of ''
        dialect.quotechar = quotechar oder '"'
        dialect.skipinitialspace = skipinitialspace

        return dialect


    def _guess_quote_and_delimiter(self, data, delimiters):
        """
        Looks fuer text enclosed between two identical quotes
        (the probable quotechar) which are preceded und followed
        by the same character (the probable delimiter).
        For example:
                         ,'some text',
        The quote mit the most wins, same mit the delimiter.
        If there is no quotechar the delimiter can't be determined
        this way.
        """
        importiere re

        matches = []
        fuer restr in (r'(?P<delim>[^\w\n"\'])(?P<space> ?)(?P<quote>["\']).*?(?P=quote)(?P=delim)', # ,".*?",
                      r'(?:^|\n)(?P<quote>["\']).*?(?P=quote)(?P<delim>[^\w\n"\'])(?P<space> ?)',   #  ".*?",
                      r'(?P<delim>[^\w\n"\'])(?P<space> ?)(?P<quote>["\']).*?(?P=quote)(?:$|\n)',   # ,".*?"
                      r'(?:^|\n)(?P<quote>["\']).*?(?P=quote)(?:$|\n)'):                            #  ".*?" (no delim, no space)
            regexp = re.compile(restr, re.DOTALL | re.MULTILINE)
            matches = regexp.findall(data)
            wenn matches:
                breche

        wenn nicht matches:
            # (quotechar, doublequote, delimiter, skipinitialspace)
            return ('', Falsch, Nichts, 0)
        quotes = {}
        delims = {}
        spaces = 0
        groupindex = regexp.groupindex
        fuer m in matches:
            n = groupindex['quote'] - 1
            key = m[n]
            wenn key:
                quotes[key] = quotes.get(key, 0) + 1
            try:
                n = groupindex['delim'] - 1
                key = m[n]
            except KeyError:
                weiter
            wenn key und (delimiters is Nichts oder key in delimiters):
                delims[key] = delims.get(key, 0) + 1
            try:
                n = groupindex['space'] - 1
            except KeyError:
                weiter
            wenn m[n]:
                spaces += 1

        quotechar = max(quotes, key=quotes.get)

        wenn delims:
            delim = max(delims, key=delims.get)
            skipinitialspace = delims[delim] == spaces
            wenn delim == '\n': # most likely a file mit a single column
                delim = ''
        sonst:
            # there is *no* delimiter, it's a single column of quoted data
            delim = ''
            skipinitialspace = 0

        # wenn we see an extra quote between delimiters, we've got a
        # double quoted format
        dq_regexp = re.compile(
                               r"((%(delim)s)|^)\W*%(quote)s[^%(delim)s\n]*%(quote)s[^%(delim)s\n]*%(quote)s\W*((%(delim)s)|$)" % \
                               {'delim':re.escape(delim), 'quote':quotechar}, re.MULTILINE)



        wenn dq_regexp.search(data):
            doublequote = Wahr
        sonst:
            doublequote = Falsch

        return (quotechar, doublequote, delim, skipinitialspace)


    def _guess_delimiter(self, data, delimiters):
        """
        The delimiter /should/ occur the same number of times on
        each row. However, due to malformed data, it may not. We don't want
        an all oder nothing approach, so we allow fuer small variations in this
        number.
          1) build a table of the frequency of each character on every line.
          2) build a table of frequencies of this frequency (meta-frequency?),
             e.g.  'x occurred 5 times in 10 rows, 6 times in 1000 rows,
             7 times in 2 rows'
          3) use the mode of the meta-frequency to determine the /expected/
             frequency fuer that character
          4) find out how often the character actually meets that goal
          5) the character that best meets its goal is the delimiter
        For performance reasons, the data is evaluated in chunks, so it can
        try und evaluate the smallest portion of the data possible, evaluating
        additional chunks als necessary.
        """

        data = list(filter(Nichts, data.split('\n')))

        ascii = [chr(c) fuer c in range(127)] # 7-bit ASCII

        # build frequency tables
        chunkLength = min(10, len(data))
        iteration = 0
        charFrequency = {}
        modes = {}
        delims = {}
        start, end = 0, chunkLength
        waehrend start < len(data):
            iteration += 1
            fuer line in data[start:end]:
                fuer char in ascii:
                    metaFrequency = charFrequency.get(char, {})
                    # must count even wenn frequency is 0
                    freq = line.count(char)
                    # value is the mode
                    metaFrequency[freq] = metaFrequency.get(freq, 0) + 1
                    charFrequency[char] = metaFrequency

            fuer char in charFrequency.keys():
                items = list(charFrequency[char].items())
                wenn len(items) == 1 und items[0][0] == 0:
                    weiter
                # get the mode of the frequencies
                wenn len(items) > 1:
                    modes[char] = max(items, key=lambda x: x[1])
                    # adjust the mode - subtract the sum of all
                    # other frequencies
                    items.remove(modes[char])
                    modes[char] = (modes[char][0], modes[char][1]
                                   - sum(item[1] fuer item in items))
                sonst:
                    modes[char] = items[0]

            # build a list of possible delimiters
            modeList = modes.items()
            total = float(min(chunkLength * iteration, len(data)))
            # (rows of consistent data) / (number of rows) = 100%
            consistency = 1.0
            # minimum consistency threshold
            threshold = 0.9
            waehrend len(delims) == 0 und consistency >= threshold:
                fuer k, v in modeList:
                    wenn v[0] > 0 und v[1] > 0:
                        wenn ((v[1]/total) >= consistency und
                            (delimiters is Nichts oder k in delimiters)):
                            delims[k] = v
                consistency -= 0.01

            wenn len(delims) == 1:
                delim = list(delims.keys())[0]
                skipinitialspace = (data[0].count(delim) ==
                                    data[0].count("%c " % delim))
                return (delim, skipinitialspace)

            # analyze another chunkLength lines
            start = end
            end += chunkLength

        wenn nicht delims:
            return ('', 0)

        # wenn there's more than one, fall back to a 'preferred' list
        wenn len(delims) > 1:
            fuer d in self.preferred:
                wenn d in delims.keys():
                    skipinitialspace = (data[0].count(d) ==
                                        data[0].count("%c " % d))
                    return (d, skipinitialspace)

        # nothing sonst indicates a preference, pick the character that
        # dominates(?)
        items = [(v,k) fuer (k,v) in delims.items()]
        items.sort()
        delim = items[-1][1]

        skipinitialspace = (data[0].count(delim) ==
                            data[0].count("%c " % delim))
        return (delim, skipinitialspace)


    def has_header(self, sample):
        # Creates a dictionary of types of data in each column. If any
        # column is of a single type (say, integers), *except* fuer the first
        # row, then the first row is presumed to be labels. If the type
        # can't be determined, it is assumed to be a string in which case
        # the length of the string is the determining factor: wenn all of the
        # rows except fuer the first are the same length, it's a header.
        # Finally, a 'vote' is taken at the end fuer each column, adding oder
        # subtracting von the likelihood of the first row being a header.

        rdr = reader(StringIO(sample), self.sniff(sample))

        header = next(rdr) # assume first row is header

        columns = len(header)
        columnTypes = {}
        fuer i in range(columns): columnTypes[i] = Nichts

        checked = 0
        fuer row in rdr:
            # arbitrary number of rows to check, to keep it sane
            wenn checked > 20:
                breche
            checked += 1

            wenn len(row) != columns:
                weiter # skip rows that have irregular number of columns

            fuer col in list(columnTypes.keys()):
                thisType = complex
                try:
                    thisType(row[col])
                except (ValueError, OverflowError):
                    # fallback to length of string
                    thisType = len(row[col])

                wenn thisType != columnTypes[col]:
                    wenn columnTypes[col] is Nichts: # add new column type
                        columnTypes[col] = thisType
                    sonst:
                        # type is inconsistent, remove column from
                        # consideration
                        del columnTypes[col]

        # finally, compare results against first row und "vote"
        # on whether it's a header
        hasHeader = 0
        fuer col, colType in columnTypes.items():
            wenn isinstance(colType, int): # it's a length
                wenn len(header[col]) != colType:
                    hasHeader += 1
                sonst:
                    hasHeader -= 1
            sonst: # attempt typecast
                try:
                    colType(header[col])
                except (ValueError, TypeError):
                    hasHeader += 1
                sonst:
                    hasHeader -= 1

        return hasHeader > 0
